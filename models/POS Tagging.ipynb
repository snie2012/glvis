{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possible libraries and models to use: flair, fastai, allennlp, huggingface\n",
    "\n",
    "### Summary report: https://nlpprogress.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Official Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(3, 3)  # Input dim is 3, output dim is 3\n",
    "inputs = [torch.randn(1, 3) for _ in range(5)]  # make a sequence of length 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.5525,  0.6355, -0.3968]]),\n",
       " tensor([[-0.6571, -1.6428,  0.9803]]),\n",
       " tensor([[-0.0421, -0.8206,  0.3133]]),\n",
       " tensor([[-1.1352,  0.3773, -0.2824]]),\n",
       " tensor([[-2.5667, -1.4303,  0.5009]])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the hidden state.\n",
    "hidden = (torch.randn(1, 1, 3),\n",
    "          torch.randn(1, 1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in inputs:\n",
    "    # Step through the sequence one element at a time.\n",
    "    # after each step, hidden contains the hidden state.\n",
    "    out, hidden = lstm(i.view(1, 1, -1), hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2682,  0.0304, -0.1526]],\n",
      "\n",
      "        [[-0.5370,  0.0346, -0.1958]],\n",
      "\n",
      "        [[-0.3947,  0.0391, -0.1217]],\n",
      "\n",
      "        [[-0.1854,  0.0740, -0.0979]],\n",
      "\n",
      "        [[-0.3600,  0.0893,  0.0215]]], grad_fn=<StackBackward>)\n",
      "(tensor([[[-0.3600,  0.0893,  0.0215]]], grad_fn=<StackBackward>), tensor([[[-1.1298,  0.4467,  0.0254]]], grad_fn=<StackBackward>))\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.cat(inputs).view(len(inputs), 1, -1)\n",
    "hidden = (torch.randn(1, 1, 3), torch.randn(1, 1, 3))  # clean out hidden state\n",
    "out, hidden = lstm(inputs, hidden)\n",
    "print(out)\n",
    "print(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'The': 0, 'dog': 1, 'ate': 2, 'the': 3, 'apple': 4, 'Everybody': 5, 'read': 6, 'that': 7, 'book': 8}\n"
     ]
    }
   ],
   "source": [
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "\n",
    "training_data = [\n",
    "    (\"The dog ate the apple\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"]),\n",
    "    (\"Everybody read that book\".split(), [\"NN\", \"V\", \"DET\", \"NN\"])\n",
    "]\n",
    "word_to_ix = {}\n",
    "for sent, tags in training_data:\n",
    "    for word in sent:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "print(word_to_ix)\n",
    "tag_to_ix = {\"DET\": 0, \"NN\": 1, \"V\": 2}\n",
    "\n",
    "# These will usually be more like 32 or 64 dimensional.\n",
    "# We will keep them small, so we can see how the weights change as we train.\n",
    "EMBEDDING_DIM = 6\n",
    "HIDDEN_DIM = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # Before we've done anything, we dont have any hidden state.\n",
    "        # Refer to the Pytorch documentation to see exactly\n",
    "        # why they have this dimensionality.\n",
    "        # The axes semantics are (num_layers, minibatch_size, hidden_dim)\n",
    "        return (torch.zeros(1, 1, self.hidden_dim),\n",
    "                torch.zeros(1, 1, self.hidden_dim))\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, self.hidden = self.lstm(\n",
    "            embeds.view(len(sentence), 1, -1), self.hidden)\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0388, -0.9874, -1.2962],\n",
      "        [-0.9900, -1.0083, -1.3334],\n",
      "        [-0.9792, -1.0514, -1.2912],\n",
      "        [-0.9556, -1.0550, -1.3197],\n",
      "        [-0.9470, -1.0579, -1.3284]])\n",
      "tensor([[-0.0882, -2.5320, -5.3084],\n",
      "        [-3.8870, -0.0483, -3.6236],\n",
      "        [-2.2643, -3.0358, -0.1648],\n",
      "        [-0.0950, -2.6379, -3.9579],\n",
      "        [-4.1251, -0.0204, -5.5152]])\n"
     ]
    }
   ],
   "source": [
    "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(tag_to_ix))\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# See what the scores are before training\n",
    "# Note that element i,j of the output is the score for tag j for word i.\n",
    "# Here we don't need to train, so the code is wrapped in torch.no_grad()\n",
    "with torch.no_grad():\n",
    "    inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "    tag_scores = model(inputs)\n",
    "    print(tag_scores)\n",
    "\n",
    "for epoch in range(300):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    for sentence, tags in training_data:\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Also, we need to clear out the hidden state of the LSTM,\n",
    "        # detaching it from its history on the last instance.\n",
    "        model.hidden = model.init_hidden()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "        # Tensors of word indices.\n",
    "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
    "        targets = prepare_sequence(tags, tag_to_ix)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        tag_scores = model(sentence_in)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        loss = loss_function(tag_scores, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# See what the scores are after training\n",
    "with torch.no_grad():\n",
    "    inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "    tag_scores = model(inputs)\n",
    "\n",
    "    # The sentence is \"the dog ate the apple\".  i,j corresponds to score for tag j\n",
    "    # for word i. The predicted tag is the maximum scoring tag.\n",
    "    # Here, we can see the predicted sequence below is 0 1 2 0 1\n",
    "    # since 0 is index of the maximum value of row 1,\n",
    "    # 1 is the index of maximum value of row 2, etc.\n",
    "    # Which is DET NOUN VERB DET NOUN, the correct sequence!\n",
    "    print(tag_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flair (https://github.com/zalandoresearch/flair)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "from flair.models import TextClassifier\n",
    "\n",
    "from flair.data import TaggedCorpus\n",
    "from flair.data_fetcher import  NLPTaskDataFetcher, NLPTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos = os.listdir('data/aclImdb_v1/aclImdb/train/pos/')\n",
    "train_neg = os.listdir('data/aclImdb_v1/aclImdb/train/neg/')\n",
    "test_pos = os.listdir('data/aclImdb_v1/aclImdb/test/pos/')\n",
    "test_neg = os.listdir('data/aclImdb_v1/aclImdb/test/neg/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_data = []\n",
    "for name in train_pos:\n",
    "    with open('data/aclImdb_v1/aclImdb/train/pos/' + name, 'r') as f:\n",
    "        pos_data.append(f.readline())\n",
    "for name in test_pos:\n",
    "    with open('data/aclImdb_v1/aclImdb/test/pos/' + name, 'r') as f:\n",
    "        pos_data.append(f.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_data = []\n",
    "for name in train_neg:\n",
    "    with open('data/aclImdb_v1/aclImdb/train/neg/' + name, 'r') as f:\n",
    "        neg_data.append(f.readline())\n",
    "for name in test_neg:\n",
    "    with open('data/aclImdb_v1/aclImdb/test/neg/' + name, 'r') as f:\n",
    "        neg_data.append(f.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [Sentence(s) for s in pos_data[:100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_model = TextClassifier.load('en-sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_val = [torch.zeros(1, 2048) for _ in range(len(sentences))]\n",
    "counter = 0\n",
    "\n",
    "def hook(m, i, o): \n",
    "    inter_val[counter].copy_(i[0].data)\n",
    "\n",
    "h = sent_model.decoder.register_forward_hook(hook)\n",
    "for sent in sentences:\n",
    "    sent_model.predict(sent)\n",
    "    counter += 1\n",
    "h.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (0.7514839172363281)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (0.21342727541923523)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (0.5871809720993042)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (0.8683277368545532)]\n",
      "[POSITIVE (0.48940327763557434)]\n",
      "[POSITIVE (0.8193634748458862)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (0.7528064250946045)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[NEGATIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (0.8242219686508179)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (0.8174653053283691)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n",
      "[POSITIVE (1.0)]\n"
     ]
    }
   ],
   "source": [
    "for sen in sentences:\n",
    "    print(sen.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 3.81 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.0411,  0.0048, -0.0511,  ..., -0.0895, -0.1808,  0.0509]]),\n",
       " tensor([[ 0.0370, -0.1056,  0.0722,  ..., -0.0667, -0.0495, -0.1277]]),\n",
       " tensor([[-0.0193, -0.0480,  0.0119,  ..., -0.1480, -0.0269, -0.1073]]),\n",
       " tensor([[-0.0140, -0.0737,  0.0113,  ...,  0.1729, -0.0655, -0.0659]]),\n",
       " tensor([[ 0.1415, -0.0319, -0.0013,  ..., -0.1360, -0.0949, -0.2074]]),\n",
       " tensor([[-0.0221, -0.0007, -0.0531,  ..., -0.1498,  0.1480, -0.2181]]),\n",
       " tensor([[ 0.0567, -0.1174,  0.1452,  ...,  0.0286,  0.0652,  0.0825]]),\n",
       " tensor([[ 0.0655, -0.0371,  0.0578,  ..., -0.1602,  0.1299, -0.1328]]),\n",
       " tensor([[-0.0255,  0.0019, -0.0559,  ...,  0.1681, -0.1455, -0.0203]]),\n",
       " tensor([[-0.0877, -0.0327,  0.0070,  ..., -0.0902, -0.0880, -0.0886]]),\n",
       " tensor([[-0.1594,  0.0520,  0.0768,  ..., -0.0364,  0.1285, -0.0340]]),\n",
       " tensor([[-0.0577, -0.0559,  0.0334,  ..., -0.0590, -0.0160, -0.0193]]),\n",
       " tensor([[-0.0321, -0.0037, -0.0690,  ...,  0.2156, -0.0177, -0.0405]]),\n",
       " tensor([[-0.2475, -0.1108, -0.0898,  ...,  0.0203, -0.0921, -0.0459]]),\n",
       " tensor([[-0.0179, -0.0558,  0.0112,  ..., -0.0332, -0.0467,  0.0371]]),\n",
       " tensor([[-0.0192, -0.0549,  0.0152,  ..., -0.0526,  0.0140, -0.0336]]),\n",
       " tensor([[0.1096, 0.0371, 0.0564,  ..., 0.1466, 0.0107, 0.0202]]),\n",
       " tensor([[-0.0242,  0.0073, -0.0612,  ...,  0.0916,  0.0784, -0.2013]]),\n",
       " tensor([[-0.1035, -0.0895, -0.0089,  ..., -0.1503, -0.0847,  0.0188]]),\n",
       " tensor([[-0.1846, -0.0581, -0.1039,  ..., -0.1459,  0.1635, -0.2022]]),\n",
       " tensor([[ 0.0314, -0.0536,  0.0317,  ...,  0.0291,  0.0297,  0.0308]]),\n",
       " tensor([[-0.0700,  0.0362, -0.0111,  ..., -0.1633,  0.1147, -0.0618]]),\n",
       " tensor([[-0.0228, -0.0065,  0.0914,  ..., -0.0663, -0.1702, -0.0031]]),\n",
       " tensor([[-0.1002,  0.0232, -0.0404,  ..., -0.1892,  0.2086, -0.0448]]),\n",
       " tensor([[-0.0376, -0.0033, -0.0518,  ...,  0.0219,  0.1470, -0.1883]]),\n",
       " tensor([[ 0.0192, -0.1012,  0.0472,  ..., -0.0359, -0.0318, -0.1189]]),\n",
       " tensor([[ 0.1051,  0.1274,  0.1060,  ..., -0.1727,  0.2130, -0.0253]]),\n",
       " tensor([[ 0.0751, -0.1016,  0.0296,  ..., -0.1242,  0.0454, -0.0637]]),\n",
       " tensor([[-0.0444, -0.1148, -0.0018,  ..., -0.0513, -0.0297, -0.1074]]),\n",
       " tensor([[-0.0356,  0.0059, -0.0592,  ..., -0.0744, -0.0491, -0.0383]]),\n",
       " tensor([[-0.0305,  0.0004, -0.0542,  ..., -0.0272,  0.0104, -0.1314]]),\n",
       " tensor([[-0.0167, -0.0659,  0.0070,  ..., -0.0752,  0.0430, -0.1124]]),\n",
       " tensor([[-0.0117, -0.0741,  0.0088,  ...,  0.1575, -0.0640, -0.1333]]),\n",
       " tensor([[-0.0563, -0.0699,  0.0377,  ..., -0.0775, -0.1472,  0.1048]]),\n",
       " tensor([[-0.0679, -0.0339,  0.0396,  ...,  0.1409, -0.1874, -0.1739]]),\n",
       " tensor([[-0.0745,  0.0189,  0.0019,  ...,  0.0093,  0.0320,  0.0333]]),\n",
       " tensor([[-0.0703, -0.1884,  0.0379,  ...,  0.0446,  0.1917, -0.0740]]),\n",
       " tensor([[-2.4184e-02, -3.8005e-05, -5.6814e-02,  ..., -9.4053e-02,\n",
       "          -3.7375e-02, -1.3199e-01]]),\n",
       " tensor([[-0.0218,  0.0046, -0.0579,  ...,  0.1031,  0.0589, -0.1806]]),\n",
       " tensor([[-0.0202, -0.0577,  0.0105,  ..., -0.0957, -0.0460, -0.0326]]),\n",
       " tensor([[ 0.0980, -0.0498,  0.2129,  ..., -0.0314, -0.1063, -0.1280]]),\n",
       " tensor([[-0.0200, -0.0525,  0.0151,  ..., -0.0776,  0.0831, -0.1427]]),\n",
       " tensor([[-0.0157, -0.0316,  0.1044,  ..., -0.0584,  0.1861, -0.0475]]),\n",
       " tensor([[ 0.0174, -0.0577, -0.0021,  ..., -0.1960, -0.0589, -0.0546]]),\n",
       " tensor([[-0.2912, -0.0983,  0.0214,  ...,  0.0721,  0.1424, -0.1960]]),\n",
       " tensor([[-0.0300, -0.0160, -0.0560,  ..., -0.0634, -0.0272, -0.1784]]),\n",
       " tensor([[-0.0206, -0.0571,  0.0167,  ..., -0.1627, -0.0202, -0.1047]]),\n",
       " tensor([[-0.0610,  0.0437, -0.0175,  ..., -0.0917, -0.1811, -0.0188]]),\n",
       " tensor([[-0.0156, -0.0637,  0.0110,  ...,  0.0159, -0.0132, -0.1965]]),\n",
       " tensor([[-0.0199, -0.0170, -0.0571,  ...,  0.1015,  0.0442,  0.0624]]),\n",
       " tensor([[-0.0160, -0.0502,  0.0137,  ..., -0.0987,  0.0339, -0.1349]]),\n",
       " tensor([[ 0.1104, -0.0121,  0.0653,  ..., -0.2196,  0.2539, -0.0091]]),\n",
       " tensor([[ 0.1552,  0.0198,  0.1070,  ..., -0.0692, -0.0140, -0.1665]]),\n",
       " tensor([[-0.0224, -0.0146, -0.0482,  ..., -0.0318, -0.0450, -0.2132]]),\n",
       " tensor([[-0.0997,  0.0707,  0.0728,  ..., -0.0825, -0.1101, -0.0489]]),\n",
       " tensor([[ 0.0030, -0.1590, -0.0031,  ..., -0.0141, -0.0795, -0.0726]]),\n",
       " tensor([[-0.0218, -0.0125, -0.0651,  ...,  0.0955, -0.0208, -0.0612]]),\n",
       " tensor([[-0.0412,  0.0002, -0.0572,  ...,  0.0686, -0.1083,  0.0764]]),\n",
       " tensor([[-0.0969, -0.0777, -0.0557,  ...,  0.0320,  0.1892, -0.0620]]),\n",
       " tensor([[-0.0448,  0.0196, -0.0542,  ...,  0.0288, -0.0969,  0.1334]]),\n",
       " tensor([[-0.0419, -0.0780,  0.0226,  ..., -0.1725,  0.0453, -0.0711]]),\n",
       " tensor([[-0.3100, -0.0971, -0.0561,  ..., -0.1602,  0.0923, -0.0548]]),\n",
       " tensor([[-0.0399, -0.0982, -0.0311,  ..., -0.0244, -0.0221, -0.0158]]),\n",
       " tensor([[-0.0308, -0.0054, -0.0628,  ..., -0.0698,  0.1482, -0.1006]]),\n",
       " tensor([[ 0.0587, -0.0327,  0.0357,  ..., -0.1032,  0.0615, -0.0262]]),\n",
       " tensor([[-0.0100, -0.0882,  0.1206,  ..., -0.1135,  0.0168, -0.0928]]),\n",
       " tensor([[-0.0171, -0.0414,  0.0102,  ..., -0.0976,  0.0238, -0.0828]]),\n",
       " tensor([[-0.0196, -0.0022, -0.0557,  ..., -0.1795,  0.0393, -0.1145]]),\n",
       " tensor([[-0.0200, -0.0779,  0.0128,  ..., -0.1266, -0.1120, -0.0486]]),\n",
       " tensor([[-0.0100, -0.0625,  0.0152,  ..., -0.2734,  0.1800, -0.2391]]),\n",
       " tensor([[-0.0515,  0.0047, -0.0561,  ..., -0.1234,  0.1348, -0.0813]]),\n",
       " tensor([[-0.2388, -0.0640, -0.2130,  ...,  0.0574,  0.1850, -0.0634]]),\n",
       " tensor([[-0.0928,  0.0557,  0.0091,  ..., -0.0431, -0.0371, -0.1372]]),\n",
       " tensor([[-0.1502,  0.0168, -0.0871,  ..., -0.0647,  0.1041, -0.0014]]),\n",
       " tensor([[-0.1122, -0.0542,  0.0193,  ..., -0.1765,  0.1249, -0.0847]]),\n",
       " tensor([[-0.3846, -0.0627, -0.0856,  ..., -0.0855,  0.1096, -0.0921]]),\n",
       " tensor([[-0.0876,  0.0413, -0.0107,  ..., -0.1454,  0.1014,  0.0426]]),\n",
       " tensor([[-0.1357,  0.0778, -0.0824,  ..., -0.1086, -0.1759, -0.1085]]),\n",
       " tensor([[-0.0330, -0.0415,  0.0688,  ...,  0.0219, -0.0968, -0.1070]]),\n",
       " tensor([[-0.0712,  0.0067,  0.0188,  ..., -0.2011,  0.1035, -0.1234]]),\n",
       " tensor([[-0.2468, -0.0506, -0.6130,  ..., -0.1878, -0.0038, -0.1279]]),\n",
       " tensor([[-0.0562, -0.0882, -0.0261,  ..., -0.0546, -0.0308, -0.0734]]),\n",
       " tensor([[-0.2276, -0.2360, -0.0678,  ..., -0.0563, -0.1289, -0.1410]]),\n",
       " tensor([[-0.1521,  0.0887,  0.0777,  ..., -0.0904,  0.0082, -0.0968]]),\n",
       " tensor([[-0.0225, -0.0089, -0.0521,  ..., -0.1878,  0.0739,  0.1807]]),\n",
       " tensor([[-0.0017,  0.0299, -0.0183,  ...,  0.0332,  0.0045, -0.0425]]),\n",
       " tensor([[-0.1064, -0.0478,  0.0030,  ..., -0.0192,  0.1085, -0.0754]]),\n",
       " tensor([[-0.0934, -0.0418,  0.0096,  ..., -0.0546, -0.1253, -0.1315]]),\n",
       " tensor([[-0.0708,  0.0671, -0.0637,  ..., -0.1617, -0.0468, -0.1357]]),\n",
       " tensor([[-0.1021, -0.1219, -0.0099,  ..., -0.0741, -0.1080, -0.1431]]),\n",
       " tensor([[-0.0155, -0.0720,  0.0075,  ..., -0.0735,  0.0845, -0.0413]]),\n",
       " tensor([[-0.0781,  0.0383, -0.0060,  ..., -0.0245, -0.0878, -0.0448]]),\n",
       " tensor([[-0.0143, -0.0702,  0.0062,  ..., -0.2393,  0.1226, -0.0989]]),\n",
       " tensor([[-0.0478, -0.1041, -0.0510,  ..., -0.1852,  0.0436, -0.0653]]),\n",
       " tensor([[-0.0163, -0.0071, -0.0554,  ..., -0.1551, -0.0654, -0.1400]]),\n",
       " tensor([[ 0.0030, -0.0889,  0.1355,  ...,  0.0013, -0.0689, -0.1502]]),\n",
       " tensor([[-0.0172, -0.0736,  0.0136,  ..., -0.0776, -0.0602, -0.0049]]),\n",
       " tensor([[-0.0512,  0.0040, -0.0604,  ...,  0.2320, -0.0305, -0.2366]]),\n",
       " tensor([[ 0.0992, -0.1211,  0.0787,  ..., -0.0089, -0.0412, -0.2181]]),\n",
       " tensor([[ 0.1741,  0.1035,  0.1091,  ..., -0.0873,  0.0088,  0.1374]])]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "inter_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-20 16:13:28,144 https://raw.githubusercontent.com/UniversalDependencies/UD_English-EWT/master/en_ewt-ud-dev.conllu not found in cache, downloading to /tmp/tmpk6qgnfvm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1667872B [00:00, 22522954.83B/s]         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-20 16:13:28,314 copying /tmp/tmpk6qgnfvm to cache at /home/snie/.flair/datasets/ud_english/en_ewt-ud-dev.conllu\n",
      "2019-02-20 16:13:28,317 removing temp file /tmp/tmpk6qgnfvm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-20 16:13:28,635 https://raw.githubusercontent.com/UniversalDependencies/UD_English-EWT/master/en_ewt-ud-test.conllu not found in cache, downloading to /tmp/tmp4_peid4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1661693B [00:00, 16564735.51B/s]         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-20 16:13:28,837 copying /tmp/tmp4_peid4s to cache at /home/snie/.flair/datasets/ud_english/en_ewt-ud-test.conllu\n",
      "2019-02-20 16:13:28,840 removing temp file /tmp/tmp4_peid4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-20 16:13:29,553 https://raw.githubusercontent.com/UniversalDependencies/UD_English-EWT/master/en_ewt-ud-train.conllu not found in cache, downloading to /tmp/tmp73b0827p\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13301153B [00:00, 53427017.37B/s]         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-20 16:13:29,881 copying /tmp/tmp73b0827p to cache at /home/snie/.flair/datasets/ud_english/en_ewt-ud-train.conllu\n",
      "2019-02-20 16:13:29,889 removing temp file /tmp/tmp73b0827p\n",
      "2019-02-20 16:13:29,890 Reading data from /home/snie/.flair/datasets/ud_english\n",
      "2019-02-20 16:13:29,890 Train: /home/snie/.flair/datasets/ud_english/en_ewt-ud-train.conllu\n",
      "2019-02-20 16:13:29,891 Dev: /home/snie/.flair/datasets/ud_english/en_ewt-ud-dev.conllu\n",
      "2019-02-20 16:13:29,891 Test: /home/snie/.flair/datasets/ud_english/en_ewt-ud-test.conllu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "corpus: TaggedCorpus = NLPTaskDataFetcher.load_corpus(NLPTask.UD_ENGLISH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = corpus.train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Al <NNP> - <HYPH> Zaman <NNP> : <:> American <JJ> forces <NNS> killed <VBD> Shaikh <NNP> Abdullah <NNP> al <NNP> - <HYPH> Ani <NNP> , <,> the <DT> preacher <NN> at <IN> the <DT> mosque <NN> in <IN> the <DT> town <NN> of <IN> Qaim <NNP> , <,> near <IN> the <DT> Syrian <JJ> border <NN> . <.>'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.to_tagged_string('pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-20 16:19:54,682 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/models-v0.4/release-dodekapos-512-l2-multi/pos-multi-v0.1.pt not found in cache, downloading to /tmp/tmpmkvm3hyv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 314055714/314055714 [01:13<00:00, 4268088.76B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-20 16:21:08,792 copying /tmp/tmpmkvm3hyv to cache at /home/snie/.flair/models/pos-multi-v0.1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-20 16:21:08,987 removing temp file /tmp/tmpmkvm3hyv\n"
     ]
    }
   ],
   "source": [
    "pos_tagger = SequenceTagger.load('pos-multi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceTagger(\n",
       "  (embeddings): StackedEmbeddings(\n",
       "    (list_embedding_0): FlairEmbeddings(\n",
       "      (lm): LanguageModel(\n",
       "        (drop): Dropout(p=0.5)\n",
       "        (encoder): Embedding(300, 100)\n",
       "        (rnn): LSTM(100, 2048)\n",
       "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (list_embedding_1): FlairEmbeddings(\n",
       "      (lm): LanguageModel(\n",
       "        (drop): Dropout(p=0.5)\n",
       "        (encoder): Embedding(300, 100)\n",
       "        (rnn): LSTM(100, 2048)\n",
       "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (word_dropout): WordDropout()\n",
       "  (locked_dropout): LockedDropout()\n",
       "  (embedding2nn): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (rnn): LSTM(4096, 512, num_layers=2, dropout=0.5, bidirectional=True)\n",
       "  (linear): Linear(in_features=1024, out_features=21, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = corpus.test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence: \"What if Google expanded on its search - engine ( and now e-mail ) wares into a full - fledged operating system ?\" - 23 Tokens]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tagger.predict(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What <what/PRON/WP/root/Int> if <if/SCONJ/IN/mark> Google <Google/PROPN/NNP/nsubj/Sing> expanded <expand/VERB/VBD/advcl/Ind/Past/Fin> on <on/ADP/IN/case> its <its/PRON/PRP$/nmod:poss/Neut/Sing/3/Yes/Prs> search <search/NOUN/NN/compound/Sing> - <-/PUNCT/HYPH/punct> engine <engine/NOUN/NN/compound/Sing> ( <(/PUNCT/-LRB-/punct> and <and/CCONJ/CC/cc> now <now/ADV/RB/advmod> e-mail <e-mail/NOUN/NN/conj/Sing> ) <)/PUNCT/-RRB-/punct> wares <wares/VERB/NNS/obl/Plur> into <into/ADP/IN/case> a <a/DET/DT/det/Ind/Art> full <full/ADJ/RB/advmod> - <-/PUNCT/HYPH/punct> fledged <fledged/VERB/JJ/amod/Pos> operating <operating/NOUN/NN/compound/Sing> system <system/NOUN/NN/obl/Sing> ? <?/PUNCT/./punct>'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.to_tagged_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.to_dict(tag_type='ner')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
