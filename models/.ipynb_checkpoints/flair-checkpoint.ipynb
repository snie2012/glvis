{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "from flair.models import TextClassifier\n",
    "\n",
    "from flair.data import TaggedCorpus\n",
    "from flair.data_fetcher import  NLPTaskDataFetcher, NLPTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Mongo database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient()\n",
    "\n",
    "db = client['glvis_db']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract hidden representations from flair's pretrained NER model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-18 16:23:11,508 loading file /home/snie/.flair/models/en-ner-conll03-v0.4.pt\n"
     ]
    }
   ],
   "source": [
    "ner = SequenceTagger.load('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-18 16:23:14,525 Reading data from data/conll/conll_03\n",
      "2019-03-18 16:23:14,526 Train: data/conll/conll_03/eng.train\n",
      "2019-03-18 16:23:14,526 Dev: data/conll/conll_03/eng.testa\n",
      "2019-03-18 16:23:14,527 Test: data/conll/conll_03/eng.testb\n"
     ]
    }
   ],
   "source": [
    "corpus = NLPTaskDataFetcher.load_corpus(NLPTask.CONLL_03, base_path='data/conll/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22137"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus.get_all_sentences())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "db['flair_ner'].drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sentence in enumerate(corpus.get_all_sentences()):\n",
    "    print(f'Start sentence {i}')\n",
    "    \n",
    "    # Define hook to get intermediate values\n",
    "    hidden_states = torch.zeros(len(sentence), 1, 512)\n",
    "    def hook(m, i):\n",
    "        hidden_states.copy_(i[0].data)\n",
    "                                \n",
    "    h = ner.linear.register_forward_pre_hook(hook)\n",
    "                                \n",
    "    ner.predict(sentence)\n",
    "                                \n",
    "    spans = sentence.get_spans('ner')\n",
    "                                \n",
    "    # Informaction to store: the named entities, their predicted labels, probabilities and hidden states\n",
    "    # If there are multiple words for one entity, take the average value of hidden states\n",
    "    # and record the number of words in the entity\n",
    "    \n",
    "    for span in spans:\n",
    "        entry = {}\n",
    "        entry['text'] = span.text\n",
    "        entry['tag'] = span.tag\n",
    "        entry['score'] = span.score\n",
    "        entry['token_num'] = len(span.tokens)\n",
    "        \n",
    "        idx = [token.idx-1 for token in span.tokens]\n",
    "        entry['linear_layer_state'] = hidden_states[idx, :, :].mean(dim=0).squeeze().tolist()\n",
    "        \n",
    "        db['flair_ner'].insert_one(entry)\n",
    "    \n",
    "    h.remove()\n",
    "    \n",
    "    print(f'Finish sentence {i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract hidden states from pretrained en-sentiment model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos = os.listdir('data/aclImdb_v1/aclImdb/train/pos/')\n",
    "train_neg = os.listdir('data/aclImdb_v1/aclImdb/train/neg/')\n",
    "test_pos = os.listdir('data/aclImdb_v1/aclImdb/test/pos/')\n",
    "test_neg = os.listdir('data/aclImdb_v1/aclImdb/test/neg/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_data = []\n",
    "for name in train_pos:\n",
    "    with open('data/aclImdb_v1/aclImdb/train/pos/' + name, 'r') as f:\n",
    "        pos_data.append(f.readline())\n",
    "for name in test_pos:\n",
    "    with open('data/aclImdb_v1/aclImdb/test/pos/' + name, 'r') as f:\n",
    "        pos_data.append(f.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_data = []\n",
    "for name in train_neg:\n",
    "    with open('data/aclImdb_v1/aclImdb/train/neg/' + name, 'r') as f:\n",
    "        neg_data.append(f.readline())\n",
    "for name in test_neg:\n",
    "    with open('data/aclImdb_v1/aclImdb/test/neg/' + name, 'r') as f:\n",
    "        neg_data.append(f.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_model = TextClassifier.load('en-sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set batch size\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hook to get intermediate values\n",
    "records = torch.zeros(batch_size, 2048)\n",
    "\n",
    "def hook(m, i, o):\n",
    "    print(i[0].data.shape)\n",
    "    records.copy_(i[0].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the hook to model\n",
    "h = sent_model.decoder.register_forward_hook(hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390.625"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_data) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(neg_data) // batch_size):\n",
    "    sentences = [Sentence(s) for s in neg_data[batch_size * i: batch_size * (i+1)]]\n",
    "    sent_model.predict(sentences, mini_batch_size=batch_size)\n",
    "    labels = [sen.labels[0].to_dict() for sen in sentences]\n",
    "    \n",
    "    val_list = records.tolist()\n",
    "    \n",
    "    db_entries = [{\n",
    "        'sentence': neg_data[batch_size * i + ix],\n",
    "        'reduce_mean': val_list[ix],\n",
    "        'label': labels[ix]\n",
    "    } for ix in range(len(sentences))]\n",
    "    \n",
    "    val_collection.insert_many(db_entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flattened val_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rec in val_collection.find():\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'value': 'POSITIVE', 'confidence': 1.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_fields = [\n",
    "    {'$addFields': {'sentiment': '$label.value', 'confidence': '$label.confidence'}},\n",
    "    {'$out': 'flattened'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened = db['flattened']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.UpdateResult at 0x7f4fd14ab9c8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete label fields in the document store\n",
    "flattened.update_many({}, {'$unset': {'label': ''}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add index to val_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sentence_text'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_collection.create_index([('sentence', pymongo.TEXT)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'confidence_1'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_collection.create_index([('confidence', 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sentiment_1'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_collection.create_index('sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test search on the index\n",
    "cur = val_collection.find({\n",
    "    '$and': [\n",
    "        {'$text': {'$search': 'happy'}}, \n",
    "        {'sentiment': 'NEGATIVE'},\n",
    "        {'confidence': {'$eq': 1.0}}\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(cur))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play with database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(term):\n",
    "    pipeline = {\n",
    "        '$text': {'$search': term}\n",
    "    }\n",
    "\n",
    "    return list(val_collection.find(pipeline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = query('\\\"movie\\\"\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = np.array([elm['val'] for elm in res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(vectors, axis=0)\n",
    "std = np.mean(vectors, axis=0)\n",
    "stats = [\n",
    "    {\n",
    "        'dim': i,\n",
    "        'mean': val[0],\n",
    "        'std': val[1]\n",
    "    } for i, val in enumerate(zip(mean, std))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [\n",
    "    {\"$group\": {\"_id\": \"$sentence\", \"count\": {\"$sum\": 1}}},\n",
    "    {\"$match\": {\"count\": {\"$gt\": 1 }}}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = val_collection.aggregate(pipeline, allowDiskUse=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
