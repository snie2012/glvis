{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "from flair.models import TextClassifier\n",
    "\n",
    "from flair.data import TaggedCorpus\n",
    "from flair.data_fetcher import  NLPTaskDataFetcher, NLPTask\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient()\n",
    "\n",
    "db = client['glvis_db']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract hidden representations from flair's pretrained NER model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-23 17:18:52,068 loading file /home/snie/.flair/models/en-ner-conll03-v0.4.pt\n"
     ]
    }
   ],
   "source": [
    "ner_tagger = SequenceTagger.load('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceTagger(\n",
       "  (embeddings): StackedEmbeddings(\n",
       "    (list_embedding_0): WordEmbeddings()\n",
       "    (list_embedding_1): FlairEmbeddings(\n",
       "      (lm): LanguageModel(\n",
       "        (drop): Dropout(p=0.05)\n",
       "        (encoder): Embedding(300, 100)\n",
       "        (rnn): LSTM(100, 2048)\n",
       "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (list_embedding_2): FlairEmbeddings(\n",
       "      (lm): LanguageModel(\n",
       "        (drop): Dropout(p=0.05)\n",
       "        (encoder): Embedding(300, 100)\n",
       "        (rnn): LSTM(100, 2048)\n",
       "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (word_dropout): WordDropout()\n",
       "  (locked_dropout): LockedDropout()\n",
       "  (embedding2nn): Linear(in_features=4196, out_features=4196, bias=True)\n",
       "  (rnn): LSTM(4196, 256, bidirectional=True)\n",
       "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-23 17:19:06,783 Reading data from data/conll/conll_03\n",
      "2019-03-23 17:19:06,784 Train: data/conll/conll_03/eng.train\n",
      "2019-03-23 17:19:06,784 Dev: data/conll/conll_03/eng.testa\n",
      "2019-03-23 17:19:06,784 Test: data/conll/conll_03/eng.testb\n"
     ]
    }
   ],
   "source": [
    "corpus = NLPTaskDataFetcher.load_corpus(NLPTask.CONLL_03, base_path='data/conll/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_dictionary = corpus.make_tag_dictionary(tag_type='ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22137"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus.get_all_sentences())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_col = db['flair_ner_embedding2nn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_col.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sentence in enumerate(corpus.get_all_sentences()):\n",
    "    print(f'Start sentence {i}')\n",
    "    \n",
    "    # Define hook to get intermediate values\n",
    "    hidden_states = torch.zeros(len(sentence), 1, 4196)\n",
    "    def hook(m, i):\n",
    "        hidden_states.copy_(i[0].data)\n",
    "                                \n",
    "    h = ner_tagger.embedding2nn.register_forward_pre_hook(hook)\n",
    "                                \n",
    "    ner_tagger.predict(sentence)\n",
    "                                \n",
    "    spans = sentence.get_spans('ner')\n",
    "                                \n",
    "    # Informaction to store: the named entities, their predicted labels, probabilities and hidden states\n",
    "    # If there are multiple words for one entity, take the average value of hidden states\n",
    "    # and record the number of words in the entity\n",
    "    \n",
    "    for span in spans:\n",
    "        entry = {}\n",
    "        entry['text'] = span.text\n",
    "        entry['tag'] = span.tag\n",
    "        entry['score'] = span.score\n",
    "        entry['token_num'] = len(span.tokens)\n",
    "        \n",
    "        idx = [token.idx-1 for token in span.tokens]\n",
    "        entry['embedding2nn'] = hidden_states[idx, :, :].mean(dim=0).squeeze().tolist()\n",
    "        \n",
    "        db_col.insert_one(entry)\n",
    "    \n",
    "    h.remove()\n",
    "    \n",
    "    print(f'Finish sentence {i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_col = db['flair_ner_linear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sentence in enumerate(corpus.get_all_sentences()):\n",
    "    print(f'Start sentence {i}')\n",
    "    \n",
    "    # Define hook to get intermediate values\n",
    "    hidden_states = torch.zeros(len(sentence), 1, 512)\n",
    "    def hook(m, i):\n",
    "        hidden_states.copy_(i[0].data)\n",
    "                                \n",
    "    h = ner_tagger.linear.register_forward_pre_hook(hook)\n",
    "                                \n",
    "    ner_tagger.predict(sentence)\n",
    "                                \n",
    "    spans = sentence.get_spans('ner')\n",
    "                                \n",
    "    # Informaction to store: the named entities, their predicted labels, probabilities and hidden states\n",
    "    # If there are multiple words for one entity, take the average value of hidden states\n",
    "    # and record the number of words in the entity\n",
    "    \n",
    "    for span in spans:\n",
    "        entry = {}\n",
    "        entry['text'] = span.text\n",
    "        entry['tag'] = span.tag\n",
    "        entry['score'] = span.score\n",
    "        entry['token_num'] = len(span.tokens)\n",
    "        \n",
    "        idx = [token.idx-1 for token in span.tokens]\n",
    "        entry['linear_layer_state'] = hidden_states[idx, :, :].mean(dim=0).squeeze().tolist()\n",
    "        \n",
    "        db_col.insert_one(entry)\n",
    "    \n",
    "    h.remove()\n",
    "    \n",
    "    print(f'Finish sentence {i}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
