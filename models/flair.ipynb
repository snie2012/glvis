{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "from flair.models import TextClassifier\n",
    "\n",
    "from flair.data import TaggedCorpus\n",
    "from flair.data_fetcher import  NLPTaskDataFetcher, NLPTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to modify learned represention and use partial model to make predictionsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-23 10:41:04,089 loading file /home/snie/.flair/models/en-chunk-conll2000-v0.2.pt\n"
     ]
    }
   ],
   "source": [
    "tagger = SequenceTagger.load('chunk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceTagger(\n",
       "  (embeddings): StackedEmbeddings(\n",
       "    (list_embedding_0): CharLMEmbeddings(\n",
       "      (lm): LanguageModel(\n",
       "        (drop): Dropout(p=0.25)\n",
       "        (encoder): Embedding(227, 100)\n",
       "        (rnn): LSTM(100, 2048)\n",
       "        (decoder): Linear(in_features=2048, out_features=227, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (list_embedding_1): CharLMEmbeddings(\n",
       "      (lm): LanguageModel(\n",
       "        (drop): Dropout(p=0.25)\n",
       "        (encoder): Embedding(227, 100)\n",
       "        (rnn): LSTM(100, 2048)\n",
       "        (decoder): Linear(in_features=2048, out_features=227, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (embedding2nn): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (rnn): LSTM(4096, 256, bidirectional=True)\n",
       "  (linear): Linear(in_features=512, out_features=45, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method predict in module flair.models.sequence_tagger_model:\n",
      "\n",
      "predict(sentences:Union[List[flair.data.Sentence], flair.data.Sentence], mini_batch_size=32, verbose=False) -> List[flair.data.Sentence] method of flair.models.sequence_tagger_model.SequenceTagger instance\n",
      "    Predicts the labels/tags for the given list of sentences. The labels/tags are added directly to the\n",
      "    sentences.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tagger.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence: \"a b c\" - 3 Tokens]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.predict(Sentence('a b c'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tagger.linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=45, bias=True)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(t, './partial_models/flair_chunck_linear_layer.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('./partial_models/flair_chunck_linear_layer.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=45, bias=True)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3074,  3.0060,  3.7630, -4.7441,  3.5282, -0.3419,  1.1387,  1.6184,\n",
       "        -0.5954,  1.4467, -2.0640, -1.3344, -0.5230,  5.2574,  1.7556,  3.7739,\n",
       "         4.8887,  0.3100, -1.7064, -1.4568, -3.6022, -3.5891, -6.6334, -1.9965,\n",
       "        -0.4712,  3.6837,  0.0715,  0.4407,  1.6095, -0.6557, -0.7850, -0.1129,\n",
       "         1.0722, -0.0530, -1.8550, -2.8702,  0.5367, -1.2927,  0.6121, -1.5596,\n",
       "        -0.6297, -1.0897, -0.3128, -0.2445,  0.2355], device='cuda:0',\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.forward(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([45])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([45, 512])\n",
      "torch.Size([45])\n"
     ]
    }
   ],
   "source": [
    "for p in t.parameters():\n",
    "    print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceTagger(\n",
       "  (embeddings): StackedEmbeddings(\n",
       "    (list_embedding_0): CharLMEmbeddings(\n",
       "      (lm): LanguageModel(\n",
       "        (drop): Dropout(p=0.25)\n",
       "        (encoder): Embedding(275, 100)\n",
       "        (rnn): LSTM(100, 2048)\n",
       "        (decoder): Linear(in_features=2048, out_features=275, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (list_embedding_1): CharLMEmbeddings(\n",
       "      (lm): LanguageModel(\n",
       "        (drop): Dropout(p=0.25)\n",
       "        (encoder): Embedding(275, 100)\n",
       "        (rnn): LSTM(100, 2048)\n",
       "        (decoder): Linear(in_features=2048, out_features=275, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (embedding2nn): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (rnn): LSTM(4096, 256, bidirectional=True)\n",
       "  (linear): Linear(in_features=512, out_features=53, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceTagger(\n",
       "  (embeddings): StackedEmbeddings(\n",
       "    (list_embedding_0): WordEmbeddings()\n",
       "    (list_embedding_1): FlairEmbeddings(\n",
       "      (lm): LanguageModel(\n",
       "        (drop): Dropout(p=0.05)\n",
       "        (encoder): Embedding(300, 100)\n",
       "        (rnn): LSTM(100, 2048)\n",
       "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (list_embedding_2): FlairEmbeddings(\n",
       "      (lm): LanguageModel(\n",
       "        (drop): Dropout(p=0.05)\n",
       "        (encoder): Embedding(300, 100)\n",
       "        (rnn): LSTM(100, 2048)\n",
       "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (word_dropout): WordDropout()\n",
       "  (locked_dropout): LockedDropout()\n",
       "  (embedding2nn): Linear(in_features=4196, out_features=4196, bias=True)\n",
       "  (rnn): LSTM(4196, 256, bidirectional=True)\n",
       "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Mongo database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient()\n",
    "\n",
    "db = client['glvis_db']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4125"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(db['flair_chunk'].find({'text':'in'})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4657"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term = 'in'\n",
    "pipeline = {\n",
    "    '$text': {'$search': f'{term}'}\n",
    "}\n",
    "\n",
    "len(list(db['flair_chunk'].find(pipeline)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flattened val_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rec in val_collection.find():\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'value': 'POSITIVE', 'confidence': 1.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_fields = [\n",
    "    {'$addFields': {'sentiment': '$label.value', 'confidence': '$label.confidence'}},\n",
    "    {'$out': 'flattened'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened = db['flattened']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.UpdateResult at 0x7f4fd14ab9c8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete label fields in the document store\n",
    "flattened.update_many({}, {'$unset': {'label': ''}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add index to val_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_collection = db['glove_6b_300d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_collection.drop_index('word_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'word_text'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_collection.create_index([('word', pymongo.TEXT)], default_language='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test search on the index\n",
    "cur = val_collection.find({\n",
    "    '$and': [\n",
    "        {'$text': {'$search': 'happy'}}, \n",
    "        {'sentiment': 'NEGATIVE'},\n",
    "        {'confidence': {'$eq': 1.0}}\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(cur))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play with database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(term):\n",
    "    pipeline = {\n",
    "        '$text': {'$search': term}\n",
    "    }\n",
    "\n",
    "    return list(val_collection.find(pipeline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = query('\\\"movie\\\"\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = np.array([elm['val'] for elm in res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(vectors, axis=0)\n",
    "std = np.mean(vectors, axis=0)\n",
    "stats = [\n",
    "    {\n",
    "        'dim': i,\n",
    "        'mean': val[0],\n",
    "        'std': val[1]\n",
    "    } for i, val in enumerate(zip(mean, std))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [\n",
    "    {\"$group\": {\"_id\": \"$sentence\", \"count\": {\"$sum\": 1}}},\n",
    "    {\"$match\": {\"count\": {\"$gt\": 1 }}}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = val_collection.aggregate(pipeline, allowDiskUse=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
