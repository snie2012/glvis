{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "from flair.data import TaggedCorpus\n",
    "from flair.data_fetcher import  NLPTaskDataFetcher, NLPTask\n",
    "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings, PooledFlairEmbeddings\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.models import SequenceTagger\n",
    "from flair.trainers import ModelTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-19 14:11:07,683 Reading data from data/conll/conll_03\n",
      "2019-03-19 14:11:07,684 Train: data/conll/conll_03/eng.train\n",
      "2019-03-19 14:11:07,684 Dev: data/conll/conll_03/eng.testa\n",
      "2019-03-19 14:11:07,684 Test: data/conll/conll_03/eng.testb\n"
     ]
    }
   ],
   "source": [
    "# 1. get the corpus\n",
    "corpus: TaggedCorpus = NLPTaskDataFetcher.load_corpus(NLPTask.CONLL_03, base_path='data/conll/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. what tag do we want to predict?\n",
    "tag_type = 'ner'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. make the tag dictionary from the corpus\n",
    "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tag_dictionary.get_items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize embeddings\n",
    "embedding_types: List[TokenEmbeddings] = [\n",
    "\n",
    "    # GloVe embeddings\n",
    "    WordEmbeddings('glove'),\n",
    "\n",
    "    # contextual string embeddings, forward\n",
    "    PooledFlairEmbeddings('news-forward', pooling='min'),\n",
    "\n",
    "    # contextual string embeddings, backward\n",
    "    PooledFlairEmbeddings('news-backward', pooling='min'),\n",
    "]\n",
    "    \n",
    "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize sequence tagger\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n",
    "                                        embeddings=embeddings,\n",
    "                                        tag_dictionary=tag_dictionary,\n",
    "                                        tag_type=tag_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-18 11:06:45,677 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 11:06:45,678 Evaluation method: MICRO_F1_SCORE\n",
      "2019-03-18 11:06:45,681 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 11:06:46,012 epoch 1 - iter 0/469 - loss 51.74505234\n",
      "2019-03-18 11:06:59,899 epoch 1 - iter 46/469 - loss 8.69937993\n",
      "2019-03-18 11:07:15,242 epoch 1 - iter 92/469 - loss 6.07558875\n",
      "2019-03-18 11:07:29,950 epoch 1 - iter 138/469 - loss 4.96187749\n",
      "2019-03-18 11:07:44,680 epoch 1 - iter 184/469 - loss 4.32885280\n",
      "2019-03-18 11:07:59,758 epoch 1 - iter 230/469 - loss 3.93080213\n",
      "2019-03-18 11:08:14,099 epoch 1 - iter 276/469 - loss 3.59848609\n",
      "2019-03-18 11:08:32,749 epoch 1 - iter 322/469 - loss 3.34469179\n",
      "2019-03-18 11:08:58,957 epoch 1 - iter 368/469 - loss 3.13816058\n",
      "2019-03-18 11:09:24,363 epoch 1 - iter 414/469 - loss 2.95783206\n",
      "2019-03-18 11:09:49,964 epoch 1 - iter 460/469 - loss 2.81368828\n",
      "2019-03-18 11:09:54,863 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 11:09:54,864 EPOCH 1 done: loss 2.7937 - lr 0.1000 - bad epochs 0\n",
      "2019-03-18 11:10:56,195 DEV  : loss 1.00787163 - f-score 0.9007 - acc 0.8193\n",
      "2019-03-18 11:11:54,271 TEST : loss 1.02864516 - f-score 0.8787 - acc 0.7836\n",
      "2019-03-18 11:12:01,736 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 11:12:02,033 epoch 2 - iter 0/469 - loss 1.05996847\n",
      "2019-03-18 11:12:16,254 epoch 2 - iter 46/469 - loss 1.50500776\n",
      "2019-03-18 11:12:29,846 epoch 2 - iter 92/469 - loss 1.50006197\n",
      "2019-03-18 11:12:42,682 epoch 2 - iter 138/469 - loss 1.44028774\n",
      "2019-03-18 11:12:54,896 epoch 2 - iter 184/469 - loss 1.38282516\n",
      "2019-03-18 11:13:07,446 epoch 2 - iter 230/469 - loss 1.32988024\n",
      "2019-03-18 11:13:20,045 epoch 2 - iter 276/469 - loss 1.29404616\n",
      "2019-03-18 11:13:32,056 epoch 2 - iter 322/469 - loss 1.27839960\n",
      "2019-03-18 11:13:44,685 epoch 2 - iter 368/469 - loss 1.25687361\n",
      "2019-03-18 11:13:56,220 epoch 2 - iter 414/469 - loss 1.23019580\n",
      "2019-03-18 11:14:05,967 epoch 2 - iter 460/469 - loss 1.22030571\n",
      "2019-03-18 11:14:07,333 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 11:14:07,334 EPOCH 2 done: loss 1.2189 - lr 0.1000 - bad epochs 0\n",
      "2019-03-18 11:14:24,856 DEV  : loss 0.70841265 - f-score 0.9247 - acc 0.8599\n",
      "2019-03-18 11:14:40,665 TEST : loss 0.98235923 - f-score 0.8902 - acc 0.8021\n",
      "2019-03-18 11:14:47,403 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 11:14:47,590 epoch 3 - iter 0/469 - loss 1.46342111\n",
      "2019-03-18 11:14:55,186 epoch 3 - iter 46/469 - loss 1.10044867\n",
      "2019-03-18 11:15:02,730 epoch 3 - iter 92/469 - loss 1.03999202\n",
      "2019-03-18 11:15:10,263 epoch 3 - iter 138/469 - loss 1.00159775\n",
      "2019-03-18 11:15:18,940 epoch 3 - iter 184/469 - loss 1.02371521\n",
      "2019-03-18 11:15:26,725 epoch 3 - iter 230/469 - loss 1.04069934\n",
      "2019-03-18 11:15:34,588 epoch 3 - iter 276/469 - loss 1.02476699\n",
      "2019-03-18 11:15:42,275 epoch 3 - iter 322/469 - loss 1.00913955\n",
      "2019-03-18 11:15:49,933 epoch 3 - iter 368/469 - loss 1.00207137\n",
      "2019-03-18 11:15:57,312 epoch 3 - iter 414/469 - loss 0.98489503\n",
      "2019-03-18 11:16:05,062 epoch 3 - iter 460/469 - loss 0.97027418\n",
      "2019-03-18 11:16:06,386 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 11:16:06,387 EPOCH 3 done: loss 0.9697 - lr 0.1000 - bad epochs 0\n",
      "2019-03-18 11:16:24,481 DEV  : loss 0.57105291 - f-score 0.9366 - acc 0.8808\n",
      "2019-03-18 11:16:41,622 TEST : loss 0.78168035 - f-score 0.9118 - acc 0.8379\n",
      "2019-03-18 11:16:49,521 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 11:16:49,707 epoch 4 - iter 0/469 - loss 1.58726990\n",
      "2019-03-18 11:16:57,734 epoch 4 - iter 46/469 - loss 0.86042881\n",
      "2019-03-18 11:17:05,643 epoch 4 - iter 92/469 - loss 0.86169430\n",
      "2019-03-18 11:17:13,515 epoch 4 - iter 138/469 - loss 0.83842035\n",
      "2019-03-18 11:17:21,387 epoch 4 - iter 184/469 - loss 0.82457918\n",
      "2019-03-18 11:17:29,117 epoch 4 - iter 230/469 - loss 0.81709007\n",
      "2019-03-18 11:17:37,136 epoch 4 - iter 276/469 - loss 0.81860333\n",
      "2019-03-18 11:17:45,061 epoch 4 - iter 322/469 - loss 0.80434301\n",
      "2019-03-18 11:17:52,794 epoch 4 - iter 368/469 - loss 0.80031756\n",
      "2019-03-18 11:18:01,054 epoch 4 - iter 414/469 - loss 0.79962765\n",
      "2019-03-18 11:18:08,809 epoch 4 - iter 460/469 - loss 0.79707026\n",
      "2019-03-18 11:18:10,141 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 11:18:10,141 EPOCH 4 done: loss 0.7960 - lr 0.1000 - bad epochs 0\n",
      "2019-03-18 11:18:28,164 DEV  : loss 0.56596130 - f-score 0.9326 - acc 0.8737\n",
      "2019-03-18 11:18:44,730 TEST : loss 0.85249072 - f-score 0.9027 - acc 0.8226\n",
      "2019-03-18 11:18:51,857 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 11:18:52,080 epoch 5 - iter 0/469 - loss 0.85586286\n",
      "2019-03-18 11:18:59,740 epoch 5 - iter 46/469 - loss 0.75220783\n",
      "2019-03-18 11:19:07,408 epoch 5 - iter 92/469 - loss 0.75481508\n",
      "2019-03-18 11:19:15,066 epoch 5 - iter 138/469 - loss 0.73349498\n",
      "2019-03-18 11:19:22,663 epoch 5 - iter 184/469 - loss 0.73328557\n",
      "2019-03-18 11:19:30,478 epoch 5 - iter 230/469 - loss 0.71689996\n",
      "2019-03-18 11:19:37,994 epoch 5 - iter 276/469 - loss 0.70387867\n",
      "2019-03-18 11:19:45,554 epoch 5 - iter 322/469 - loss 0.71118442\n",
      "2019-03-18 11:19:53,063 epoch 5 - iter 368/469 - loss 0.70834995\n",
      "2019-03-18 11:20:00,700 epoch 5 - iter 414/469 - loss 0.70482484\n",
      "2019-03-18 11:20:08,355 epoch 5 - iter 460/469 - loss 0.69903277\n",
      "2019-03-18 11:20:09,625 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 11:20:09,626 EPOCH 5 done: loss 0.7009 - lr 0.1000 - bad epochs 0\n",
      "2019-03-18 11:20:27,257 DEV  : loss 0.51165992 - f-score 0.9395 - acc 0.8860\n",
      "2019-03-18 11:20:43,256 TEST : loss 0.77672225 - f-score 0.9161 - acc 0.8452\n",
      "2019-03-18 11:20:50,334 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 11:20:50,534 epoch 6 - iter 0/469 - loss 0.78833890\n",
      "2019-03-18 11:20:57,976 epoch 6 - iter 46/469 - loss 0.59841926\n",
      "2019-03-18 11:21:05,663 epoch 6 - iter 92/469 - loss 0.60251558\n",
      "2019-03-18 11:21:13,060 epoch 6 - iter 138/469 - loss 0.62872556\n",
      "2019-03-18 11:21:20,858 epoch 6 - iter 184/469 - loss 0.64764279\n",
      "2019-03-18 11:21:28,891 epoch 6 - iter 230/469 - loss 0.68373698\n",
      "2019-03-18 11:21:36,761 epoch 6 - iter 276/469 - loss 0.66301368\n",
      "2019-03-18 11:21:44,568 epoch 6 - iter 322/469 - loss 0.66705324\n",
      "2019-03-18 11:21:52,796 epoch 6 - iter 368/469 - loss 0.66301791\n",
      "2019-03-18 11:22:01,303 epoch 6 - iter 414/469 - loss 0.66273674\n",
      "2019-03-18 11:22:09,470 epoch 6 - iter 460/469 - loss 0.66372560\n",
      "2019-03-18 11:22:10,703 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 11:22:10,704 EPOCH 6 done: loss 0.6641 - lr 0.1000 - bad epochs 0\n",
      "2019-03-18 11:22:29,267 DEV  : loss 0.46664175 - f-score 0.9484 - acc 0.9020\n",
      "2019-03-18 11:22:46,361 TEST : loss 0.77614588 - f-score 0.9198 - acc 0.8515\n",
      "2019-03-18 11:22:54,753 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 11:22:54,965 epoch 7 - iter 0/469 - loss 0.47227064\n",
      "2019-03-18 11:23:02,874 epoch 7 - iter 46/469 - loss 0.58784202\n",
      "2019-03-18 11:23:10,558 epoch 7 - iter 92/469 - loss 0.57696377\n",
      "2019-03-18 11:23:18,080 epoch 7 - iter 138/469 - loss 0.57072538\n",
      "2019-03-18 11:23:25,885 epoch 7 - iter 184/469 - loss 0.58464447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-18 11:23:33,649 epoch 7 - iter 230/469 - loss 0.59033514\n",
      "2019-03-18 11:23:41,440 epoch 7 - iter 276/469 - loss 0.59070381\n",
      "2019-03-18 11:23:48,941 epoch 7 - iter 322/469 - loss 0.58665750\n",
      "2019-03-18 11:23:56,768 epoch 7 - iter 368/469 - loss 0.59065836\n",
      "2019-03-18 11:24:04,195 epoch 7 - iter 414/469 - loss 0.59350641\n",
      "2019-03-18 11:24:11,832 epoch 7 - iter 460/469 - loss 0.59794770\n",
      "2019-03-18 11:24:13,067 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 11:24:13,067 EPOCH 7 done: loss 0.5982 - lr 0.1000 - bad epochs 0\n",
      "2019-03-18 11:24:30,942 DEV  : loss 0.44104525 - f-score 0.9498 - acc 0.9044\n",
      "2019-03-18 11:24:47,245 TEST : loss 0.74859393 - f-score 0.9207 - acc 0.8531\n",
      "2019-03-18 11:24:54,732 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 11:24:54,915 epoch 8 - iter 0/469 - loss 0.38839477\n",
      "2019-03-18 11:25:02,469 epoch 8 - iter 46/469 - loss 0.57332006\n",
      "2019-03-18 11:25:10,209 epoch 8 - iter 92/469 - loss 0.52405907\n",
      "2019-03-18 11:25:17,742 epoch 8 - iter 138/469 - loss 0.51073872\n",
      "2019-03-18 11:25:25,364 epoch 8 - iter 184/469 - loss 0.50619640\n",
      "2019-03-18 11:25:32,802 epoch 8 - iter 230/469 - loss 0.50897623\n",
      "2019-03-18 11:25:40,665 epoch 8 - iter 276/469 - loss 0.50196804\n",
      "2019-03-18 11:25:48,713 epoch 8 - iter 322/469 - loss 0.51516469\n",
      "2019-03-18 11:25:56,336 epoch 8 - iter 368/469 - loss 0.51615148\n",
      "2019-03-18 11:26:04,291 epoch 8 - iter 414/469 - loss 0.52076854\n",
      "2019-03-18 11:26:12,097 epoch 8 - iter 460/469 - loss 0.53264763\n",
      "2019-03-18 11:26:13,274 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 11:26:13,274 EPOCH 8 done: loss 0.5332 - lr 0.1000 - bad epochs 0\n",
      "2019-03-18 11:26:31,268 DEV  : loss 0.45706421 - f-score 0.9493 - acc 0.9035\n",
      "2019-03-18 11:26:47,924 TEST : loss 0.76445484 - f-score 0.9189 - acc 0.8499\n",
      "2019-03-18 11:26:54,638 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 11:26:54,831 epoch 9 - iter 0/469 - loss 0.36189631\n",
      "2019-03-18 11:27:02,467 epoch 9 - iter 46/469 - loss 0.60028657\n",
      "2019-03-18 11:27:10,407 epoch 9 - iter 92/469 - loss 0.57182379\n",
      "2019-03-18 11:27:18,463 epoch 9 - iter 138/469 - loss 0.54657540\n",
      "2019-03-18 11:27:26,056 epoch 9 - iter 184/469 - loss 0.52786756\n",
      "2019-03-18 11:27:34,079 epoch 9 - iter 230/469 - loss 0.52033723\n",
      "2019-03-18 11:27:41,676 epoch 9 - iter 276/469 - loss 0.51430765\n",
      "2019-03-18 11:27:49,067 epoch 9 - iter 322/469 - loss 0.52268723\n",
      "2019-03-18 11:27:56,757 epoch 9 - iter 368/469 - loss 0.52402935\n",
      "2019-03-18 11:28:04,205 epoch 9 - iter 414/469 - loss 0.51974672\n",
      "2019-03-18 11:28:11,745 epoch 9 - iter 460/469 - loss 0.52126097\n",
      "2019-03-18 11:28:13,009 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 11:28:13,009 EPOCH 9 done: loss 0.5226 - lr 0.1000 - bad epochs 0\n",
      "2019-03-18 11:28:30,577 DEV  : loss 0.47271976 - f-score 0.9475 - acc 0.9003\n",
      "2019-03-18 11:28:47,481 TEST : loss 0.77212018 - f-score 0.9195 - acc 0.8509\n",
      "2019-03-18 11:28:54,121 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 11:28:54,315 epoch 10 - iter 0/469 - loss 0.70063841\n",
      "2019-03-18 11:29:01,925 epoch 10 - iter 46/469 - loss 0.42087649\n",
      "2019-03-18 11:29:09,423 epoch 10 - iter 92/469 - loss 0.43250939\n",
      "2019-03-18 11:29:17,136 epoch 10 - iter 138/469 - loss 0.41851985\n",
      "2019-03-18 11:29:25,105 epoch 10 - iter 184/469 - loss 0.45198704\n",
      "2019-03-18 11:29:32,989 epoch 10 - iter 230/469 - loss 0.45342665\n",
      "2019-03-18 11:29:41,074 epoch 10 - iter 276/469 - loss 0.45906999\n",
      "2019-03-18 11:29:49,046 epoch 10 - iter 322/469 - loss 0.46794351\n",
      "2019-03-18 11:29:56,731 epoch 10 - iter 368/469 - loss 0.48033408\n",
      "2019-03-18 11:30:04,486 epoch 10 - iter 414/469 - loss 0.48394437\n",
      "2019-03-18 11:30:12,221 epoch 10 - iter 460/469 - loss 0.49012087\n",
      "2019-03-18 11:30:13,471 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 11:30:13,472 EPOCH 10 done: loss 0.4918 - lr 0.1000 - bad epochs 0\n",
      "2019-03-18 11:30:32,295 DEV  : loss 0.43068114 - f-score 0.9491 - acc 0.9032\n",
      "2019-03-18 11:30:49,597 TEST : loss 0.78702950 - f-score 0.9190 - acc 0.8501\n",
      "2019-03-18 11:30:56,805 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 11:30:56,989 epoch 11 - iter 0/469 - loss 1.05033255\n",
      "2019-03-18 11:31:04,743 epoch 11 - iter 46/469 - loss 0.63844594\n",
      "2019-03-18 11:31:12,656 epoch 11 - iter 92/469 - loss 0.51493504\n",
      "2019-03-18 11:31:20,565 epoch 11 - iter 138/469 - loss 0.52010212\n",
      "2019-03-18 11:31:28,667 epoch 11 - iter 184/469 - loss 0.50903025\n",
      "2019-03-18 11:31:36,731 epoch 11 - iter 230/469 - loss 0.48555569\n",
      "2019-03-18 11:31:45,016 epoch 11 - iter 276/469 - loss 0.47920116\n",
      "2019-03-18 11:31:52,857 epoch 11 - iter 322/469 - loss 0.47739374\n",
      "2019-03-18 11:32:00,768 epoch 11 - iter 368/469 - loss 0.47321276\n",
      "2019-03-18 11:32:08,458 epoch 11 - iter 414/469 - loss 0.47143707\n",
      "2019-03-18 11:32:16,232 epoch 11 - iter 460/469 - loss 0.47173649\n",
      "2019-03-18 11:32:17,483 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 11:32:17,484 EPOCH 11 done: loss 0.4712 - lr 0.1000 - bad epochs 0\n",
      "2019-03-18 11:32:35,612 DEV  : loss 0.44730547 - f-score 0.9493 - acc 0.9035\n",
      "2019-03-18 11:32:52,230 TEST : loss 0.81264979 - f-score 0.9195 - acc 0.8510\n",
      "2019-03-18 11:32:59,443 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 11:32:59,606 epoch 12 - iter 0/469 - loss 0.14033905\n",
      "2019-03-18 11:33:07,987 epoch 12 - iter 46/469 - loss 0.40209523\n",
      "2019-03-18 11:33:16,100 epoch 12 - iter 92/469 - loss 0.45134341\n",
      "2019-03-18 11:33:24,197 epoch 12 - iter 138/469 - loss 0.46634933\n",
      "2019-03-18 11:33:32,212 epoch 12 - iter 184/469 - loss 0.46262893\n",
      "2019-03-18 11:33:40,235 epoch 12 - iter 230/469 - loss 0.44401762\n",
      "2019-03-18 11:33:48,316 epoch 12 - iter 276/469 - loss 0.44495870\n",
      "2019-03-18 11:33:56,423 epoch 12 - iter 322/469 - loss 0.44477533\n",
      "2019-03-18 11:34:04,342 epoch 12 - iter 368/469 - loss 0.44328835\n",
      "2019-03-18 11:34:13,044 epoch 12 - iter 414/469 - loss 0.44941522\n",
      "2019-03-18 11:34:21,141 epoch 12 - iter 460/469 - loss 0.45551766\n",
      "2019-03-18 11:34:22,431 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 11:34:22,432 EPOCH 12 done: loss 0.4541 - lr 0.1000 - bad epochs 0\n",
      "2019-03-18 11:34:41,112 DEV  : loss 0.50329334 - f-score 0.9440 - acc 0.8940\n",
      "2019-03-18 11:34:58,206 TEST : loss 0.83451349 - f-score 0.9224 - acc 0.8559\n",
      "2019-03-18 11:35:06,143 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 11:35:06,349 epoch 13 - iter 0/469 - loss 0.87730861\n",
      "2019-03-18 11:35:14,081 epoch 13 - iter 46/469 - loss 0.45863231\n",
      "2019-03-18 11:35:21,895 epoch 13 - iter 92/469 - loss 0.41135169\n",
      "2019-03-18 11:35:29,976 epoch 13 - iter 138/469 - loss 0.43622329\n",
      "2019-03-18 11:35:37,918 epoch 13 - iter 184/469 - loss 0.42412529\n",
      "2019-03-18 11:35:45,897 epoch 13 - iter 230/469 - loss 0.43567769\n",
      "2019-03-18 11:35:54,142 epoch 13 - iter 276/469 - loss 0.43906328\n",
      "2019-03-18 11:36:02,173 epoch 13 - iter 322/469 - loss 0.43606179\n",
      "2019-03-18 11:36:10,232 epoch 13 - iter 368/469 - loss 0.42975795\n",
      "2019-03-18 11:36:18,341 epoch 13 - iter 414/469 - loss 0.42761045\n",
      "2019-03-18 11:36:26,341 epoch 13 - iter 460/469 - loss 0.41733569\n",
      "2019-03-18 11:36:27,552 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 11:36:27,553 EPOCH 13 done: loss 0.4171 - lr 0.1000 - bad epochs 0\n",
      "2019-03-18 11:36:46,976 DEV  : loss 0.44132501 - f-score 0.9491 - acc 0.9031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-18 11:37:05,662 TEST : loss 0.78753442 - f-score 0.9223 - acc 0.8558\n",
      "2019-03-18 11:37:13,445 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 11:37:13,638 epoch 14 - iter 0/469 - loss 0.95461822\n",
      "2019-03-18 11:37:21,972 epoch 14 - iter 46/469 - loss 0.42554584\n",
      "2019-03-18 11:37:30,562 epoch 14 - iter 92/469 - loss 0.47763945\n",
      "2019-03-18 11:37:39,137 epoch 14 - iter 138/469 - loss 0.44756335\n",
      "2019-03-18 11:37:47,416 epoch 14 - iter 184/469 - loss 0.44916415\n",
      "2019-03-18 11:37:55,649 epoch 14 - iter 230/469 - loss 0.43655704\n",
      "2019-03-18 11:38:04,401 epoch 14 - iter 276/469 - loss 0.42842539\n",
      "2019-03-18 11:38:12,248 epoch 14 - iter 322/469 - loss 0.42567767\n",
      "2019-03-18 11:38:20,130 epoch 14 - iter 368/469 - loss 0.42326000\n",
      "2019-03-18 11:38:28,040 epoch 14 - iter 414/469 - loss 0.42724262\n",
      "2019-03-18 11:38:35,972 epoch 14 - iter 460/469 - loss 0.42453556\n",
      "2019-03-18 11:38:37,299 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 11:38:37,299 EPOCH 14 done: loss 0.4232 - lr 0.1000 - bad epochs 0\n",
      "2019-03-18 11:38:56,480 DEV  : loss 0.43633872 - f-score 0.9517 - acc 0.9079\n",
      "2019-03-18 11:39:13,440 TEST : loss 0.75936425 - f-score 0.9244 - acc 0.8595\n",
      "2019-03-18 11:39:13,442 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 11:39:13,651 epoch 15 - iter 0/469 - loss 0.92632514\n",
      "2019-03-18 11:39:21,696 epoch 15 - iter 46/469 - loss 0.43039691\n",
      "2019-03-18 11:39:29,929 epoch 15 - iter 92/469 - loss 0.41582164\n",
      "2019-03-18 11:39:37,832 epoch 15 - iter 138/469 - loss 0.40256523\n",
      "2019-03-18 11:39:45,720 epoch 15 - iter 184/469 - loss 0.41016504\n",
      "2019-03-18 11:39:53,649 epoch 15 - iter 230/469 - loss 0.40778349\n",
      "2019-03-18 11:40:01,813 epoch 15 - iter 276/469 - loss 0.42607773\n",
      "2019-03-18 11:40:10,049 epoch 15 - iter 322/469 - loss 0.41437255\n",
      "2019-03-18 11:40:18,317 epoch 15 - iter 368/469 - loss 0.41128503\n",
      "2019-03-18 11:40:26,412 epoch 15 - iter 414/469 - loss 0.41519510\n",
      "2019-03-18 11:40:34,466 epoch 15 - iter 460/469 - loss 0.41199520\n",
      "2019-03-18 11:40:35,656 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 11:40:35,657 EPOCH 15 done: loss 0.4121 - lr 0.1000 - bad epochs 1\n",
      "2019-03-18 11:40:54,726 DEV  : loss 0.41453338 - f-score 0.9550 - acc 0.9140\n",
      "2019-03-18 11:41:12,024 TEST : loss 0.75827140 - f-score 0.9247 - acc 0.8599\n",
      "2019-03-18 11:41:19,494 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 11:41:19,673 epoch 16 - iter 0/469 - loss 0.32576323\n",
      "2019-03-18 11:41:27,185 epoch 16 - iter 46/469 - loss 0.38268299\n",
      "2019-03-18 11:41:35,367 epoch 16 - iter 92/469 - loss 0.38426862\n",
      "2019-03-18 11:41:43,270 epoch 16 - iter 138/469 - loss 0.38198981\n",
      "2019-03-18 11:41:51,441 epoch 16 - iter 184/469 - loss 0.37892792\n",
      "2019-03-18 11:41:59,214 epoch 16 - iter 230/469 - loss 0.38646456\n",
      "2019-03-18 11:42:07,547 epoch 16 - iter 276/469 - loss 0.38291892\n",
      "2019-03-18 11:42:15,930 epoch 16 - iter 322/469 - loss 0.39349421\n",
      "2019-03-18 11:42:23,832 epoch 16 - iter 368/469 - loss 0.38826597\n",
      "2019-03-18 11:42:31,899 epoch 16 - iter 414/469 - loss 0.38865767\n",
      "2019-03-18 11:42:40,022 epoch 16 - iter 460/469 - loss 0.39003064\n",
      "2019-03-18 11:42:41,426 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 11:42:41,426 EPOCH 16 done: loss 0.3875 - lr 0.1000 - bad epochs 0\n",
      "2019-03-18 11:43:01,121 DEV  : loss 0.44817927 - f-score 0.9529 - acc 0.9102\n",
      "2019-03-18 11:43:17,933 TEST : loss 0.80416256 - f-score 0.9241 - acc 0.8589\n",
      "2019-03-18 11:43:25,130 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 11:43:25,361 epoch 17 - iter 0/469 - loss 0.44671133\n",
      "2019-03-18 11:43:33,025 epoch 17 - iter 46/469 - loss 0.38590203\n",
      "2019-03-18 11:43:40,995 epoch 17 - iter 92/469 - loss 0.38064666\n",
      "2019-03-18 11:43:48,868 epoch 17 - iter 138/469 - loss 0.39497240\n",
      "2019-03-18 11:43:56,713 epoch 17 - iter 184/469 - loss 0.39487184\n",
      "2019-03-18 11:44:04,957 epoch 17 - iter 230/469 - loss 0.37705720\n",
      "2019-03-18 11:44:13,170 epoch 17 - iter 276/469 - loss 0.37718227\n",
      "2019-03-18 11:44:20,989 epoch 17 - iter 322/469 - loss 0.36744602\n",
      "2019-03-18 11:44:28,930 epoch 17 - iter 368/469 - loss 0.37494819\n",
      "2019-03-18 11:44:37,142 epoch 17 - iter 414/469 - loss 0.38235363\n",
      "2019-03-18 11:44:45,171 epoch 17 - iter 460/469 - loss 0.38541262\n",
      "2019-03-18 11:44:46,495 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 11:44:46,496 EPOCH 17 done: loss 0.3855 - lr 0.1000 - bad epochs 0\n",
      "2019-03-18 11:45:04,957 DEV  : loss 0.41928765 - f-score 0.9567 - acc 0.9171\n",
      "2019-03-18 11:45:21,620 TEST : loss 0.82058090 - f-score 0.9234 - acc 0.8578\n",
      "2019-03-18 11:45:29,366 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 11:45:29,554 epoch 18 - iter 0/469 - loss 0.21884072\n",
      "2019-03-18 11:45:37,491 epoch 18 - iter 46/469 - loss 0.36965654\n",
      "2019-03-18 11:45:45,517 epoch 18 - iter 92/469 - loss 0.33800152\n",
      "2019-03-18 11:45:54,195 epoch 18 - iter 138/469 - loss 0.35400900\n",
      "2019-03-18 11:46:02,764 epoch 18 - iter 184/469 - loss 0.33741443\n",
      "2019-03-18 11:46:10,947 epoch 18 - iter 230/469 - loss 0.35323876\n",
      "2019-03-18 11:46:19,310 epoch 18 - iter 276/469 - loss 0.35771652\n",
      "2019-03-18 11:46:27,897 epoch 18 - iter 322/469 - loss 0.36457085\n",
      "2019-03-18 11:46:36,424 epoch 18 - iter 368/469 - loss 0.35969158\n",
      "2019-03-18 11:46:44,774 epoch 18 - iter 414/469 - loss 0.35542405\n",
      "2019-03-18 11:46:53,100 epoch 18 - iter 460/469 - loss 0.35981358\n",
      "2019-03-18 11:46:54,432 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 11:46:54,432 EPOCH 18 done: loss 0.3594 - lr 0.1000 - bad epochs 0\n",
      "2019-03-18 11:47:13,131 DEV  : loss 0.43265271 - f-score 0.9507 - acc 0.9061\n",
      "2019-03-18 11:47:31,190 TEST : loss 0.80903631 - f-score 0.9244 - acc 0.8595\n",
      "2019-03-18 11:47:38,448 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 11:47:38,633 epoch 19 - iter 0/469 - loss 0.29630500\n",
      "2019-03-18 11:47:46,879 epoch 19 - iter 46/469 - loss 0.34774110\n",
      "2019-03-18 11:47:54,950 epoch 19 - iter 92/469 - loss 0.31678247\n",
      "2019-03-18 11:48:02,725 epoch 19 - iter 138/469 - loss 0.31876223\n",
      "2019-03-18 11:48:10,768 epoch 19 - iter 184/469 - loss 0.33048620\n",
      "2019-03-18 11:48:19,019 epoch 19 - iter 230/469 - loss 0.33191626\n",
      "2019-03-18 11:48:27,130 epoch 19 - iter 276/469 - loss 0.33313344\n",
      "2019-03-18 11:48:35,166 epoch 19 - iter 322/469 - loss 0.33946640\n",
      "2019-03-18 11:48:43,350 epoch 19 - iter 368/469 - loss 0.34125748\n",
      "2019-03-18 11:48:51,315 epoch 19 - iter 414/469 - loss 0.34099923\n",
      "2019-03-18 11:48:59,487 epoch 19 - iter 460/469 - loss 0.34550514\n",
      "2019-03-18 11:49:00,755 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 11:49:00,756 EPOCH 19 done: loss 0.3470 - lr 0.1000 - bad epochs 0\n",
      "2019-03-18 11:49:19,892 DEV  : loss 0.44133639 - f-score 0.9521 - acc 0.9086\n",
      "2019-03-18 11:49:37,853 TEST : loss 0.89989382 - f-score 0.9196 - acc 0.8512\n",
      "2019-03-18 11:49:44,604 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 11:49:44,837 epoch 20 - iter 0/469 - loss 0.13424143\n",
      "2019-03-18 11:49:52,810 epoch 20 - iter 46/469 - loss 0.37929838\n",
      "2019-03-18 11:50:00,807 epoch 20 - iter 92/469 - loss 0.35559203\n",
      "2019-03-18 11:50:08,566 epoch 20 - iter 138/469 - loss 0.36258165\n",
      "2019-03-18 11:50:16,789 epoch 20 - iter 184/469 - loss 0.36038347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-18 11:50:24,593 epoch 20 - iter 230/469 - loss 0.36013642\n",
      "2019-03-18 11:50:32,596 epoch 20 - iter 276/469 - loss 0.35544942\n",
      "2019-03-18 11:50:40,485 epoch 20 - iter 322/469 - loss 0.35883499\n",
      "2019-03-18 11:50:48,324 epoch 20 - iter 368/469 - loss 0.35829297\n",
      "2019-03-18 11:50:56,288 epoch 20 - iter 414/469 - loss 0.35213511\n",
      "2019-03-18 11:51:04,402 epoch 20 - iter 460/469 - loss 0.35135429\n",
      "2019-03-18 11:51:05,721 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 11:51:05,722 EPOCH 20 done: loss 0.3546 - lr 0.1000 - bad epochs 0\n",
      "2019-03-18 11:51:23,927 DEV  : loss 0.43367520 - f-score 0.9539 - acc 0.9119\n",
      "2019-03-18 11:51:40,992 TEST : loss 0.83103889 - f-score 0.9253 - acc 0.8610\n",
      "2019-03-18 11:51:40,995 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 11:51:41,183 epoch 21 - iter 0/469 - loss 0.39662588\n",
      "2019-03-18 11:51:48,862 epoch 21 - iter 46/469 - loss 0.33890030\n",
      "2019-03-18 11:51:56,927 epoch 21 - iter 92/469 - loss 0.31526083\n",
      "2019-03-18 11:52:04,729 epoch 21 - iter 138/469 - loss 0.30563855\n",
      "2019-03-18 11:52:12,712 epoch 21 - iter 184/469 - loss 0.32865710\n",
      "2019-03-18 11:52:21,163 epoch 21 - iter 230/469 - loss 0.32365546\n",
      "2019-03-18 11:52:29,105 epoch 21 - iter 276/469 - loss 0.33591589\n",
      "2019-03-18 11:52:36,758 epoch 21 - iter 322/469 - loss 0.33379660\n",
      "2019-03-18 11:52:44,509 epoch 21 - iter 368/469 - loss 0.33497507\n",
      "2019-03-18 11:52:52,097 epoch 21 - iter 414/469 - loss 0.32992783\n",
      "2019-03-18 11:52:59,653 epoch 21 - iter 460/469 - loss 0.32555997\n",
      "2019-03-18 11:53:00,912 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 11:53:00,913 EPOCH 21 done: loss 0.3272 - lr 0.1000 - bad epochs 1\n",
      "2019-03-18 11:53:19,707 DEV  : loss 0.46407780 - f-score 0.9514 - acc 0.9073\n",
      "2019-03-18 11:53:36,682 TEST : loss 0.90629339 - f-score 0.9212 - acc 0.8540\n",
      "2019-03-18 11:53:44,364 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 11:53:44,559 epoch 22 - iter 0/469 - loss 0.40796927\n",
      "2019-03-18 11:53:52,647 epoch 22 - iter 46/469 - loss 0.34219987\n",
      "2019-03-18 11:54:00,294 epoch 22 - iter 92/469 - loss 0.35165603\n",
      "2019-03-18 11:54:08,107 epoch 22 - iter 138/469 - loss 0.33876623\n",
      "2019-03-18 11:54:15,895 epoch 22 - iter 184/469 - loss 0.33945219\n",
      "2019-03-18 11:54:23,558 epoch 22 - iter 230/469 - loss 0.33514617\n",
      "2019-03-18 11:54:31,255 epoch 22 - iter 276/469 - loss 0.33565015\n",
      "2019-03-18 11:54:39,195 epoch 22 - iter 322/469 - loss 0.33032674\n",
      "2019-03-18 11:54:47,073 epoch 22 - iter 368/469 - loss 0.33042069\n",
      "2019-03-18 11:54:54,797 epoch 22 - iter 414/469 - loss 0.33202370\n",
      "2019-03-18 11:55:02,710 epoch 22 - iter 460/469 - loss 0.33642933\n",
      "2019-03-18 11:55:03,942 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 11:55:03,942 EPOCH 22 done: loss 0.3372 - lr 0.1000 - bad epochs 0\n",
      "2019-03-18 11:55:21,666 DEV  : loss 0.47979560 - f-score 0.9507 - acc 0.9060\n",
      "2019-03-18 11:55:37,758 TEST : loss 0.90551323 - f-score 0.9170 - acc 0.8468\n",
      "2019-03-18 11:55:37,759 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 11:55:37,941 epoch 23 - iter 0/469 - loss 0.74677831\n",
      "2019-03-18 11:55:45,434 epoch 23 - iter 46/469 - loss 0.30504822\n",
      "2019-03-18 11:55:52,990 epoch 23 - iter 92/469 - loss 0.29987073\n",
      "2019-03-18 11:56:00,650 epoch 23 - iter 138/469 - loss 0.31874556\n",
      "2019-03-18 11:56:08,573 epoch 23 - iter 184/469 - loss 0.30735194\n",
      "2019-03-18 11:56:16,282 epoch 23 - iter 230/469 - loss 0.29793811\n",
      "2019-03-18 11:56:24,208 epoch 23 - iter 276/469 - loss 0.29773159\n",
      "2019-03-18 11:56:32,357 epoch 23 - iter 322/469 - loss 0.30281009\n",
      "2019-03-18 11:56:40,266 epoch 23 - iter 368/469 - loss 0.29775145\n",
      "2019-03-18 11:56:48,103 epoch 23 - iter 414/469 - loss 0.30117696\n",
      "2019-03-18 11:56:55,886 epoch 23 - iter 460/469 - loss 0.30432437\n",
      "2019-03-18 11:56:57,011 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 11:56:57,012 EPOCH 23 done: loss 0.3023 - lr 0.1000 - bad epochs 1\n",
      "2019-03-18 11:57:16,427 DEV  : loss 0.46662399 - f-score 0.9524 - acc 0.9092\n",
      "2019-03-18 11:57:33,425 TEST : loss 0.88924766 - f-score 0.9220 - acc 0.8553\n",
      "2019-03-18 11:57:39,646 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 11:57:39,846 epoch 24 - iter 0/469 - loss 0.20994779\n",
      "2019-03-18 11:57:47,200 epoch 24 - iter 46/469 - loss 0.33016409\n",
      "2019-03-18 11:57:54,733 epoch 24 - iter 92/469 - loss 0.30007595\n",
      "2019-03-18 11:58:02,512 epoch 24 - iter 138/469 - loss 0.30745317\n",
      "2019-03-18 11:58:10,114 epoch 24 - iter 184/469 - loss 0.30482580\n",
      "2019-03-18 11:58:17,800 epoch 24 - iter 230/469 - loss 0.30249951\n",
      "2019-03-18 11:58:25,773 epoch 24 - iter 276/469 - loss 0.29034663\n",
      "2019-03-18 11:58:33,631 epoch 24 - iter 322/469 - loss 0.29700679\n",
      "2019-03-18 11:58:41,266 epoch 24 - iter 368/469 - loss 0.30837712\n",
      "2019-03-18 11:58:49,239 epoch 24 - iter 414/469 - loss 0.30408357\n",
      "2019-03-18 11:58:57,225 epoch 24 - iter 460/469 - loss 0.30674301\n",
      "2019-03-18 11:58:58,492 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 11:58:58,492 EPOCH 24 done: loss 0.3072 - lr 0.1000 - bad epochs 0\n",
      "2019-03-18 11:59:16,610 DEV  : loss 0.44615087 - f-score 0.9510 - acc 0.9066\n",
      "2019-03-18 11:59:33,239 TEST : loss 0.94008672 - f-score 0.9218 - acc 0.8550\n",
      "2019-03-18 11:59:33,241 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 11:59:33,405 epoch 25 - iter 0/469 - loss 0.19023672\n",
      "2019-03-18 11:59:40,975 epoch 25 - iter 46/469 - loss 0.29318339\n",
      "2019-03-18 11:59:48,516 epoch 25 - iter 92/469 - loss 0.27884836\n",
      "2019-03-18 11:59:56,158 epoch 25 - iter 138/469 - loss 0.30288321\n",
      "2019-03-18 12:00:04,042 epoch 25 - iter 184/469 - loss 0.30713279\n",
      "2019-03-18 12:00:11,676 epoch 25 - iter 230/469 - loss 0.29268867\n",
      "2019-03-18 12:00:19,442 epoch 25 - iter 276/469 - loss 0.29667676\n",
      "2019-03-18 12:00:27,446 epoch 25 - iter 322/469 - loss 0.30225001\n",
      "2019-03-18 12:00:35,645 epoch 25 - iter 368/469 - loss 0.29952001\n",
      "2019-03-18 12:00:43,304 epoch 25 - iter 414/469 - loss 0.30892575\n",
      "2019-03-18 12:00:50,840 epoch 25 - iter 460/469 - loss 0.30767050\n",
      "2019-03-18 12:00:52,037 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 12:00:52,038 EPOCH 25 done: loss 0.3072 - lr 0.1000 - bad epochs 1\n",
      "2019-03-18 12:01:10,664 DEV  : loss 0.46083266 - f-score 0.9558 - acc 0.9154\n",
      "2019-03-18 12:01:27,580 TEST : loss 0.86274755 - f-score 0.9242 - acc 0.8591\n",
      "2019-03-18 12:01:27,582 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 12:01:27,782 epoch 26 - iter 0/469 - loss 0.95165682\n",
      "2019-03-18 12:01:35,304 epoch 26 - iter 46/469 - loss 0.26197005\n",
      "2019-03-18 12:01:42,982 epoch 26 - iter 92/469 - loss 0.25522935\n",
      "2019-03-18 12:01:50,595 epoch 26 - iter 138/469 - loss 0.28587437\n",
      "2019-03-18 12:01:58,525 epoch 26 - iter 184/469 - loss 0.30470712\n",
      "2019-03-18 12:02:06,161 epoch 26 - iter 230/469 - loss 0.29134516\n",
      "2019-03-18 12:02:13,826 epoch 26 - iter 276/469 - loss 0.29548610\n",
      "2019-03-18 12:02:21,537 epoch 26 - iter 322/469 - loss 0.29747567\n",
      "2019-03-18 12:02:29,539 epoch 26 - iter 368/469 - loss 0.30065000\n",
      "2019-03-18 12:02:37,729 epoch 26 - iter 414/469 - loss 0.29787587\n",
      "2019-03-18 12:02:45,507 epoch 26 - iter 460/469 - loss 0.30343237\n",
      "2019-03-18 12:02:46,812 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 12:02:46,812 EPOCH 26 done: loss 0.3023 - lr 0.1000 - bad epochs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-18 12:03:05,097 DEV  : loss 0.45996803 - f-score 0.9533 - acc 0.9108\n",
      "2019-03-18 12:03:21,537 TEST : loss 0.87309504 - f-score 0.9239 - acc 0.8585\n",
      "2019-03-18 12:03:21,539 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 12:03:21,705 epoch 27 - iter 0/469 - loss 0.65542257\n",
      "2019-03-18 12:03:29,405 epoch 27 - iter 46/469 - loss 0.32783604\n",
      "2019-03-18 12:03:37,093 epoch 27 - iter 92/469 - loss 0.31962301\n",
      "2019-03-18 12:03:44,651 epoch 27 - iter 138/469 - loss 0.31325931\n",
      "2019-03-18 12:03:52,402 epoch 27 - iter 184/469 - loss 0.29256054\n",
      "2019-03-18 12:04:00,391 epoch 27 - iter 230/469 - loss 0.29274898\n",
      "2019-03-18 12:04:08,562 epoch 27 - iter 276/469 - loss 0.30430461\n",
      "2019-03-18 12:04:16,150 epoch 27 - iter 322/469 - loss 0.30223874\n",
      "2019-03-18 12:04:23,828 epoch 27 - iter 368/469 - loss 0.30239759\n",
      "2019-03-18 12:04:31,789 epoch 27 - iter 414/469 - loss 0.30286029\n",
      "2019-03-18 12:04:39,707 epoch 27 - iter 460/469 - loss 0.30049695\n",
      "2019-03-18 12:04:41,084 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 12:04:41,085 EPOCH 27 done: loss 0.3003 - lr 0.1000 - bad epochs 3\n",
      "2019-03-18 12:04:58,854 DEV  : loss 0.47581804 - f-score 0.9542 - acc 0.9125\n",
      "2019-03-18 12:05:15,711 TEST : loss 0.87903434 - f-score 0.9254 - acc 0.8612\n",
      "2019-03-18 12:05:24,642 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 12:05:24,848 epoch 28 - iter 0/469 - loss 0.38139659\n",
      "2019-03-18 12:05:32,475 epoch 28 - iter 46/469 - loss 0.27821355\n",
      "2019-03-18 12:05:40,082 epoch 28 - iter 92/469 - loss 0.28496489\n",
      "2019-03-18 12:05:47,738 epoch 28 - iter 138/469 - loss 0.30137017\n",
      "2019-03-18 12:05:55,441 epoch 28 - iter 184/469 - loss 0.30572668\n",
      "2019-03-18 12:06:03,621 epoch 28 - iter 230/469 - loss 0.30378232\n",
      "2019-03-18 12:06:11,230 epoch 28 - iter 276/469 - loss 0.30045370\n",
      "2019-03-18 12:06:19,143 epoch 28 - iter 322/469 - loss 0.29732943\n",
      "2019-03-18 12:06:26,911 epoch 28 - iter 368/469 - loss 0.29745116\n",
      "2019-03-18 12:06:34,565 epoch 28 - iter 414/469 - loss 0.29874333\n",
      "2019-03-18 12:06:42,289 epoch 28 - iter 460/469 - loss 0.29667929\n",
      "2019-03-18 12:06:43,495 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 12:06:43,495 EPOCH 28 done: loss 0.2984 - lr 0.1000 - bad epochs 0\n",
      "2019-03-18 12:07:01,258 DEV  : loss 0.47883731 - f-score 0.9503 - acc 0.9054\n",
      "2019-03-18 12:07:17,934 TEST : loss 0.87932771 - f-score 0.9238 - acc 0.8584\n",
      "2019-03-18 12:07:24,594 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 12:07:24,764 epoch 29 - iter 0/469 - loss 0.50860429\n",
      "2019-03-18 12:07:32,625 epoch 29 - iter 46/469 - loss 0.35301849\n",
      "2019-03-18 12:07:40,344 epoch 29 - iter 92/469 - loss 0.31576384\n",
      "2019-03-18 12:07:48,499 epoch 29 - iter 138/469 - loss 0.30236230\n",
      "2019-03-18 12:07:56,307 epoch 29 - iter 184/469 - loss 0.30440250\n",
      "2019-03-18 12:08:04,201 epoch 29 - iter 230/469 - loss 0.29497459\n",
      "2019-03-18 12:08:11,700 epoch 29 - iter 276/469 - loss 0.28544353\n",
      "2019-03-18 12:08:19,834 epoch 29 - iter 322/469 - loss 0.28826676\n",
      "2019-03-18 12:08:27,815 epoch 29 - iter 368/469 - loss 0.28632182\n",
      "2019-03-18 12:08:35,532 epoch 29 - iter 414/469 - loss 0.28644251\n",
      "2019-03-18 12:08:43,331 epoch 29 - iter 460/469 - loss 0.28698167\n",
      "2019-03-18 12:08:44,779 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 12:08:44,779 EPOCH 29 done: loss 0.2851 - lr 0.1000 - bad epochs 0\n",
      "2019-03-18 12:09:03,557 DEV  : loss 0.51124609 - f-score 0.9495 - acc 0.9039\n",
      "2019-03-18 12:09:20,234 TEST : loss 0.93438995 - f-score 0.9240 - acc 0.8586\n",
      "2019-03-18 12:09:27,388 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 12:09:27,639 epoch 30 - iter 0/469 - loss 0.08055747\n",
      "2019-03-18 12:09:35,121 epoch 30 - iter 46/469 - loss 0.31492281\n",
      "2019-03-18 12:09:42,974 epoch 30 - iter 92/469 - loss 0.29051967\n",
      "2019-03-18 12:09:50,684 epoch 30 - iter 138/469 - loss 0.27371168\n",
      "2019-03-18 12:09:58,868 epoch 30 - iter 184/469 - loss 0.27652717\n",
      "2019-03-18 12:10:06,627 epoch 30 - iter 230/469 - loss 0.28107872\n",
      "2019-03-18 12:10:14,300 epoch 30 - iter 276/469 - loss 0.28220819\n",
      "2019-03-18 12:10:21,907 epoch 30 - iter 322/469 - loss 0.27855778\n",
      "2019-03-18 12:10:29,153 epoch 30 - iter 368/469 - loss 0.28035770\n",
      "2019-03-18 12:10:36,793 epoch 30 - iter 414/469 - loss 0.27997326\n",
      "2019-03-18 12:10:44,563 epoch 30 - iter 460/469 - loss 0.28140443\n",
      "2019-03-18 12:10:45,946 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 12:10:45,946 EPOCH 30 done: loss 0.2832 - lr 0.1000 - bad epochs 0\n",
      "2019-03-18 12:11:04,006 DEV  : loss 0.45704350 - f-score 0.9559 - acc 0.9155\n",
      "2019-03-18 12:11:20,543 TEST : loss 0.91230702 - f-score 0.9259 - acc 0.8621\n",
      "2019-03-18 12:11:28,417 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 12:11:28,617 epoch 31 - iter 0/469 - loss 0.21251389\n",
      "2019-03-18 12:11:36,192 epoch 31 - iter 46/469 - loss 0.25744727\n",
      "2019-03-18 12:11:44,115 epoch 31 - iter 92/469 - loss 0.29604612\n",
      "2019-03-18 12:11:52,018 epoch 31 - iter 138/469 - loss 0.28967190\n",
      "2019-03-18 12:11:59,934 epoch 31 - iter 184/469 - loss 0.29901212\n",
      "2019-03-18 12:12:07,870 epoch 31 - iter 230/469 - loss 0.29515871\n",
      "2019-03-18 12:12:15,874 epoch 31 - iter 276/469 - loss 0.28357558\n",
      "2019-03-18 12:12:24,329 epoch 31 - iter 322/469 - loss 0.27986741\n",
      "2019-03-18 12:12:32,700 epoch 31 - iter 368/469 - loss 0.28159330\n",
      "2019-03-18 12:12:40,540 epoch 31 - iter 414/469 - loss 0.28890120\n",
      "2019-03-18 12:12:48,767 epoch 31 - iter 460/469 - loss 0.28651758\n",
      "2019-03-18 12:12:50,066 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 12:12:50,067 EPOCH 31 done: loss 0.2855 - lr 0.1000 - bad epochs 0\n",
      "2019-03-18 12:13:08,819 DEV  : loss 0.45794943 - f-score 0.9531 - acc 0.9104\n",
      "2019-03-18 12:13:26,419 TEST : loss 0.91872376 - f-score 0.9248 - acc 0.8601\n",
      "2019-03-18 12:13:26,420 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 12:13:26,602 epoch 32 - iter 0/469 - loss 0.56907296\n",
      "2019-03-18 12:13:34,533 epoch 32 - iter 46/469 - loss 0.27554472\n",
      "2019-03-18 12:13:42,493 epoch 32 - iter 92/469 - loss 0.27924410\n",
      "2019-03-18 12:13:50,243 epoch 32 - iter 138/469 - loss 0.27950944\n",
      "2019-03-18 12:13:58,130 epoch 32 - iter 184/469 - loss 0.29057010\n",
      "2019-03-18 12:14:06,177 epoch 32 - iter 230/469 - loss 0.29118584\n",
      "2019-03-18 12:14:13,879 epoch 32 - iter 276/469 - loss 0.28808249\n",
      "2019-03-18 12:14:21,840 epoch 32 - iter 322/469 - loss 0.27687486\n",
      "2019-03-18 12:14:30,025 epoch 32 - iter 368/469 - loss 0.28021865\n",
      "2019-03-18 12:14:38,475 epoch 32 - iter 414/469 - loss 0.28154060\n",
      "2019-03-18 12:14:46,546 epoch 32 - iter 460/469 - loss 0.27913851\n",
      "2019-03-18 12:14:47,833 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 12:14:47,834 EPOCH 32 done: loss 0.2792 - lr 0.1000 - bad epochs 1\n",
      "2019-03-18 12:15:06,287 DEV  : loss 0.48019004 - f-score 0.9534 - acc 0.9109\n",
      "2019-03-18 12:15:23,400 TEST : loss 0.94407630 - f-score 0.9248 - acc 0.8602\n",
      "2019-03-18 12:15:32,066 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 12:15:32,253 epoch 33 - iter 0/469 - loss 0.11987129\n",
      "2019-03-18 12:15:39,935 epoch 33 - iter 46/469 - loss 0.24374855\n",
      "2019-03-18 12:15:47,653 epoch 33 - iter 92/469 - loss 0.25255285\n",
      "2019-03-18 12:15:55,697 epoch 33 - iter 138/469 - loss 0.26111980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-18 12:16:03,657 epoch 33 - iter 184/469 - loss 0.25639233\n",
      "2019-03-18 12:16:11,641 epoch 33 - iter 230/469 - loss 0.25494139\n",
      "2019-03-18 12:16:19,592 epoch 33 - iter 276/469 - loss 0.25684317\n",
      "2019-03-18 12:16:27,547 epoch 33 - iter 322/469 - loss 0.26068468\n",
      "2019-03-18 12:16:35,325 epoch 33 - iter 368/469 - loss 0.26589721\n",
      "2019-03-18 12:16:43,049 epoch 33 - iter 414/469 - loss 0.26786854\n",
      "2019-03-18 12:16:50,962 epoch 33 - iter 460/469 - loss 0.26965371\n",
      "2019-03-18 12:16:52,238 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 12:16:52,239 EPOCH 33 done: loss 0.2706 - lr 0.1000 - bad epochs 0\n",
      "2019-03-18 12:17:10,325 DEV  : loss 0.52967423 - f-score 0.9491 - acc 0.9032\n",
      "2019-03-18 12:17:27,619 TEST : loss 0.99234653 - f-score 0.9226 - acc 0.8562\n",
      "2019-03-18 12:17:36,226 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 12:17:36,380 epoch 34 - iter 0/469 - loss 0.08703345\n",
      "2019-03-18 12:17:44,237 epoch 34 - iter 46/469 - loss 0.21461636\n",
      "2019-03-18 12:17:52,067 epoch 34 - iter 92/469 - loss 0.23287149\n",
      "2019-03-18 12:17:59,693 epoch 34 - iter 138/469 - loss 0.24018437\n",
      "2019-03-18 12:18:07,805 epoch 34 - iter 184/469 - loss 0.26276935\n",
      "2019-03-18 12:18:15,850 epoch 34 - iter 230/469 - loss 0.25569932\n",
      "2019-03-18 12:18:24,143 epoch 34 - iter 276/469 - loss 0.25018471\n",
      "2019-03-18 12:18:32,263 epoch 34 - iter 322/469 - loss 0.26409257\n",
      "2019-03-18 12:18:40,588 epoch 34 - iter 368/469 - loss 0.25512584\n",
      "2019-03-18 12:18:48,730 epoch 34 - iter 414/469 - loss 0.26107884\n",
      "2019-03-18 12:18:56,660 epoch 34 - iter 460/469 - loss 0.26387073\n",
      "2019-03-18 12:18:58,036 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 12:18:58,037 EPOCH 34 done: loss 0.2630 - lr 0.1000 - bad epochs 0\n",
      "2019-03-18 12:19:17,231 DEV  : loss 0.49740744 - f-score 0.9549 - acc 0.9137\n",
      "2019-03-18 12:19:34,763 TEST : loss 0.96272540 - f-score 0.9250 - acc 0.8604\n",
      "2019-03-18 12:19:41,501 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 12:19:41,745 epoch 35 - iter 0/469 - loss 0.31272325\n",
      "2019-03-18 12:19:49,737 epoch 35 - iter 46/469 - loss 0.26731784\n",
      "2019-03-18 12:19:57,665 epoch 35 - iter 92/469 - loss 0.27162139\n",
      "2019-03-18 12:20:05,971 epoch 35 - iter 138/469 - loss 0.25672579\n",
      "2019-03-18 12:20:14,004 epoch 35 - iter 184/469 - loss 0.26251415\n",
      "2019-03-18 12:20:21,588 epoch 35 - iter 230/469 - loss 0.26293873\n",
      "2019-03-18 12:20:29,229 epoch 35 - iter 276/469 - loss 0.25342727\n",
      "2019-03-18 12:20:36,891 epoch 35 - iter 322/469 - loss 0.25657732\n",
      "2019-03-18 12:20:44,867 epoch 35 - iter 368/469 - loss 0.25679033\n",
      "2019-03-18 12:20:52,917 epoch 35 - iter 414/469 - loss 0.25862819\n",
      "2019-03-18 12:21:00,911 epoch 35 - iter 460/469 - loss 0.25990902\n",
      "2019-03-18 12:21:02,332 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 12:21:02,333 EPOCH 35 done: loss 0.2600 - lr 0.1000 - bad epochs 0\n",
      "2019-03-18 12:21:21,375 DEV  : loss 0.48234564 - f-score 0.9522 - acc 0.9088\n",
      "2019-03-18 12:21:39,352 TEST : loss 0.94838947 - f-score 0.9239 - acc 0.8586\n",
      "2019-03-18 12:21:47,154 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 12:21:47,575 epoch 36 - iter 0/469 - loss 0.40490687\n",
      "2019-03-18 12:21:55,371 epoch 36 - iter 46/469 - loss 0.29792376\n",
      "2019-03-18 12:22:03,553 epoch 36 - iter 92/469 - loss 0.25732245\n",
      "2019-03-18 12:22:11,569 epoch 36 - iter 138/469 - loss 0.25434735\n",
      "2019-03-18 12:22:20,115 epoch 36 - iter 184/469 - loss 0.25142130\n",
      "2019-03-18 12:22:27,932 epoch 36 - iter 230/469 - loss 0.25409443\n",
      "2019-03-18 12:22:35,740 epoch 36 - iter 276/469 - loss 0.25665035\n",
      "2019-03-18 12:22:43,757 epoch 36 - iter 322/469 - loss 0.25467260\n",
      "2019-03-18 12:22:51,406 epoch 36 - iter 368/469 - loss 0.25559352\n",
      "2019-03-18 12:22:59,179 epoch 36 - iter 414/469 - loss 0.25057736\n",
      "2019-03-18 12:23:07,067 epoch 36 - iter 460/469 - loss 0.26120747\n",
      "2019-03-18 12:23:08,320 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 12:23:08,320 EPOCH 36 done: loss 0.2634 - lr 0.1000 - bad epochs 0\n",
      "2019-03-18 12:23:26,655 DEV  : loss 0.47549084 - f-score 0.9524 - acc 0.9091\n",
      "2019-03-18 12:23:43,723 TEST : loss 0.91869754 - f-score 0.9229 - acc 0.8567\n",
      "2019-03-18 12:23:43,724 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 12:23:43,875 epoch 37 - iter 0/469 - loss 0.53132266\n",
      "2019-03-18 12:23:51,753 epoch 37 - iter 46/469 - loss 0.25933708\n",
      "2019-03-18 12:23:59,918 epoch 37 - iter 92/469 - loss 0.23869058\n",
      "2019-03-18 12:24:07,653 epoch 37 - iter 138/469 - loss 0.24829251\n",
      "2019-03-18 12:24:15,617 epoch 37 - iter 184/469 - loss 0.24803265\n",
      "2019-03-18 12:24:23,547 epoch 37 - iter 230/469 - loss 0.26418860\n",
      "2019-03-18 12:24:32,116 epoch 37 - iter 276/469 - loss 0.25835650\n",
      "2019-03-18 12:24:40,452 epoch 37 - iter 322/469 - loss 0.25443515\n",
      "2019-03-18 12:24:48,923 epoch 37 - iter 368/469 - loss 0.24948384\n",
      "2019-03-18 12:24:56,816 epoch 37 - iter 414/469 - loss 0.24914623\n",
      "2019-03-18 12:25:04,894 epoch 37 - iter 460/469 - loss 0.25173397\n",
      "2019-03-18 12:25:06,099 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 12:25:06,100 EPOCH 37 done: loss 0.2500 - lr 0.1000 - bad epochs 1\n",
      "2019-03-18 12:25:24,887 DEV  : loss 0.52666408 - f-score 0.9498 - acc 0.9045\n",
      "2019-03-18 12:25:42,372 TEST : loss 0.97761303 - f-score 0.9222 - acc 0.8556\n",
      "2019-03-18 12:25:50,048 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 12:25:50,232 epoch 38 - iter 0/469 - loss 0.33158934\n",
      "2019-03-18 12:25:57,871 epoch 38 - iter 46/469 - loss 0.25892513\n",
      "2019-03-18 12:26:05,516 epoch 38 - iter 92/469 - loss 0.24535201\n",
      "2019-03-18 12:26:13,271 epoch 38 - iter 138/469 - loss 0.25649861\n",
      "2019-03-18 12:26:22,009 epoch 38 - iter 184/469 - loss 0.25941743\n",
      "2019-03-18 12:26:30,015 epoch 38 - iter 230/469 - loss 0.26216978\n",
      "2019-03-18 12:26:38,059 epoch 38 - iter 276/469 - loss 0.26278601\n",
      "2019-03-18 12:26:46,210 epoch 38 - iter 322/469 - loss 0.26443450\n",
      "2019-03-18 12:26:54,383 epoch 38 - iter 368/469 - loss 0.26134510\n",
      "2019-03-18 12:27:02,210 epoch 38 - iter 414/469 - loss 0.26328814\n",
      "2019-03-18 12:27:10,506 epoch 38 - iter 460/469 - loss 0.26420747\n",
      "2019-03-18 12:27:11,951 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 12:27:11,951 EPOCH 38 done: loss 0.2624 - lr 0.1000 - bad epochs 0\n",
      "2019-03-18 12:27:30,420 DEV  : loss 0.51148069 - f-score 0.9505 - acc 0.9057\n",
      "2019-03-18 12:27:47,313 TEST : loss 0.95108896 - f-score 0.9237 - acc 0.8583\n",
      "2019-03-18 12:27:47,317 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 12:27:47,492 epoch 39 - iter 0/469 - loss 0.67759824\n",
      "2019-03-18 12:27:55,455 epoch 39 - iter 46/469 - loss 0.28799501\n",
      "2019-03-18 12:28:03,526 epoch 39 - iter 92/469 - loss 0.28025732\n",
      "2019-03-18 12:28:11,419 epoch 39 - iter 138/469 - loss 0.29129629\n",
      "2019-03-18 12:28:19,456 epoch 39 - iter 184/469 - loss 0.28433488\n",
      "2019-03-18 12:28:27,712 epoch 39 - iter 230/469 - loss 0.27738262\n",
      "2019-03-18 12:28:35,631 epoch 39 - iter 276/469 - loss 0.27254372\n",
      "2019-03-18 12:28:43,515 epoch 39 - iter 322/469 - loss 0.27098378\n",
      "2019-03-18 12:28:51,359 epoch 39 - iter 368/469 - loss 0.27122837\n",
      "2019-03-18 12:28:59,228 epoch 39 - iter 414/469 - loss 0.26646283\n",
      "2019-03-18 12:29:07,100 epoch 39 - iter 460/469 - loss 0.26186644\n",
      "2019-03-18 12:29:08,420 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-18 12:29:08,421 EPOCH 39 done: loss 0.2616 - lr 0.1000 - bad epochs 1\n",
      "2019-03-18 12:29:26,464 DEV  : loss 0.51507068 - f-score 0.9498 - acc 0.9044\n",
      "2019-03-18 12:29:42,937 TEST : loss 0.98609102 - f-score 0.9218 - acc 0.8550\n",
      "2019-03-18 12:29:42,938 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 12:29:43,138 epoch 40 - iter 0/469 - loss 0.43644270\n",
      "2019-03-18 12:29:50,960 epoch 40 - iter 46/469 - loss 0.23463831\n",
      "2019-03-18 12:29:58,756 epoch 40 - iter 92/469 - loss 0.25330102\n",
      "2019-03-18 12:30:06,347 epoch 40 - iter 138/469 - loss 0.25662035\n",
      "2019-03-18 12:30:14,034 epoch 40 - iter 184/469 - loss 0.24374802\n",
      "2019-03-18 12:30:21,864 epoch 40 - iter 230/469 - loss 0.23760307\n",
      "2019-03-18 12:30:29,788 epoch 40 - iter 276/469 - loss 0.23030516\n",
      "2019-03-18 12:30:37,612 epoch 40 - iter 322/469 - loss 0.22846720\n",
      "2019-03-18 12:30:45,963 epoch 40 - iter 368/469 - loss 0.23086825\n",
      "2019-03-18 12:30:53,717 epoch 40 - iter 414/469 - loss 0.23916963\n",
      "2019-03-18 12:31:01,893 epoch 40 - iter 460/469 - loss 0.24144576\n",
      "2019-03-18 12:31:03,202 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 12:31:03,202 EPOCH 40 done: loss 0.2422 - lr 0.1000 - bad epochs 2\n",
      "2019-03-18 12:31:22,892 DEV  : loss 0.48051214 - f-score 0.9540 - acc 0.9121\n",
      "2019-03-18 12:31:40,149 TEST : loss 0.94940525 - f-score 0.9240 - acc 0.8588\n",
      "2019-03-18 12:31:48,229 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 12:31:48,424 epoch 41 - iter 0/469 - loss 0.18348390\n",
      "2019-03-18 12:31:56,308 epoch 41 - iter 46/469 - loss 0.25878864\n",
      "2019-03-18 12:32:04,280 epoch 41 - iter 92/469 - loss 0.24157441\n",
      "2019-03-18 12:32:12,530 epoch 41 - iter 138/469 - loss 0.22832444\n",
      "2019-03-18 12:32:20,641 epoch 41 - iter 184/469 - loss 0.23321398\n",
      "2019-03-18 12:32:28,524 epoch 41 - iter 230/469 - loss 0.23126123\n",
      "2019-03-18 12:32:36,455 epoch 41 - iter 276/469 - loss 0.23263562\n",
      "2019-03-18 12:32:44,218 epoch 41 - iter 322/469 - loss 0.23090270\n",
      "2019-03-18 12:32:51,937 epoch 41 - iter 368/469 - loss 0.23310992\n",
      "2019-03-18 12:32:59,658 epoch 41 - iter 414/469 - loss 0.23810285\n",
      "2019-03-18 12:33:07,227 epoch 41 - iter 460/469 - loss 0.24007667\n",
      "2019-03-18 12:33:08,447 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 12:33:08,447 EPOCH 41 done: loss 0.2413 - lr 0.1000 - bad epochs 0\n",
      "2019-03-18 12:33:26,702 DEV  : loss 0.51769871 - f-score 0.9540 - acc 0.9122\n",
      "2019-03-18 12:33:43,917 TEST : loss 0.98020637 - f-score 0.9277 - acc 0.8651\n",
      "2019-03-18 12:33:52,050 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 12:33:52,191 epoch 42 - iter 0/469 - loss 0.06368500\n",
      "2019-03-18 12:34:00,127 epoch 42 - iter 46/469 - loss 0.22587361\n",
      "2019-03-18 12:34:08,341 epoch 42 - iter 92/469 - loss 0.23561950\n",
      "2019-03-18 12:34:16,352 epoch 42 - iter 138/469 - loss 0.22901520\n",
      "2019-03-18 12:34:24,105 epoch 42 - iter 184/469 - loss 0.26514846\n",
      "2019-03-18 12:34:32,202 epoch 42 - iter 230/469 - loss 0.26798711\n",
      "2019-03-18 12:34:40,211 epoch 42 - iter 276/469 - loss 0.26532964\n",
      "2019-03-18 12:34:48,011 epoch 42 - iter 322/469 - loss 0.25504182\n",
      "2019-03-18 12:34:55,831 epoch 42 - iter 368/469 - loss 0.25609582\n",
      "2019-03-18 12:35:03,860 epoch 42 - iter 414/469 - loss 0.25563316\n",
      "2019-03-18 12:35:11,616 epoch 42 - iter 460/469 - loss 0.25860687\n",
      "2019-03-18 12:35:12,863 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 12:35:12,864 EPOCH 42 done: loss 0.2580 - lr 0.1000 - bad epochs 0\n",
      "2019-03-18 12:35:31,251 DEV  : loss 0.50073862 - f-score 0.9536 - acc 0.9114\n",
      "2019-03-18 12:35:48,089 TEST : loss 0.99011135 - f-score 0.9288 - acc 0.8671\n",
      "2019-03-18 12:35:48,093 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 12:35:48,257 epoch 43 - iter 0/469 - loss 0.24780831\n",
      "2019-03-18 12:35:55,844 epoch 43 - iter 46/469 - loss 0.23149866\n",
      "2019-03-18 12:36:03,578 epoch 43 - iter 92/469 - loss 0.23280536\n",
      "2019-03-18 12:36:11,098 epoch 43 - iter 138/469 - loss 0.23221232\n",
      "2019-03-18 12:36:18,287 epoch 43 - iter 184/469 - loss 0.23220821\n",
      "2019-03-18 12:36:26,364 epoch 43 - iter 230/469 - loss 0.23874458\n",
      "2019-03-18 12:36:33,906 epoch 43 - iter 276/469 - loss 0.23874492\n",
      "2019-03-18 12:36:41,769 epoch 43 - iter 322/469 - loss 0.23453636\n",
      "2019-03-18 12:36:49,269 epoch 43 - iter 368/469 - loss 0.22965130\n",
      "2019-03-18 12:36:57,146 epoch 43 - iter 414/469 - loss 0.23390597\n",
      "2019-03-18 12:37:04,536 epoch 43 - iter 460/469 - loss 0.23364967\n",
      "2019-03-18 12:37:05,774 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 12:37:05,775 EPOCH 43 done: loss 0.2325 - lr 0.1000 - bad epochs 1\n",
      "2019-03-18 12:37:22,987 DEV  : loss 0.55500251 - f-score 0.9539 - acc 0.9119\n",
      "2019-03-18 12:37:38,713 TEST : loss 0.96988708 - f-score 0.9256 - acc 0.8616\n",
      "2019-03-18 12:37:46,728 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 12:37:46,940 epoch 44 - iter 0/469 - loss 0.24267638\n",
      "2019-03-18 12:37:54,367 epoch 44 - iter 46/469 - loss 0.22102041\n",
      "2019-03-18 12:38:01,852 epoch 44 - iter 92/469 - loss 0.23135008\n",
      "2019-03-18 12:38:09,568 epoch 44 - iter 138/469 - loss 0.23513347\n",
      "2019-03-18 12:38:16,781 epoch 44 - iter 184/469 - loss 0.23260386\n",
      "2019-03-18 12:38:24,396 epoch 44 - iter 230/469 - loss 0.23348679\n",
      "2019-03-18 12:38:32,472 epoch 44 - iter 276/469 - loss 0.23105948\n",
      "2019-03-18 12:38:39,947 epoch 44 - iter 322/469 - loss 0.24049916\n",
      "2019-03-18 12:38:47,781 epoch 44 - iter 368/469 - loss 0.24084580\n",
      "2019-03-18 12:38:55,467 epoch 44 - iter 414/469 - loss 0.23883457\n",
      "2019-03-18 12:39:02,911 epoch 44 - iter 460/469 - loss 0.23631117\n",
      "2019-03-18 12:39:04,132 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 12:39:04,133 EPOCH 44 done: loss 0.2366 - lr 0.1000 - bad epochs 0\n",
      "2019-03-18 12:39:21,783 DEV  : loss 0.51669931 - f-score 0.9543 - acc 0.9125\n",
      "2019-03-18 12:39:37,988 TEST : loss 1.00901818 - f-score 0.9238 - acc 0.8584\n",
      "2019-03-18 12:39:37,990 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 12:39:38,159 epoch 45 - iter 0/469 - loss 0.12595382\n",
      "2019-03-18 12:39:45,327 epoch 45 - iter 46/469 - loss 0.20235793\n",
      "2019-03-18 12:39:52,677 epoch 45 - iter 92/469 - loss 0.21008697\n",
      "2019-03-18 12:40:00,149 epoch 45 - iter 138/469 - loss 0.24384498\n",
      "2019-03-18 12:40:07,746 epoch 45 - iter 184/469 - loss 0.25317393\n",
      "2019-03-18 12:40:15,332 epoch 45 - iter 230/469 - loss 0.25952232\n",
      "2019-03-18 12:40:23,170 epoch 45 - iter 276/469 - loss 0.25122308\n",
      "2019-03-18 12:40:30,757 epoch 45 - iter 322/469 - loss 0.24269289\n",
      "2019-03-18 12:40:38,363 epoch 45 - iter 368/469 - loss 0.25208871\n",
      "2019-03-18 12:40:46,168 epoch 45 - iter 414/469 - loss 0.25134813\n",
      "2019-03-18 12:40:53,633 epoch 45 - iter 460/469 - loss 0.24951712\n",
      "2019-03-18 12:40:54,905 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 12:40:54,906 EPOCH 45 done: loss 0.2482 - lr 0.1000 - bad epochs 1\n",
      "2019-03-18 12:41:12,300 DEV  : loss 0.52445656 - f-score 0.9535 - acc 0.9111\n",
      "2019-03-18 12:41:28,382 TEST : loss 0.97905028 - f-score 0.9253 - acc 0.8609\n",
      "2019-03-18 12:41:28,383 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 12:41:28,540 epoch 46 - iter 0/469 - loss 0.19686270\n",
      "2019-03-18 12:41:35,876 epoch 46 - iter 46/469 - loss 0.28798539\n",
      "2019-03-18 12:41:43,514 epoch 46 - iter 92/469 - loss 0.29856280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-18 12:41:51,168 epoch 46 - iter 138/469 - loss 0.28636979\n",
      "2019-03-18 12:41:58,820 epoch 46 - iter 184/469 - loss 0.28476435\n",
      "2019-03-18 12:42:06,679 epoch 46 - iter 230/469 - loss 0.28384825\n",
      "2019-03-18 12:42:14,291 epoch 46 - iter 276/469 - loss 0.28383254\n",
      "2019-03-18 12:42:22,018 epoch 46 - iter 322/469 - loss 0.27473559\n",
      "2019-03-18 12:42:29,663 epoch 46 - iter 368/469 - loss 0.26754554\n",
      "2019-03-18 12:42:37,508 epoch 46 - iter 414/469 - loss 0.26504100\n",
      "2019-03-18 12:42:45,019 epoch 46 - iter 460/469 - loss 0.26765203\n",
      "2019-03-18 12:42:46,320 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 12:42:46,321 EPOCH 46 done: loss 0.2678 - lr 0.1000 - bad epochs 2\n",
      "2019-03-18 12:43:04,861 DEV  : loss 0.51679015 - f-score 0.9548 - acc 0.9136\n",
      "2019-03-18 12:43:21,171 TEST : loss 0.96569419 - f-score 0.9259 - acc 0.8621\n",
      "2019-03-18 12:43:21,172 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 12:43:21,326 epoch 47 - iter 0/469 - loss 0.12215209\n",
      "2019-03-18 12:43:28,979 epoch 47 - iter 46/469 - loss 0.22654999\n",
      "2019-03-18 12:43:36,698 epoch 47 - iter 92/469 - loss 0.23097537\n",
      "2019-03-18 12:43:44,307 epoch 47 - iter 138/469 - loss 0.22408455\n",
      "2019-03-18 12:43:52,079 epoch 47 - iter 184/469 - loss 0.24044259\n",
      "2019-03-18 12:43:59,616 epoch 47 - iter 230/469 - loss 0.23808234\n",
      "2019-03-18 12:44:07,139 epoch 47 - iter 276/469 - loss 0.23882524\n",
      "2019-03-18 12:44:14,918 epoch 47 - iter 322/469 - loss 0.24068690\n",
      "2019-03-18 12:44:22,324 epoch 47 - iter 368/469 - loss 0.23422550\n",
      "2019-03-18 12:44:29,922 epoch 47 - iter 414/469 - loss 0.23852961\n",
      "2019-03-18 12:44:37,489 epoch 47 - iter 460/469 - loss 0.23583661\n",
      "2019-03-18 12:44:38,788 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 12:44:38,789 EPOCH 47 done: loss 0.2383 - lr 0.1000 - bad epochs 3\n",
      "2019-03-18 12:44:56,170 DEV  : loss 0.52795041 - f-score 0.9519 - acc 0.9082\n",
      "2019-03-18 12:45:12,402 TEST : loss 0.96707219 - f-score 0.9267 - acc 0.8634\n",
      "Epoch    46: reducing learning rate of group 0 to 5.0000e-02.\n",
      "2019-03-18 12:45:12,403 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 12:45:12,602 epoch 48 - iter 0/469 - loss 0.15673280\n",
      "2019-03-18 12:45:19,887 epoch 48 - iter 46/469 - loss 0.27428191\n",
      "2019-03-18 12:45:27,293 epoch 48 - iter 92/469 - loss 0.23680052\n",
      "2019-03-18 12:45:34,898 epoch 48 - iter 138/469 - loss 0.23628732\n",
      "2019-03-18 12:45:42,349 epoch 48 - iter 184/469 - loss 0.23487330\n",
      "2019-03-18 12:45:49,891 epoch 48 - iter 230/469 - loss 0.22884228\n",
      "2019-03-18 12:45:57,568 epoch 48 - iter 276/469 - loss 0.22133329\n",
      "2019-03-18 12:46:05,092 epoch 48 - iter 322/469 - loss 0.21690822\n",
      "2019-03-18 12:46:12,875 epoch 48 - iter 368/469 - loss 0.21737122\n",
      "2019-03-18 12:46:20,438 epoch 48 - iter 414/469 - loss 0.21666271\n",
      "2019-03-18 12:46:27,903 epoch 48 - iter 460/469 - loss 0.21567274\n",
      "2019-03-18 12:46:29,246 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 12:46:29,247 EPOCH 48 done: loss 0.2153 - lr 0.0500 - bad epochs 0\n",
      "2019-03-18 12:46:46,369 DEV  : loss 0.52503246 - f-score 0.9513 - acc 0.9072\n",
      "2019-03-18 12:47:02,350 TEST : loss 0.98703647 - f-score 0.9277 - acc 0.8652\n",
      "2019-03-18 12:47:10,288 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 12:47:10,473 epoch 49 - iter 0/469 - loss 0.12626627\n",
      "2019-03-18 12:47:17,849 epoch 49 - iter 46/469 - loss 0.16746999\n",
      "2019-03-18 12:47:25,210 epoch 49 - iter 92/469 - loss 0.16698071\n",
      "2019-03-18 12:47:32,787 epoch 49 - iter 138/469 - loss 0.19758764\n",
      "2019-03-18 12:47:40,336 epoch 49 - iter 184/469 - loss 0.19951953\n",
      "2019-03-18 12:47:47,973 epoch 49 - iter 230/469 - loss 0.20575672\n",
      "2019-03-18 12:47:55,491 epoch 49 - iter 276/469 - loss 0.20125916\n",
      "2019-03-18 12:48:03,059 epoch 49 - iter 322/469 - loss 0.19761059\n",
      "2019-03-18 12:48:10,491 epoch 49 - iter 368/469 - loss 0.19799525\n",
      "2019-03-18 12:48:17,919 epoch 49 - iter 414/469 - loss 0.19241937\n",
      "2019-03-18 12:48:25,414 epoch 49 - iter 460/469 - loss 0.19239472\n",
      "2019-03-18 12:48:26,653 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 12:48:26,653 EPOCH 49 done: loss 0.1910 - lr 0.0500 - bad epochs 0\n",
      "2019-03-18 12:48:43,689 DEV  : loss 0.53269368 - f-score 0.9515 - acc 0.9075\n",
      "2019-03-18 12:48:59,669 TEST : loss 1.03203511 - f-score 0.9244 - acc 0.8594\n",
      "2019-03-18 12:49:05,753 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 12:49:05,917 epoch 50 - iter 0/469 - loss 0.12821445\n",
      "2019-03-18 12:49:13,070 epoch 50 - iter 46/469 - loss 0.23010319\n",
      "2019-03-18 12:49:20,514 epoch 50 - iter 92/469 - loss 0.20512409\n",
      "2019-03-18 12:49:27,942 epoch 50 - iter 138/469 - loss 0.21187873\n",
      "2019-03-18 12:49:35,764 epoch 50 - iter 184/469 - loss 0.20299362\n",
      "2019-03-18 12:49:43,212 epoch 50 - iter 230/469 - loss 0.20672954\n",
      "2019-03-18 12:49:50,705 epoch 50 - iter 276/469 - loss 0.20479237\n",
      "2019-03-18 12:49:59,141 epoch 50 - iter 322/469 - loss 0.20627321\n",
      "2019-03-18 12:50:06,830 epoch 50 - iter 368/469 - loss 0.20288145\n",
      "2019-03-18 12:50:14,307 epoch 50 - iter 414/469 - loss 0.20041480\n",
      "2019-03-18 12:50:22,109 epoch 50 - iter 460/469 - loss 0.20551138\n",
      "2019-03-18 12:50:23,369 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 12:50:23,369 EPOCH 50 done: loss 0.2052 - lr 0.0500 - bad epochs 0\n",
      "2019-03-18 12:50:40,811 DEV  : loss 0.51852953 - f-score 0.9538 - acc 0.9117\n",
      "2019-03-18 12:50:57,121 TEST : loss 0.98987335 - f-score 0.9283 - acc 0.8662\n",
      "2019-03-18 12:50:57,122 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 12:50:57,282 epoch 51 - iter 0/469 - loss 0.13687846\n",
      "2019-03-18 12:51:04,905 epoch 51 - iter 46/469 - loss 0.21711616\n",
      "2019-03-18 12:51:12,570 epoch 51 - iter 92/469 - loss 0.20204333\n",
      "2019-03-18 12:51:20,211 epoch 51 - iter 138/469 - loss 0.20206320\n",
      "2019-03-18 12:51:27,612 epoch 51 - iter 184/469 - loss 0.20966362\n",
      "2019-03-18 12:51:34,949 epoch 51 - iter 230/469 - loss 0.20279066\n",
      "2019-03-18 12:51:42,388 epoch 51 - iter 276/469 - loss 0.20893454\n",
      "2019-03-18 12:51:49,881 epoch 51 - iter 322/469 - loss 0.20611214\n",
      "2019-03-18 12:51:57,687 epoch 51 - iter 368/469 - loss 0.20034186\n",
      "2019-03-18 12:52:05,119 epoch 51 - iter 414/469 - loss 0.19770729\n",
      "2019-03-18 12:52:12,496 epoch 51 - iter 460/469 - loss 0.19583142\n",
      "2019-03-18 12:52:13,927 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 12:52:13,927 EPOCH 51 done: loss 0.1953 - lr 0.0500 - bad epochs 1\n",
      "2019-03-18 12:52:31,059 DEV  : loss 0.52500564 - f-score 0.9552 - acc 0.9142\n",
      "2019-03-18 12:52:47,050 TEST : loss 1.03209329 - f-score 0.9257 - acc 0.8618\n",
      "2019-03-18 12:52:47,051 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 12:52:47,223 epoch 52 - iter 0/469 - loss 0.67866075\n",
      "2019-03-18 12:52:54,744 epoch 52 - iter 46/469 - loss 0.20724957\n",
      "2019-03-18 12:53:02,291 epoch 52 - iter 92/469 - loss 0.19250641\n",
      "2019-03-18 12:53:09,556 epoch 52 - iter 138/469 - loss 0.19239714\n",
      "2019-03-18 12:53:16,841 epoch 52 - iter 184/469 - loss 0.20599616\n",
      "2019-03-18 12:53:24,352 epoch 52 - iter 230/469 - loss 0.20666654\n",
      "2019-03-18 12:53:31,882 epoch 52 - iter 276/469 - loss 0.20757519\n",
      "2019-03-18 12:53:39,310 epoch 52 - iter 322/469 - loss 0.20741843\n",
      "2019-03-18 12:53:46,797 epoch 52 - iter 368/469 - loss 0.20675386\n",
      "2019-03-18 12:53:54,390 epoch 52 - iter 414/469 - loss 0.20149551\n",
      "2019-03-18 12:54:02,089 epoch 52 - iter 460/469 - loss 0.19688848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-18 12:54:03,385 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 12:54:03,386 EPOCH 52 done: loss 0.1953 - lr 0.0500 - bad epochs 2\n",
      "2019-03-18 12:54:21,687 DEV  : loss 0.56542641 - f-score 0.9533 - acc 0.9108\n",
      "2019-03-18 12:54:38,042 TEST : loss 1.05157316 - f-score 0.9271 - acc 0.8641\n",
      "2019-03-18 12:54:38,043 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 12:54:38,205 epoch 53 - iter 0/469 - loss 0.20390928\n",
      "2019-03-18 12:54:45,616 epoch 53 - iter 46/469 - loss 0.20231220\n",
      "2019-03-18 12:54:53,135 epoch 53 - iter 92/469 - loss 0.20293183\n",
      "2019-03-18 12:55:00,551 epoch 53 - iter 138/469 - loss 0.19805133\n",
      "2019-03-18 12:55:07,977 epoch 53 - iter 184/469 - loss 0.19740269\n",
      "2019-03-18 12:55:15,607 epoch 53 - iter 230/469 - loss 0.18991269\n",
      "2019-03-18 12:55:23,151 epoch 53 - iter 276/469 - loss 0.18920294\n",
      "2019-03-18 12:55:30,673 epoch 53 - iter 322/469 - loss 0.18316248\n",
      "2019-03-18 12:55:38,258 epoch 53 - iter 368/469 - loss 0.18052321\n",
      "2019-03-18 12:55:46,010 epoch 53 - iter 414/469 - loss 0.17867360\n",
      "2019-03-18 12:55:53,504 epoch 53 - iter 460/469 - loss 0.17889234\n",
      "2019-03-18 12:55:54,796 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 12:55:54,797 EPOCH 53 done: loss 0.1804 - lr 0.0500 - bad epochs 3\n",
      "2019-03-18 12:56:11,973 DEV  : loss 0.51800054 - f-score 0.9574 - acc 0.9183\n",
      "2019-03-18 12:56:27,947 TEST : loss 1.03301013 - f-score 0.9268 - acc 0.8636\n",
      "2019-03-18 12:56:36,020 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 12:56:36,214 epoch 54 - iter 0/469 - loss 0.07395419\n",
      "2019-03-18 12:56:43,969 epoch 54 - iter 46/469 - loss 0.18456242\n",
      "2019-03-18 12:56:51,333 epoch 54 - iter 92/469 - loss 0.16059493\n",
      "2019-03-18 12:56:58,721 epoch 54 - iter 138/469 - loss 0.16939763\n",
      "2019-03-18 12:57:06,124 epoch 54 - iter 184/469 - loss 0.16082392\n",
      "2019-03-18 12:57:13,752 epoch 54 - iter 230/469 - loss 0.16399465\n",
      "2019-03-18 12:57:21,403 epoch 54 - iter 276/469 - loss 0.17316367\n",
      "2019-03-18 12:57:29,012 epoch 54 - iter 322/469 - loss 0.16945710\n",
      "2019-03-18 12:57:36,880 epoch 54 - iter 368/469 - loss 0.17452564\n",
      "2019-03-18 12:57:44,150 epoch 54 - iter 414/469 - loss 0.17362446\n",
      "2019-03-18 12:57:51,598 epoch 54 - iter 460/469 - loss 0.17662077\n",
      "2019-03-18 12:57:52,806 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 12:57:52,807 EPOCH 54 done: loss 0.1752 - lr 0.0500 - bad epochs 0\n",
      "2019-03-18 12:58:11,082 DEV  : loss 0.57525766 - f-score 0.9527 - acc 0.9097\n",
      "2019-03-18 12:58:27,366 TEST : loss 1.08317256 - f-score 0.9265 - acc 0.8631\n",
      "2019-03-18 12:58:33,975 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 12:58:34,179 epoch 55 - iter 0/469 - loss 0.14070714\n",
      "2019-03-18 12:58:41,976 epoch 55 - iter 46/469 - loss 0.20876177\n",
      "2019-03-18 12:58:49,476 epoch 55 - iter 92/469 - loss 0.17907402\n",
      "2019-03-18 12:58:57,036 epoch 55 - iter 138/469 - loss 0.18132446\n",
      "2019-03-18 12:59:04,543 epoch 55 - iter 184/469 - loss 0.18604155\n",
      "2019-03-18 12:59:11,927 epoch 55 - iter 230/469 - loss 0.17895371\n",
      "2019-03-18 12:59:19,426 epoch 55 - iter 276/469 - loss 0.17668984\n",
      "2019-03-18 12:59:26,663 epoch 55 - iter 322/469 - loss 0.17081700\n",
      "2019-03-18 12:59:34,168 epoch 55 - iter 368/469 - loss 0.16863516\n",
      "2019-03-18 12:59:42,013 epoch 55 - iter 414/469 - loss 0.16678120\n",
      "2019-03-18 12:59:49,423 epoch 55 - iter 460/469 - loss 0.16401746\n",
      "2019-03-18 12:59:50,685 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 12:59:50,686 EPOCH 55 done: loss 0.1643 - lr 0.0500 - bad epochs 0\n",
      "2019-03-18 13:00:07,943 DEV  : loss 0.54147303 - f-score 0.9541 - acc 0.9123\n",
      "2019-03-18 13:00:24,003 TEST : loss 1.06160879 - f-score 0.9265 - acc 0.8630\n",
      "2019-03-18 13:00:31,420 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 13:00:31,591 epoch 56 - iter 0/469 - loss 0.08775353\n",
      "2019-03-18 13:00:38,913 epoch 56 - iter 46/469 - loss 0.21242042\n",
      "2019-03-18 13:00:46,145 epoch 56 - iter 92/469 - loss 0.19384061\n",
      "2019-03-18 13:00:53,876 epoch 56 - iter 138/469 - loss 0.19728058\n",
      "2019-03-18 13:01:01,460 epoch 56 - iter 184/469 - loss 0.18591161\n",
      "2019-03-18 13:01:09,125 epoch 56 - iter 230/469 - loss 0.19179706\n",
      "2019-03-18 13:01:16,614 epoch 56 - iter 276/469 - loss 0.19078619\n",
      "2019-03-18 13:01:24,010 epoch 56 - iter 322/469 - loss 0.18705480\n",
      "2019-03-18 13:01:31,563 epoch 56 - iter 368/469 - loss 0.18061438\n",
      "2019-03-18 13:01:39,185 epoch 56 - iter 414/469 - loss 0.18116832\n",
      "2019-03-18 13:01:46,728 epoch 56 - iter 460/469 - loss 0.18071691\n",
      "2019-03-18 13:01:47,998 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 13:01:47,999 EPOCH 56 done: loss 0.1805 - lr 0.0500 - bad epochs 0\n",
      "2019-03-18 13:02:05,475 DEV  : loss 0.55022073 - f-score 0.9560 - acc 0.9157\n",
      "2019-03-18 13:02:21,635 TEST : loss 1.08219361 - f-score 0.9264 - acc 0.8630\n",
      "2019-03-18 13:02:21,636 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 13:02:21,816 epoch 57 - iter 0/469 - loss 0.15809578\n",
      "2019-03-18 13:02:29,343 epoch 57 - iter 46/469 - loss 0.21444550\n",
      "2019-03-18 13:02:37,040 epoch 57 - iter 92/469 - loss 0.22476756\n",
      "2019-03-18 13:02:44,831 epoch 57 - iter 138/469 - loss 0.20389174\n",
      "2019-03-18 13:02:52,307 epoch 57 - iter 184/469 - loss 0.20608304\n",
      "2019-03-18 13:02:59,843 epoch 57 - iter 230/469 - loss 0.20574144\n",
      "2019-03-18 13:03:07,424 epoch 57 - iter 276/469 - loss 0.20574589\n",
      "2019-03-18 13:03:14,903 epoch 57 - iter 322/469 - loss 0.20164487\n",
      "2019-03-18 13:03:22,422 epoch 57 - iter 368/469 - loss 0.19571241\n",
      "2019-03-18 13:03:30,098 epoch 57 - iter 414/469 - loss 0.19061754\n",
      "2019-03-18 13:03:37,627 epoch 57 - iter 460/469 - loss 0.18922114\n",
      "2019-03-18 13:03:38,790 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 13:03:38,791 EPOCH 57 done: loss 0.1880 - lr 0.0500 - bad epochs 1\n",
      "2019-03-18 13:03:56,220 DEV  : loss 0.53057355 - f-score 0.9555 - acc 0.9149\n",
      "2019-03-18 13:04:12,516 TEST : loss 1.08085489 - f-score 0.9274 - acc 0.8648\n",
      "2019-03-18 13:04:12,517 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 13:04:12,691 epoch 58 - iter 0/469 - loss 0.24232018\n",
      "2019-03-18 13:04:19,993 epoch 58 - iter 46/469 - loss 0.17892280\n",
      "2019-03-18 13:04:27,422 epoch 58 - iter 92/469 - loss 0.17813690\n",
      "2019-03-18 13:04:35,186 epoch 58 - iter 138/469 - loss 0.17914715\n",
      "2019-03-18 13:04:42,894 epoch 58 - iter 184/469 - loss 0.17573108\n",
      "2019-03-18 13:04:50,366 epoch 58 - iter 230/469 - loss 0.17632375\n",
      "2019-03-18 13:04:58,163 epoch 58 - iter 276/469 - loss 0.17620260\n",
      "2019-03-18 13:05:05,632 epoch 58 - iter 322/469 - loss 0.17124536\n",
      "2019-03-18 13:05:13,186 epoch 58 - iter 368/469 - loss 0.16901592\n",
      "2019-03-18 13:05:20,759 epoch 58 - iter 414/469 - loss 0.17305850\n",
      "2019-03-18 13:05:28,236 epoch 58 - iter 460/469 - loss 0.17082436\n",
      "2019-03-18 13:05:29,473 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 13:05:29,473 EPOCH 58 done: loss 0.1709 - lr 0.0500 - bad epochs 2\n",
      "2019-03-18 13:05:47,738 DEV  : loss 0.55168515 - f-score 0.9539 - acc 0.9118\n",
      "2019-03-18 13:06:03,988 TEST : loss 1.13690114 - f-score 0.9258 - acc 0.8620\n",
      "2019-03-18 13:06:03,990 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 13:06:04,140 epoch 59 - iter 0/469 - loss 0.26842418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-18 13:06:11,452 epoch 59 - iter 46/469 - loss 0.15684853\n",
      "2019-03-18 13:06:19,071 epoch 59 - iter 92/469 - loss 0.16871639\n",
      "2019-03-18 13:06:26,567 epoch 59 - iter 138/469 - loss 0.15563089\n",
      "2019-03-18 13:06:34,136 epoch 59 - iter 184/469 - loss 0.15286539\n",
      "2019-03-18 13:06:41,731 epoch 59 - iter 230/469 - loss 0.15063853\n",
      "2019-03-18 13:06:49,426 epoch 59 - iter 276/469 - loss 0.15515079\n",
      "2019-03-18 13:06:57,054 epoch 59 - iter 322/469 - loss 0.15549504\n",
      "2019-03-18 13:07:04,595 epoch 59 - iter 368/469 - loss 0.15822365\n",
      "2019-03-18 13:07:12,134 epoch 59 - iter 414/469 - loss 0.15570805\n",
      "2019-03-18 13:07:19,644 epoch 59 - iter 460/469 - loss 0.15464976\n",
      "2019-03-18 13:07:20,864 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 13:07:20,864 EPOCH 59 done: loss 0.1543 - lr 0.0500 - bad epochs 3\n",
      "2019-03-18 13:07:37,927 DEV  : loss 0.56940091 - f-score 0.9556 - acc 0.9150\n",
      "2019-03-18 13:07:53,887 TEST : loss 1.15552080 - f-score 0.9274 - acc 0.8646\n",
      "2019-03-18 13:08:00,481 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 13:08:00,676 epoch 60 - iter 0/469 - loss 0.01685160\n",
      "2019-03-18 13:08:08,105 epoch 60 - iter 46/469 - loss 0.19657689\n",
      "2019-03-18 13:08:15,505 epoch 60 - iter 92/469 - loss 0.17115689\n",
      "2019-03-18 13:08:23,309 epoch 60 - iter 138/469 - loss 0.15285763\n",
      "2019-03-18 13:08:30,907 epoch 60 - iter 184/469 - loss 0.15807626\n",
      "2019-03-18 13:08:38,303 epoch 60 - iter 230/469 - loss 0.15541194\n",
      "2019-03-18 13:08:46,176 epoch 60 - iter 276/469 - loss 0.15746671\n",
      "2019-03-18 13:08:53,693 epoch 60 - iter 322/469 - loss 0.15508480\n",
      "2019-03-18 13:09:01,095 epoch 60 - iter 368/469 - loss 0.16237036\n",
      "2019-03-18 13:09:08,615 epoch 60 - iter 414/469 - loss 0.16181750\n",
      "2019-03-18 13:09:16,238 epoch 60 - iter 460/469 - loss 0.16336801\n",
      "2019-03-18 13:09:17,500 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 13:09:17,501 EPOCH 60 done: loss 0.1632 - lr 0.0500 - bad epochs 0\n",
      "2019-03-18 13:09:35,701 DEV  : loss 0.56316578 - f-score 0.9546 - acc 0.9132\n",
      "2019-03-18 13:09:51,874 TEST : loss 1.12777019 - f-score 0.9295 - acc 0.8684\n",
      "2019-03-18 13:09:51,875 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 13:09:52,029 epoch 61 - iter 0/469 - loss 0.08410680\n",
      "2019-03-18 13:09:59,331 epoch 61 - iter 46/469 - loss 0.17789235\n",
      "2019-03-18 13:10:06,928 epoch 61 - iter 92/469 - loss 0.18709323\n",
      "2019-03-18 13:10:14,574 epoch 61 - iter 138/469 - loss 0.18418921\n",
      "2019-03-18 13:10:22,279 epoch 61 - iter 184/469 - loss 0.18202634\n",
      "2019-03-18 13:10:29,808 epoch 61 - iter 230/469 - loss 0.17704595\n",
      "2019-03-18 13:10:37,191 epoch 61 - iter 276/469 - loss 0.17118446\n",
      "2019-03-18 13:10:44,783 epoch 61 - iter 322/469 - loss 0.17100952\n",
      "2019-03-18 13:10:52,394 epoch 61 - iter 368/469 - loss 0.16509112\n",
      "2019-03-18 13:10:59,909 epoch 61 - iter 414/469 - loss 0.16742669\n",
      "2019-03-18 13:11:07,760 epoch 61 - iter 460/469 - loss 0.16797896\n",
      "2019-03-18 13:11:08,995 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 13:11:08,995 EPOCH 61 done: loss 0.1695 - lr 0.0500 - bad epochs 1\n",
      "2019-03-18 13:11:26,448 DEV  : loss 0.54893512 - f-score 0.9548 - acc 0.9137\n",
      "2019-03-18 13:11:42,729 TEST : loss 1.16360784 - f-score 0.9249 - acc 0.8604\n",
      "2019-03-18 13:11:42,730 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 13:11:42,877 epoch 62 - iter 0/469 - loss 0.02708605\n",
      "2019-03-18 13:11:50,354 epoch 62 - iter 46/469 - loss 0.12974042\n",
      "2019-03-18 13:11:57,809 epoch 62 - iter 92/469 - loss 0.15355319\n",
      "2019-03-18 13:12:05,435 epoch 62 - iter 138/469 - loss 0.16080755\n",
      "2019-03-18 13:12:12,985 epoch 62 - iter 184/469 - loss 0.15820919\n",
      "2019-03-18 13:12:20,866 epoch 62 - iter 230/469 - loss 0.15298508\n",
      "2019-03-18 13:12:28,577 epoch 62 - iter 276/469 - loss 0.15588051\n",
      "2019-03-18 13:12:35,993 epoch 62 - iter 322/469 - loss 0.15468571\n",
      "2019-03-18 13:12:43,744 epoch 62 - iter 368/469 - loss 0.15951238\n",
      "2019-03-18 13:12:51,295 epoch 62 - iter 414/469 - loss 0.15756343\n",
      "2019-03-18 13:12:58,700 epoch 62 - iter 460/469 - loss 0.16162868\n",
      "2019-03-18 13:12:59,957 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 13:12:59,958 EPOCH 62 done: loss 0.1615 - lr 0.0500 - bad epochs 2\n",
      "2019-03-18 13:13:17,276 DEV  : loss 0.53820765 - f-score 0.9561 - acc 0.9159\n",
      "2019-03-18 13:13:33,432 TEST : loss 1.09364271 - f-score 0.9290 - acc 0.8674\n",
      "2019-03-18 13:13:33,433 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 13:13:33,619 epoch 63 - iter 0/469 - loss 0.31465417\n",
      "2019-03-18 13:13:41,069 epoch 63 - iter 46/469 - loss 0.16014962\n",
      "2019-03-18 13:13:48,632 epoch 63 - iter 92/469 - loss 0.18532511\n",
      "2019-03-18 13:13:56,211 epoch 63 - iter 138/469 - loss 0.18265720\n",
      "2019-03-18 13:14:03,834 epoch 63 - iter 184/469 - loss 0.17913170\n",
      "2019-03-18 13:14:11,973 epoch 63 - iter 230/469 - loss 0.17144892\n",
      "2019-03-18 13:14:19,560 epoch 63 - iter 276/469 - loss 0.16938843\n",
      "2019-03-18 13:14:27,119 epoch 63 - iter 322/469 - loss 0.16913174\n",
      "2019-03-18 13:14:34,953 epoch 63 - iter 368/469 - loss 0.16859230\n",
      "2019-03-18 13:14:42,719 epoch 63 - iter 414/469 - loss 0.16838996\n",
      "2019-03-18 13:14:50,806 epoch 63 - iter 460/469 - loss 0.16170473\n",
      "2019-03-18 13:14:52,130 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 13:14:52,131 EPOCH 63 done: loss 0.1628 - lr 0.0500 - bad epochs 3\n",
      "2019-03-18 13:15:09,670 DEV  : loss 0.57356113 - f-score 0.9545 - acc 0.9130\n",
      "2019-03-18 13:15:26,197 TEST : loss 1.12865210 - f-score 0.9271 - acc 0.8641\n",
      "Epoch    62: reducing learning rate of group 0 to 2.5000e-02.\n",
      "2019-03-18 13:15:26,199 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 13:15:26,398 epoch 64 - iter 0/469 - loss 0.37249434\n",
      "2019-03-18 13:15:34,461 epoch 64 - iter 46/469 - loss 0.18182118\n",
      "2019-03-18 13:15:42,204 epoch 64 - iter 92/469 - loss 0.16836435\n",
      "2019-03-18 13:15:49,894 epoch 64 - iter 138/469 - loss 0.15548008\n",
      "2019-03-18 13:15:57,675 epoch 64 - iter 184/469 - loss 0.17096934\n",
      "2019-03-18 13:16:05,437 epoch 64 - iter 230/469 - loss 0.16139449\n",
      "2019-03-18 13:16:13,354 epoch 64 - iter 276/469 - loss 0.15904995\n",
      "2019-03-18 13:16:21,276 epoch 64 - iter 322/469 - loss 0.15445118\n",
      "2019-03-18 13:16:29,173 epoch 64 - iter 368/469 - loss 0.15920544\n",
      "2019-03-18 13:16:36,930 epoch 64 - iter 414/469 - loss 0.15533755\n",
      "2019-03-18 13:16:44,627 epoch 64 - iter 460/469 - loss 0.15807388\n",
      "2019-03-18 13:16:45,919 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 13:16:45,919 EPOCH 64 done: loss 0.1568 - lr 0.0250 - bad epochs 0\n",
      "2019-03-18 13:17:03,822 DEV  : loss 0.57862532 - f-score 0.9539 - acc 0.9118\n",
      "2019-03-18 13:17:20,510 TEST : loss 1.11089373 - f-score 0.9268 - acc 0.8636\n",
      "2019-03-18 13:17:20,512 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 13:17:20,694 epoch 65 - iter 0/469 - loss 0.11742359\n",
      "2019-03-18 13:17:28,048 epoch 65 - iter 46/469 - loss 0.14934023\n",
      "2019-03-18 13:17:35,961 epoch 65 - iter 92/469 - loss 0.15584838\n",
      "2019-03-18 13:17:43,734 epoch 65 - iter 138/469 - loss 0.14625804\n",
      "2019-03-18 13:17:51,658 epoch 65 - iter 184/469 - loss 0.13659701\n",
      "2019-03-18 13:17:59,359 epoch 65 - iter 230/469 - loss 0.14336727\n",
      "2019-03-18 13:18:07,068 epoch 65 - iter 276/469 - loss 0.14571345\n",
      "2019-03-18 13:18:14,678 epoch 65 - iter 322/469 - loss 0.14443018\n",
      "2019-03-18 13:18:22,876 epoch 65 - iter 368/469 - loss 0.14634685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-18 13:18:30,555 epoch 65 - iter 414/469 - loss 0.14411148\n",
      "2019-03-18 13:18:38,492 epoch 65 - iter 460/469 - loss 0.14701763\n",
      "2019-03-18 13:18:39,710 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 13:18:39,710 EPOCH 65 done: loss 0.1471 - lr 0.0250 - bad epochs 1\n",
      "2019-03-18 13:18:59,230 DEV  : loss 0.56669843 - f-score 0.9541 - acc 0.9123\n",
      "2019-03-18 13:19:16,362 TEST : loss 1.13989592 - f-score 0.9281 - acc 0.8659\n",
      "2019-03-18 13:19:22,698 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 13:19:22,879 epoch 66 - iter 0/469 - loss 0.01953363\n",
      "2019-03-18 13:19:30,586 epoch 66 - iter 46/469 - loss 0.15464561\n",
      "2019-03-18 13:19:38,436 epoch 66 - iter 92/469 - loss 0.13868327\n",
      "2019-03-18 13:19:46,253 epoch 66 - iter 138/469 - loss 0.13498162\n",
      "2019-03-18 13:19:53,951 epoch 66 - iter 184/469 - loss 0.13458789\n",
      "2019-03-18 13:20:02,146 epoch 66 - iter 230/469 - loss 0.13203812\n",
      "2019-03-18 13:20:09,660 epoch 66 - iter 276/469 - loss 0.13805420\n",
      "2019-03-18 13:20:17,418 epoch 66 - iter 322/469 - loss 0.13473592\n",
      "2019-03-18 13:20:25,285 epoch 66 - iter 368/469 - loss 0.13696077\n",
      "2019-03-18 13:20:33,211 epoch 66 - iter 414/469 - loss 0.14053736\n",
      "2019-03-18 13:20:40,846 epoch 66 - iter 460/469 - loss 0.13760071\n",
      "2019-03-18 13:20:42,042 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 13:20:42,043 EPOCH 66 done: loss 0.1388 - lr 0.0250 - bad epochs 0\n",
      "2019-03-18 13:20:59,987 DEV  : loss 0.57070762 - f-score 0.9546 - acc 0.9131\n",
      "2019-03-18 13:21:16,773 TEST : loss 1.13689232 - f-score 0.9274 - acc 0.8647\n",
      "2019-03-18 13:21:24,705 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 13:21:24,876 epoch 67 - iter 0/469 - loss 0.07264364\n",
      "2019-03-18 13:21:32,864 epoch 67 - iter 46/469 - loss 0.15891866\n",
      "2019-03-18 13:21:40,451 epoch 67 - iter 92/469 - loss 0.13750471\n",
      "2019-03-18 13:21:48,493 epoch 67 - iter 138/469 - loss 0.13594798\n",
      "2019-03-18 13:21:56,226 epoch 67 - iter 184/469 - loss 0.13211680\n",
      "2019-03-18 13:22:04,053 epoch 67 - iter 230/469 - loss 0.14342465\n",
      "2019-03-18 13:22:11,533 epoch 67 - iter 276/469 - loss 0.14383661\n",
      "2019-03-18 13:22:19,489 epoch 67 - iter 322/469 - loss 0.14162959\n",
      "2019-03-18 13:22:27,368 epoch 67 - iter 368/469 - loss 0.13950198\n",
      "2019-03-18 13:22:34,999 epoch 67 - iter 414/469 - loss 0.13798894\n",
      "2019-03-18 13:22:42,936 epoch 67 - iter 460/469 - loss 0.13714468\n",
      "2019-03-18 13:22:44,171 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 13:22:44,171 EPOCH 67 done: loss 0.1366 - lr 0.0250 - bad epochs 0\n",
      "2019-03-18 13:23:02,503 DEV  : loss 0.57604641 - f-score 0.9547 - acc 0.9134\n",
      "2019-03-18 13:23:19,310 TEST : loss 1.16768444 - f-score 0.9295 - acc 0.8683\n",
      "2019-03-18 13:23:25,987 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 13:23:26,144 epoch 68 - iter 0/469 - loss 0.10686558\n",
      "2019-03-18 13:23:33,804 epoch 68 - iter 46/469 - loss 0.13436873\n",
      "2019-03-18 13:23:41,806 epoch 68 - iter 92/469 - loss 0.12882975\n",
      "2019-03-18 13:23:49,572 epoch 68 - iter 138/469 - loss 0.13677058\n",
      "2019-03-18 13:23:57,576 epoch 68 - iter 184/469 - loss 0.13915212\n",
      "2019-03-18 13:24:05,431 epoch 68 - iter 230/469 - loss 0.14343404\n",
      "2019-03-18 13:24:13,308 epoch 68 - iter 276/469 - loss 0.13831280\n",
      "2019-03-18 13:24:21,235 epoch 68 - iter 322/469 - loss 0.13800807\n",
      "2019-03-18 13:24:28,858 epoch 68 - iter 368/469 - loss 0.14286757\n",
      "2019-03-18 13:24:36,992 epoch 68 - iter 414/469 - loss 0.14437953\n",
      "2019-03-18 13:24:44,882 epoch 68 - iter 460/469 - loss 0.14380850\n",
      "2019-03-18 13:24:46,181 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 13:24:46,182 EPOCH 68 done: loss 0.1452 - lr 0.0250 - bad epochs 0\n",
      "2019-03-18 13:25:04,546 DEV  : loss 0.57564425 - f-score 0.9555 - acc 0.9148\n",
      "2019-03-18 13:25:22,645 TEST : loss 1.18919432 - f-score 0.9296 - acc 0.8685\n",
      "2019-03-18 13:25:22,646 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 13:25:22,812 epoch 69 - iter 0/469 - loss 0.02355564\n",
      "2019-03-18 13:25:30,710 epoch 69 - iter 46/469 - loss 0.17829547\n",
      "2019-03-18 13:25:38,691 epoch 69 - iter 92/469 - loss 0.15239807\n",
      "2019-03-18 13:25:46,697 epoch 69 - iter 138/469 - loss 0.15082622\n",
      "2019-03-18 13:25:54,521 epoch 69 - iter 184/469 - loss 0.15406354\n",
      "2019-03-18 13:26:02,537 epoch 69 - iter 230/469 - loss 0.15649923\n",
      "2019-03-18 13:26:10,485 epoch 69 - iter 276/469 - loss 0.17037519\n",
      "2019-03-18 13:26:18,283 epoch 69 - iter 322/469 - loss 0.16233443\n",
      "2019-03-18 13:26:26,007 epoch 69 - iter 368/469 - loss 0.15767324\n",
      "2019-03-18 13:26:33,915 epoch 69 - iter 414/469 - loss 0.15615003\n",
      "2019-03-18 13:26:41,898 epoch 69 - iter 460/469 - loss 0.15461211\n",
      "2019-03-18 13:26:43,130 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 13:26:43,131 EPOCH 69 done: loss 0.1536 - lr 0.0250 - bad epochs 1\n",
      "2019-03-18 13:27:00,989 DEV  : loss 0.55556291 - f-score 0.9570 - acc 0.9175\n",
      "2019-03-18 13:27:17,919 TEST : loss 1.17631960 - f-score 0.9300 - acc 0.8691\n",
      "2019-03-18 13:27:17,921 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 13:27:18,114 epoch 70 - iter 0/469 - loss 0.14697921\n",
      "2019-03-18 13:27:25,851 epoch 70 - iter 46/469 - loss 0.12452481\n",
      "2019-03-18 13:27:33,824 epoch 70 - iter 92/469 - loss 0.11785762\n",
      "2019-03-18 13:27:41,578 epoch 70 - iter 138/469 - loss 0.12873991\n",
      "2019-03-18 13:27:49,407 epoch 70 - iter 184/469 - loss 0.12691878\n",
      "2019-03-18 13:27:57,186 epoch 70 - iter 230/469 - loss 0.12850029\n",
      "2019-03-18 13:28:05,040 epoch 70 - iter 276/469 - loss 0.13230665\n",
      "2019-03-18 13:28:13,057 epoch 70 - iter 322/469 - loss 0.13799839\n",
      "2019-03-18 13:28:20,954 epoch 70 - iter 368/469 - loss 0.13792272\n",
      "2019-03-18 13:28:28,723 epoch 70 - iter 414/469 - loss 0.13987396\n",
      "2019-03-18 13:28:36,328 epoch 70 - iter 460/469 - loss 0.13928327\n",
      "2019-03-18 13:28:37,644 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 13:28:37,645 EPOCH 70 done: loss 0.1395 - lr 0.0250 - bad epochs 2\n",
      "2019-03-18 13:28:55,614 DEV  : loss 0.57622349 - f-score 0.9574 - acc 0.9183\n",
      "2019-03-18 13:29:12,490 TEST : loss 1.15726554 - f-score 0.9292 - acc 0.8678\n",
      "2019-03-18 13:29:12,492 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 13:29:12,658 epoch 71 - iter 0/469 - loss 0.03284106\n",
      "2019-03-18 13:29:20,567 epoch 71 - iter 46/469 - loss 0.20076491\n",
      "2019-03-18 13:29:28,527 epoch 71 - iter 92/469 - loss 0.16780204\n",
      "2019-03-18 13:29:36,263 epoch 71 - iter 138/469 - loss 0.15470763\n",
      "2019-03-18 13:29:44,128 epoch 71 - iter 184/469 - loss 0.15390211\n",
      "2019-03-18 13:29:52,041 epoch 71 - iter 230/469 - loss 0.15049424\n",
      "2019-03-18 13:29:59,626 epoch 71 - iter 276/469 - loss 0.15771903\n",
      "2019-03-18 13:30:07,879 epoch 71 - iter 322/469 - loss 0.16054322\n",
      "2019-03-18 13:30:15,577 epoch 71 - iter 368/469 - loss 0.15592384\n",
      "2019-03-18 13:30:23,396 epoch 71 - iter 414/469 - loss 0.15605719\n",
      "2019-03-18 13:30:31,225 epoch 71 - iter 460/469 - loss 0.15783861\n",
      "2019-03-18 13:30:32,409 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 13:30:32,410 EPOCH 71 done: loss 0.1588 - lr 0.0250 - bad epochs 3\n",
      "2019-03-18 13:30:51,138 DEV  : loss 0.57926130 - f-score 0.9557 - acc 0.9152\n",
      "2019-03-18 13:31:07,765 TEST : loss 1.18032157 - f-score 0.9282 - acc 0.8661\n",
      "Epoch    70: reducing learning rate of group 0 to 1.2500e-02.\n",
      "2019-03-18 13:31:07,767 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 13:31:07,937 epoch 72 - iter 0/469 - loss 0.10614109\n",
      "2019-03-18 13:31:15,464 epoch 72 - iter 46/469 - loss 0.14247953\n",
      "2019-03-18 13:31:23,150 epoch 72 - iter 92/469 - loss 0.14923702\n",
      "2019-03-18 13:31:30,976 epoch 72 - iter 138/469 - loss 0.15283926\n",
      "2019-03-18 13:31:38,718 epoch 72 - iter 184/469 - loss 0.14696321\n",
      "2019-03-18 13:31:46,285 epoch 72 - iter 230/469 - loss 0.15290205\n",
      "2019-03-18 13:31:54,089 epoch 72 - iter 276/469 - loss 0.15256169\n",
      "2019-03-18 13:32:01,730 epoch 72 - iter 322/469 - loss 0.14774583\n",
      "2019-03-18 13:32:09,456 epoch 72 - iter 368/469 - loss 0.14445075\n",
      "2019-03-18 13:32:17,115 epoch 72 - iter 414/469 - loss 0.14013842\n",
      "2019-03-18 13:32:24,851 epoch 72 - iter 460/469 - loss 0.13557822\n",
      "2019-03-18 13:32:26,095 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 13:32:26,096 EPOCH 72 done: loss 0.1362 - lr 0.0125 - bad epochs 0\n",
      "2019-03-18 13:32:43,653 DEV  : loss 0.57511890 - f-score 0.9559 - acc 0.9155\n",
      "2019-03-18 13:33:00,509 TEST : loss 1.17046428 - f-score 0.9295 - acc 0.8684\n",
      "2019-03-18 13:33:07,816 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 13:33:08,004 epoch 73 - iter 0/469 - loss 0.02165377\n",
      "2019-03-18 13:33:15,754 epoch 73 - iter 46/469 - loss 0.15358386\n",
      "2019-03-18 13:33:23,987 epoch 73 - iter 92/469 - loss 0.15417834\n",
      "2019-03-18 13:33:31,687 epoch 73 - iter 138/469 - loss 0.14069064\n",
      "2019-03-18 13:33:39,346 epoch 73 - iter 184/469 - loss 0.14071476\n",
      "2019-03-18 13:33:47,107 epoch 73 - iter 230/469 - loss 0.14537626\n",
      "2019-03-18 13:33:54,982 epoch 73 - iter 276/469 - loss 0.14056547\n",
      "2019-03-18 13:34:02,831 epoch 73 - iter 322/469 - loss 0.13827308\n",
      "2019-03-18 13:34:10,519 epoch 73 - iter 368/469 - loss 0.13502985\n",
      "2019-03-18 13:34:18,251 epoch 73 - iter 414/469 - loss 0.13005181\n",
      "2019-03-18 13:34:25,878 epoch 73 - iter 460/469 - loss 0.12712677\n",
      "2019-03-18 13:34:27,185 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 13:34:27,186 EPOCH 73 done: loss 0.1276 - lr 0.0125 - bad epochs 0\n",
      "2019-03-18 13:34:45,799 DEV  : loss 0.58642334 - f-score 0.9563 - acc 0.9163\n",
      "2019-03-18 13:35:02,135 TEST : loss 1.18279696 - f-score 0.9300 - acc 0.8692\n",
      "2019-03-18 13:35:08,885 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 13:35:09,076 epoch 74 - iter 0/469 - loss 0.48636109\n",
      "2019-03-18 13:35:16,339 epoch 74 - iter 46/469 - loss 0.14313125\n",
      "2019-03-18 13:35:24,011 epoch 74 - iter 92/469 - loss 0.14063551\n",
      "2019-03-18 13:35:31,859 epoch 74 - iter 138/469 - loss 0.12626260\n",
      "2019-03-18 13:35:39,582 epoch 74 - iter 184/469 - loss 0.12614435\n",
      "2019-03-18 13:35:47,461 epoch 74 - iter 230/469 - loss 0.12809614\n",
      "2019-03-18 13:35:55,284 epoch 74 - iter 276/469 - loss 0.12735716\n",
      "2019-03-18 13:36:03,200 epoch 74 - iter 322/469 - loss 0.13194706\n",
      "2019-03-18 13:36:10,936 epoch 74 - iter 368/469 - loss 0.13175845\n",
      "2019-03-18 13:36:18,432 epoch 74 - iter 414/469 - loss 0.13148907\n",
      "2019-03-18 13:36:26,197 epoch 74 - iter 460/469 - loss 0.13120137\n",
      "2019-03-18 13:36:27,491 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 13:36:27,492 EPOCH 74 done: loss 0.1323 - lr 0.0125 - bad epochs 0\n",
      "2019-03-18 13:36:44,869 DEV  : loss 0.57993662 - f-score 0.9564 - acc 0.9164\n",
      "2019-03-18 13:37:01,147 TEST : loss 1.19446623 - f-score 0.9303 - acc 0.8697\n",
      "2019-03-18 13:37:01,148 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 13:37:01,309 epoch 75 - iter 0/469 - loss 0.02074403\n",
      "2019-03-18 13:37:08,597 epoch 75 - iter 46/469 - loss 0.15030489\n",
      "2019-03-18 13:37:15,899 epoch 75 - iter 92/469 - loss 0.13183970\n",
      "2019-03-18 13:37:23,504 epoch 75 - iter 138/469 - loss 0.13894191\n",
      "2019-03-18 13:37:31,238 epoch 75 - iter 184/469 - loss 0.14266279\n",
      "2019-03-18 13:37:39,018 epoch 75 - iter 230/469 - loss 0.14287344\n",
      "2019-03-18 13:37:47,155 epoch 75 - iter 276/469 - loss 0.14561812\n",
      "2019-03-18 13:37:55,209 epoch 75 - iter 322/469 - loss 0.14245162\n",
      "2019-03-18 13:38:03,126 epoch 75 - iter 368/469 - loss 0.13823038\n",
      "2019-03-18 13:38:11,287 epoch 75 - iter 414/469 - loss 0.14402857\n",
      "2019-03-18 13:38:19,108 epoch 75 - iter 460/469 - loss 0.14768165\n",
      "2019-03-18 13:38:20,469 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 13:38:20,470 EPOCH 75 done: loss 0.1469 - lr 0.0125 - bad epochs 1\n",
      "2019-03-18 13:38:39,028 DEV  : loss 0.59141421 - f-score 0.9559 - acc 0.9155\n",
      "2019-03-18 13:38:55,122 TEST : loss 1.20105660 - f-score 0.9296 - acc 0.8684\n",
      "2019-03-18 13:38:55,123 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 13:38:55,307 epoch 76 - iter 0/469 - loss 0.28665426\n",
      "2019-03-18 13:39:03,276 epoch 76 - iter 46/469 - loss 0.12941615\n",
      "2019-03-18 13:39:11,102 epoch 76 - iter 92/469 - loss 0.11771214\n",
      "2019-03-18 13:39:18,621 epoch 76 - iter 138/469 - loss 0.13490397\n",
      "2019-03-18 13:39:26,206 epoch 76 - iter 184/469 - loss 0.13756394\n",
      "2019-03-18 13:39:33,809 epoch 76 - iter 230/469 - loss 0.13764824\n",
      "2019-03-18 13:39:41,553 epoch 76 - iter 276/469 - loss 0.14179801\n",
      "2019-03-18 13:39:49,431 epoch 76 - iter 322/469 - loss 0.13995517\n",
      "2019-03-18 13:39:57,253 epoch 76 - iter 368/469 - loss 0.14028931\n",
      "2019-03-18 13:40:04,918 epoch 76 - iter 414/469 - loss 0.13881335\n",
      "2019-03-18 13:40:12,669 epoch 76 - iter 460/469 - loss 0.14157415\n",
      "2019-03-18 13:40:13,928 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 13:40:13,929 EPOCH 76 done: loss 0.1414 - lr 0.0125 - bad epochs 2\n",
      "2019-03-18 13:40:31,949 DEV  : loss 0.58922189 - f-score 0.9560 - acc 0.9157\n",
      "2019-03-18 13:40:48,719 TEST : loss 1.20486987 - f-score 0.9292 - acc 0.8679\n",
      "2019-03-18 13:40:48,720 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 13:40:48,927 epoch 77 - iter 0/469 - loss 0.25470084\n",
      "2019-03-18 13:40:56,801 epoch 77 - iter 46/469 - loss 0.16813661\n",
      "2019-03-18 13:41:04,627 epoch 77 - iter 92/469 - loss 0.14260817\n",
      "2019-03-18 13:41:12,830 epoch 77 - iter 138/469 - loss 0.14314571\n",
      "2019-03-18 13:41:20,793 epoch 77 - iter 184/469 - loss 0.14196476\n",
      "2019-03-18 13:41:28,550 epoch 77 - iter 230/469 - loss 0.13158572\n",
      "2019-03-18 13:41:36,521 epoch 77 - iter 276/469 - loss 0.13114767\n",
      "2019-03-18 13:41:44,415 epoch 77 - iter 322/469 - loss 0.13084961\n",
      "2019-03-18 13:41:52,258 epoch 77 - iter 368/469 - loss 0.12824736\n",
      "2019-03-18 13:42:00,466 epoch 77 - iter 414/469 - loss 0.13008199\n",
      "2019-03-18 13:42:08,619 epoch 77 - iter 460/469 - loss 0.12886159\n",
      "2019-03-18 13:42:09,923 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 13:42:09,923 EPOCH 77 done: loss 0.1301 - lr 0.0125 - bad epochs 3\n",
      "2019-03-18 13:42:28,429 DEV  : loss 0.59279746 - f-score 0.9562 - acc 0.9162\n",
      "2019-03-18 13:42:45,776 TEST : loss 1.20178115 - f-score 0.9283 - acc 0.8662\n",
      "Epoch    76: reducing learning rate of group 0 to 6.2500e-03.\n",
      "2019-03-18 13:42:45,777 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 13:42:45,964 epoch 78 - iter 0/469 - loss 0.00981975\n",
      "2019-03-18 13:42:53,780 epoch 78 - iter 46/469 - loss 0.13366503\n",
      "2019-03-18 13:43:01,289 epoch 78 - iter 92/469 - loss 0.15737987\n",
      "2019-03-18 13:43:09,966 epoch 78 - iter 138/469 - loss 0.14704128\n",
      "2019-03-18 13:43:17,517 epoch 78 - iter 184/469 - loss 0.13166981\n",
      "2019-03-18 13:43:25,706 epoch 78 - iter 230/469 - loss 0.13248743\n",
      "2019-03-18 13:43:33,623 epoch 78 - iter 276/469 - loss 0.13267757\n",
      "2019-03-18 13:43:41,270 epoch 78 - iter 322/469 - loss 0.12814866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-18 13:43:49,379 epoch 78 - iter 368/469 - loss 0.12939415\n",
      "2019-03-18 13:43:57,156 epoch 78 - iter 414/469 - loss 0.12546803\n",
      "2019-03-18 13:44:04,909 epoch 78 - iter 460/469 - loss 0.12236029\n",
      "2019-03-18 13:44:06,176 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 13:44:06,177 EPOCH 78 done: loss 0.1226 - lr 0.0063 - bad epochs 0\n",
      "2019-03-18 13:44:23,859 DEV  : loss 0.59300584 - f-score 0.9557 - acc 0.9152\n",
      "2019-03-18 13:44:40,555 TEST : loss 1.20712960 - f-score 0.9289 - acc 0.8674\n",
      "2019-03-18 13:44:48,229 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 13:44:48,430 epoch 79 - iter 0/469 - loss 0.23177516\n",
      "2019-03-18 13:44:55,930 epoch 79 - iter 46/469 - loss 0.09792545\n",
      "2019-03-18 13:45:03,785 epoch 79 - iter 92/469 - loss 0.11938514\n",
      "2019-03-18 13:45:11,650 epoch 79 - iter 138/469 - loss 0.12953231\n",
      "2019-03-18 13:45:19,157 epoch 79 - iter 184/469 - loss 0.13345276\n",
      "2019-03-18 13:45:27,033 epoch 79 - iter 230/469 - loss 0.12706313\n",
      "2019-03-18 13:45:34,736 epoch 79 - iter 276/469 - loss 0.13226472\n",
      "2019-03-18 13:45:42,549 epoch 79 - iter 322/469 - loss 0.12953393\n",
      "2019-03-18 13:45:50,655 epoch 79 - iter 368/469 - loss 0.12919565\n",
      "2019-03-18 13:45:58,386 epoch 79 - iter 414/469 - loss 0.13377734\n",
      "2019-03-18 13:46:06,176 epoch 79 - iter 460/469 - loss 0.13767429\n",
      "2019-03-18 13:46:07,475 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 13:46:07,475 EPOCH 79 done: loss 0.1383 - lr 0.0063 - bad epochs 0\n",
      "2019-03-18 13:46:25,100 DEV  : loss 0.59743834 - f-score 0.9557 - acc 0.9152\n",
      "2019-03-18 13:46:42,225 TEST : loss 1.20889854 - f-score 0.9295 - acc 0.8683\n",
      "2019-03-18 13:46:42,226 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 13:46:42,386 epoch 80 - iter 0/469 - loss 0.10778755\n",
      "2019-03-18 13:46:50,206 epoch 80 - iter 46/469 - loss 0.15311327\n",
      "2019-03-18 13:46:57,780 epoch 80 - iter 92/469 - loss 0.16397500\n",
      "2019-03-18 13:47:05,433 epoch 80 - iter 138/469 - loss 0.15137262\n",
      "2019-03-18 13:47:13,254 epoch 80 - iter 184/469 - loss 0.15633145\n",
      "2019-03-18 13:47:20,854 epoch 80 - iter 230/469 - loss 0.15122328\n",
      "2019-03-18 13:47:28,634 epoch 80 - iter 276/469 - loss 0.15871719\n",
      "2019-03-18 13:47:36,209 epoch 80 - iter 322/469 - loss 0.15268866\n",
      "2019-03-18 13:47:43,834 epoch 80 - iter 368/469 - loss 0.15171641\n",
      "2019-03-18 13:47:51,437 epoch 80 - iter 414/469 - loss 0.14648232\n",
      "2019-03-18 13:47:59,064 epoch 80 - iter 460/469 - loss 0.14850599\n",
      "2019-03-18 13:48:00,301 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 13:48:00,301 EPOCH 80 done: loss 0.1471 - lr 0.0063 - bad epochs 1\n",
      "2019-03-18 13:48:18,088 DEV  : loss 0.59320945 - f-score 0.9553 - acc 0.9145\n",
      "2019-03-18 13:48:35,120 TEST : loss 1.21005321 - f-score 0.9294 - acc 0.8681\n",
      "2019-03-18 13:48:35,121 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 13:48:35,331 epoch 81 - iter 0/469 - loss 0.05167729\n",
      "2019-03-18 13:48:42,760 epoch 81 - iter 46/469 - loss 0.14163865\n",
      "2019-03-18 13:48:50,616 epoch 81 - iter 92/469 - loss 0.13875845\n",
      "2019-03-18 13:48:58,197 epoch 81 - iter 138/469 - loss 0.13747537\n",
      "2019-03-18 13:49:05,743 epoch 81 - iter 184/469 - loss 0.12659532\n",
      "2019-03-18 13:49:13,448 epoch 81 - iter 230/469 - loss 0.12722607\n",
      "2019-03-18 13:49:21,213 epoch 81 - iter 276/469 - loss 0.12421202\n",
      "2019-03-18 13:49:29,092 epoch 81 - iter 322/469 - loss 0.12392644\n",
      "2019-03-18 13:49:37,267 epoch 81 - iter 368/469 - loss 0.12330469\n",
      "2019-03-18 13:49:45,114 epoch 81 - iter 414/469 - loss 0.12463632\n",
      "2019-03-18 13:49:53,026 epoch 81 - iter 460/469 - loss 0.12486631\n",
      "2019-03-18 13:49:54,348 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 13:49:54,349 EPOCH 81 done: loss 0.1236 - lr 0.0063 - bad epochs 2\n",
      "2019-03-18 13:50:12,423 DEV  : loss 0.59828538 - f-score 0.9555 - acc 0.9148\n",
      "2019-03-18 13:50:29,493 TEST : loss 1.20706427 - f-score 0.9288 - acc 0.8670\n",
      "2019-03-18 13:50:29,495 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 13:50:29,677 epoch 82 - iter 0/469 - loss 0.06757587\n",
      "2019-03-18 13:50:37,103 epoch 82 - iter 46/469 - loss 0.11614338\n",
      "2019-03-18 13:50:44,876 epoch 82 - iter 92/469 - loss 0.13110586\n",
      "2019-03-18 13:50:52,681 epoch 82 - iter 138/469 - loss 0.14003899\n",
      "2019-03-18 13:51:00,468 epoch 82 - iter 184/469 - loss 0.13927808\n",
      "2019-03-18 13:51:08,606 epoch 82 - iter 230/469 - loss 0.13995772\n",
      "2019-03-18 13:51:16,689 epoch 82 - iter 276/469 - loss 0.13682605\n",
      "2019-03-18 13:51:24,424 epoch 82 - iter 322/469 - loss 0.12929241\n",
      "2019-03-18 13:51:32,222 epoch 82 - iter 368/469 - loss 0.12796090\n",
      "2019-03-18 13:51:40,234 epoch 82 - iter 414/469 - loss 0.12783656\n",
      "2019-03-18 13:51:48,323 epoch 82 - iter 460/469 - loss 0.12227145\n",
      "2019-03-18 13:51:49,618 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 13:51:49,619 EPOCH 82 done: loss 0.1226 - lr 0.0063 - bad epochs 3\n",
      "2019-03-18 13:52:08,618 DEV  : loss 0.59573209 - f-score 0.9564 - acc 0.9165\n",
      "2019-03-18 13:52:25,687 TEST : loss 1.21673298 - f-score 0.9289 - acc 0.8673\n",
      "Epoch    81: reducing learning rate of group 0 to 3.1250e-03.\n",
      "2019-03-18 13:52:25,690 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 13:52:25,850 epoch 83 - iter 0/469 - loss 0.00467998\n",
      "2019-03-18 13:52:33,682 epoch 83 - iter 46/469 - loss 0.13310060\n",
      "2019-03-18 13:52:41,443 epoch 83 - iter 92/469 - loss 0.12982416\n",
      "2019-03-18 13:52:49,185 epoch 83 - iter 138/469 - loss 0.12798623\n",
      "2019-03-18 13:52:57,002 epoch 83 - iter 184/469 - loss 0.12690357\n",
      "2019-03-18 13:53:04,535 epoch 83 - iter 230/469 - loss 0.12110386\n",
      "2019-03-18 13:53:12,304 epoch 83 - iter 276/469 - loss 0.11539693\n",
      "2019-03-18 13:53:20,072 epoch 83 - iter 322/469 - loss 0.11344786\n",
      "2019-03-18 13:53:28,108 epoch 83 - iter 368/469 - loss 0.11571269\n",
      "2019-03-18 13:53:36,113 epoch 83 - iter 414/469 - loss 0.11977627\n",
      "2019-03-18 13:53:43,959 epoch 83 - iter 460/469 - loss 0.11789253\n",
      "2019-03-18 13:53:45,161 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 13:53:45,162 EPOCH 83 done: loss 0.1176 - lr 0.0031 - bad epochs 0\n",
      "2019-03-18 13:54:03,593 DEV  : loss 0.59765959 - f-score 0.9568 - acc 0.9173\n",
      "2019-03-18 13:54:20,241 TEST : loss 1.21928251 - f-score 0.9296 - acc 0.8684\n",
      "2019-03-18 13:54:28,911 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 13:54:30,621 epoch 84 - iter 0/469 - loss 0.18318617\n",
      "2019-03-18 13:54:38,493 epoch 84 - iter 46/469 - loss 0.16580242\n",
      "2019-03-18 13:54:46,338 epoch 84 - iter 92/469 - loss 0.17257767\n",
      "2019-03-18 13:54:54,158 epoch 84 - iter 138/469 - loss 0.15963098\n",
      "2019-03-18 13:55:01,902 epoch 84 - iter 184/469 - loss 0.15879887\n",
      "2019-03-18 13:55:09,764 epoch 84 - iter 230/469 - loss 0.14554555\n",
      "2019-03-18 13:55:18,007 epoch 84 - iter 276/469 - loss 0.14454332\n",
      "2019-03-18 13:55:25,747 epoch 84 - iter 322/469 - loss 0.14516402\n",
      "2019-03-18 13:55:33,949 epoch 84 - iter 368/469 - loss 0.13825564\n",
      "2019-03-18 13:55:42,124 epoch 84 - iter 414/469 - loss 0.14119198\n",
      "2019-03-18 13:55:49,736 epoch 84 - iter 460/469 - loss 0.13919227\n",
      "2019-03-18 13:55:51,013 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 13:55:51,013 EPOCH 84 done: loss 0.1395 - lr 0.0031 - bad epochs 0\n",
      "2019-03-18 13:56:09,771 DEV  : loss 0.59707052 - f-score 0.9569 - acc 0.9174\n",
      "2019-03-18 13:56:26,677 TEST : loss 1.21621239 - f-score 0.9296 - acc 0.8684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-18 13:56:26,680 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 13:56:26,864 epoch 85 - iter 0/469 - loss 0.00835049\n",
      "2019-03-18 13:56:34,331 epoch 85 - iter 46/469 - loss 0.16747869\n",
      "2019-03-18 13:56:42,142 epoch 85 - iter 92/469 - loss 0.13552265\n",
      "2019-03-18 13:56:50,063 epoch 85 - iter 138/469 - loss 0.12091006\n",
      "2019-03-18 13:56:57,688 epoch 85 - iter 184/469 - loss 0.11731767\n",
      "2019-03-18 13:57:05,611 epoch 85 - iter 230/469 - loss 0.12053147\n",
      "2019-03-18 13:57:13,762 epoch 85 - iter 276/469 - loss 0.11799449\n",
      "2019-03-18 13:57:21,661 epoch 85 - iter 322/469 - loss 0.11378296\n",
      "2019-03-18 13:57:30,110 epoch 85 - iter 368/469 - loss 0.11275602\n",
      "2019-03-18 13:57:38,393 epoch 85 - iter 414/469 - loss 0.11497239\n",
      "2019-03-18 13:57:46,187 epoch 85 - iter 460/469 - loss 0.11891607\n",
      "2019-03-18 13:57:47,505 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 13:57:47,506 EPOCH 85 done: loss 0.1219 - lr 0.0031 - bad epochs 1\n",
      "2019-03-18 13:58:05,723 DEV  : loss 0.59564954 - f-score 0.9569 - acc 0.9174\n",
      "2019-03-18 13:58:22,717 TEST : loss 1.21908510 - f-score 0.9295 - acc 0.8682\n",
      "2019-03-18 13:58:22,720 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 13:58:22,886 epoch 86 - iter 0/469 - loss 0.14598644\n",
      "2019-03-18 13:58:30,475 epoch 86 - iter 46/469 - loss 0.10014659\n",
      "2019-03-18 13:58:38,093 epoch 86 - iter 92/469 - loss 0.10412009\n",
      "2019-03-18 13:58:46,189 epoch 86 - iter 138/469 - loss 0.13200502\n",
      "2019-03-18 13:58:54,137 epoch 86 - iter 184/469 - loss 0.13918769\n",
      "2019-03-18 13:59:01,939 epoch 86 - iter 230/469 - loss 0.13120249\n",
      "2019-03-18 13:59:09,970 epoch 86 - iter 276/469 - loss 0.13034309\n",
      "2019-03-18 13:59:17,896 epoch 86 - iter 322/469 - loss 0.13310136\n",
      "2019-03-18 13:59:25,904 epoch 86 - iter 368/469 - loss 0.13312811\n",
      "2019-03-18 13:59:33,637 epoch 86 - iter 414/469 - loss 0.12948497\n",
      "2019-03-18 13:59:41,503 epoch 86 - iter 460/469 - loss 0.12912236\n",
      "2019-03-18 13:59:42,790 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 13:59:42,791 EPOCH 86 done: loss 0.1324 - lr 0.0031 - bad epochs 2\n",
      "2019-03-18 14:00:00,907 DEV  : loss 0.59303641 - f-score 0.9564 - acc 0.9165\n",
      "2019-03-18 14:00:17,873 TEST : loss 1.21871233 - f-score 0.9292 - acc 0.8679\n",
      "2019-03-18 14:00:17,876 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 14:00:18,066 epoch 87 - iter 0/469 - loss 0.19313467\n",
      "2019-03-18 14:00:25,730 epoch 87 - iter 46/469 - loss 0.12032687\n",
      "2019-03-18 14:00:33,798 epoch 87 - iter 92/469 - loss 0.11126570\n",
      "2019-03-18 14:00:42,316 epoch 87 - iter 138/469 - loss 0.10777907\n",
      "2019-03-18 14:00:50,385 epoch 87 - iter 184/469 - loss 0.12211809\n",
      "2019-03-18 14:00:58,069 epoch 87 - iter 230/469 - loss 0.11982312\n",
      "2019-03-18 14:01:05,806 epoch 87 - iter 276/469 - loss 0.12584978\n",
      "2019-03-18 14:01:13,642 epoch 87 - iter 322/469 - loss 0.13356549\n",
      "2019-03-18 14:01:21,535 epoch 87 - iter 368/469 - loss 0.13012160\n",
      "2019-03-18 14:01:29,410 epoch 87 - iter 414/469 - loss 0.13304315\n",
      "2019-03-18 14:01:37,598 epoch 87 - iter 460/469 - loss 0.13225256\n",
      "2019-03-18 14:01:38,912 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 14:01:38,913 EPOCH 87 done: loss 0.1319 - lr 0.0031 - bad epochs 3\n",
      "2019-03-18 14:01:57,183 DEV  : loss 0.59505564 - f-score 0.9563 - acc 0.9163\n",
      "2019-03-18 14:02:14,359 TEST : loss 1.21957362 - f-score 0.9292 - acc 0.8678\n",
      "Epoch    86: reducing learning rate of group 0 to 1.5625e-03.\n",
      "2019-03-18 14:02:14,362 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 14:02:14,531 epoch 88 - iter 0/469 - loss 0.04916257\n",
      "2019-03-18 14:02:22,356 epoch 88 - iter 46/469 - loss 0.13690428\n",
      "2019-03-18 14:02:29,999 epoch 88 - iter 92/469 - loss 0.12705895\n",
      "2019-03-18 14:02:37,624 epoch 88 - iter 138/469 - loss 0.12608960\n",
      "2019-03-18 14:02:45,444 epoch 88 - iter 184/469 - loss 0.12015231\n",
      "2019-03-18 14:02:53,304 epoch 88 - iter 230/469 - loss 0.12261345\n",
      "2019-03-18 14:03:01,218 epoch 88 - iter 276/469 - loss 0.11796798\n",
      "2019-03-18 14:03:09,216 epoch 88 - iter 322/469 - loss 0.12013800\n",
      "2019-03-18 14:03:16,871 epoch 88 - iter 368/469 - loss 0.12925841\n",
      "2019-03-18 14:03:24,576 epoch 88 - iter 414/469 - loss 0.12519739\n",
      "2019-03-18 14:03:32,350 epoch 88 - iter 460/469 - loss 0.12398115\n",
      "2019-03-18 14:03:33,699 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 14:03:33,700 EPOCH 88 done: loss 0.1230 - lr 0.0016 - bad epochs 0\n",
      "2019-03-18 14:03:52,030 DEV  : loss 0.59477001 - f-score 0.9561 - acc 0.9160\n",
      "2019-03-18 14:04:09,106 TEST : loss 1.21666348 - f-score 0.9290 - acc 0.8675\n",
      "2019-03-18 14:04:09,107 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 14:04:09,314 epoch 89 - iter 0/469 - loss 0.00995004\n",
      "2019-03-18 14:04:17,029 epoch 89 - iter 46/469 - loss 0.14058938\n",
      "2019-03-18 14:04:24,650 epoch 89 - iter 92/469 - loss 0.12141556\n",
      "2019-03-18 14:04:32,366 epoch 89 - iter 138/469 - loss 0.11746874\n",
      "2019-03-18 14:04:39,982 epoch 89 - iter 184/469 - loss 0.13174527\n",
      "2019-03-18 14:04:47,845 epoch 89 - iter 230/469 - loss 0.12414177\n",
      "2019-03-18 14:04:55,579 epoch 89 - iter 276/469 - loss 0.12699030\n",
      "2019-03-18 14:05:03,351 epoch 89 - iter 322/469 - loss 0.13336446\n",
      "2019-03-18 14:05:11,100 epoch 89 - iter 368/469 - loss 0.12943493\n",
      "2019-03-18 14:05:19,401 epoch 89 - iter 414/469 - loss 0.12947405\n",
      "2019-03-18 14:05:27,439 epoch 89 - iter 460/469 - loss 0.13130026\n",
      "2019-03-18 14:05:28,711 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 14:05:28,711 EPOCH 89 done: loss 0.1315 - lr 0.0016 - bad epochs 1\n",
      "2019-03-18 14:05:48,061 DEV  : loss 0.59496737 - f-score 0.9557 - acc 0.9151\n",
      "2019-03-18 14:06:05,011 TEST : loss 1.21831393 - f-score 0.9292 - acc 0.8678\n",
      "2019-03-18 14:06:05,012 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 14:06:05,195 epoch 90 - iter 0/469 - loss 0.29962772\n",
      "2019-03-18 14:06:12,755 epoch 90 - iter 46/469 - loss 0.09691467\n",
      "2019-03-18 14:06:20,559 epoch 90 - iter 92/469 - loss 0.11320253\n",
      "2019-03-18 14:06:28,397 epoch 90 - iter 138/469 - loss 0.11233481\n",
      "2019-03-18 14:06:36,177 epoch 90 - iter 184/469 - loss 0.11160218\n",
      "2019-03-18 14:06:43,733 epoch 90 - iter 230/469 - loss 0.11641671\n",
      "2019-03-18 14:06:51,558 epoch 90 - iter 276/469 - loss 0.11558686\n",
      "2019-03-18 14:06:59,204 epoch 90 - iter 322/469 - loss 0.11352537\n",
      "2019-03-18 14:07:07,468 epoch 90 - iter 368/469 - loss 0.11902215\n",
      "2019-03-18 14:07:15,024 epoch 90 - iter 414/469 - loss 0.12231859\n",
      "2019-03-18 14:07:22,439 epoch 90 - iter 460/469 - loss 0.11913679\n",
      "2019-03-18 14:07:23,794 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 14:07:23,795 EPOCH 90 done: loss 0.1201 - lr 0.0016 - bad epochs 2\n",
      "2019-03-18 14:07:41,312 DEV  : loss 0.59495443 - f-score 0.9557 - acc 0.9153\n",
      "2019-03-18 14:07:58,111 TEST : loss 1.21972895 - f-score 0.9296 - acc 0.8686\n",
      "2019-03-18 14:07:58,113 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 14:07:58,268 epoch 91 - iter 0/469 - loss 0.07997936\n",
      "2019-03-18 14:08:06,214 epoch 91 - iter 46/469 - loss 0.11704981\n",
      "2019-03-18 14:08:13,928 epoch 91 - iter 92/469 - loss 0.11293851\n",
      "2019-03-18 14:08:21,883 epoch 91 - iter 138/469 - loss 0.13783894\n",
      "2019-03-18 14:08:29,839 epoch 91 - iter 184/469 - loss 0.15257941\n",
      "2019-03-18 14:08:37,640 epoch 91 - iter 230/469 - loss 0.15021380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-18 14:08:45,307 epoch 91 - iter 276/469 - loss 0.14218533\n",
      "2019-03-18 14:08:53,294 epoch 91 - iter 322/469 - loss 0.14253475\n",
      "2019-03-18 14:09:01,503 epoch 91 - iter 368/469 - loss 0.13823016\n",
      "2019-03-18 14:09:09,026 epoch 91 - iter 414/469 - loss 0.13647673\n",
      "2019-03-18 14:09:16,866 epoch 91 - iter 460/469 - loss 0.13370844\n",
      "2019-03-18 14:09:18,106 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 14:09:18,106 EPOCH 91 done: loss 0.1330 - lr 0.0016 - bad epochs 3\n",
      "2019-03-18 14:09:36,091 DEV  : loss 0.59429818 - f-score 0.9563 - acc 0.9163\n",
      "2019-03-18 14:09:52,685 TEST : loss 1.22274280 - f-score 0.9296 - acc 0.8684\n",
      "Epoch    90: reducing learning rate of group 0 to 7.8125e-04.\n",
      "2019-03-18 14:09:52,686 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 14:09:52,870 epoch 92 - iter 0/469 - loss 0.29615417\n",
      "2019-03-18 14:10:00,495 epoch 92 - iter 46/469 - loss 0.11257246\n",
      "2019-03-18 14:10:08,051 epoch 92 - iter 92/469 - loss 0.14086306\n",
      "2019-03-18 14:10:16,208 epoch 92 - iter 138/469 - loss 0.15424762\n",
      "2019-03-18 14:10:24,049 epoch 92 - iter 184/469 - loss 0.15617588\n",
      "2019-03-18 14:10:32,834 epoch 92 - iter 230/469 - loss 0.14796108\n",
      "2019-03-18 14:10:40,948 epoch 92 - iter 276/469 - loss 0.14304145\n",
      "2019-03-18 14:10:49,133 epoch 92 - iter 322/469 - loss 0.15033890\n",
      "2019-03-18 14:10:56,931 epoch 92 - iter 368/469 - loss 0.14784958\n",
      "2019-03-18 14:11:04,864 epoch 92 - iter 414/469 - loss 0.14641538\n",
      "2019-03-18 14:11:12,695 epoch 92 - iter 460/469 - loss 0.14204147\n",
      "2019-03-18 14:11:13,933 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 14:11:13,934 EPOCH 92 done: loss 0.1420 - lr 0.0008 - bad epochs 0\n",
      "2019-03-18 14:11:31,836 DEV  : loss 0.59409642 - f-score 0.9561 - acc 0.9159\n",
      "2019-03-18 14:11:48,925 TEST : loss 1.22233772 - f-score 0.9296 - acc 0.8686\n",
      "2019-03-18 14:11:48,926 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 14:11:49,118 epoch 93 - iter 0/469 - loss 0.06158549\n",
      "2019-03-18 14:11:57,066 epoch 93 - iter 46/469 - loss 0.11325722\n",
      "2019-03-18 14:12:04,882 epoch 93 - iter 92/469 - loss 0.12084361\n",
      "2019-03-18 14:12:12,378 epoch 93 - iter 138/469 - loss 0.12887535\n",
      "2019-03-18 14:12:20,732 epoch 93 - iter 184/469 - loss 0.12556654\n",
      "2019-03-18 14:12:28,811 epoch 93 - iter 230/469 - loss 0.11694971\n",
      "2019-03-18 14:12:37,012 epoch 93 - iter 276/469 - loss 0.11191928\n",
      "2019-03-18 14:12:44,938 epoch 93 - iter 322/469 - loss 0.11124053\n",
      "2019-03-18 14:12:52,705 epoch 93 - iter 368/469 - loss 0.11531546\n",
      "2019-03-18 14:13:00,648 epoch 93 - iter 414/469 - loss 0.11574565\n",
      "2019-03-18 14:13:08,567 epoch 93 - iter 460/469 - loss 0.11690776\n",
      "2019-03-18 14:13:09,770 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 14:13:09,771 EPOCH 93 done: loss 0.1161 - lr 0.0008 - bad epochs 1\n",
      "2019-03-18 14:13:27,641 DEV  : loss 0.59338057 - f-score 0.9561 - acc 0.9159\n",
      "2019-03-18 14:13:45,551 TEST : loss 1.22060323 - f-score 0.9296 - acc 0.8684\n",
      "2019-03-18 14:13:52,709 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 14:13:52,915 epoch 94 - iter 0/469 - loss 0.01183614\n",
      "2019-03-18 14:14:00,701 epoch 94 - iter 46/469 - loss 0.10705840\n",
      "2019-03-18 14:14:08,298 epoch 94 - iter 92/469 - loss 0.11494240\n",
      "2019-03-18 14:14:15,997 epoch 94 - iter 138/469 - loss 0.11659212\n",
      "2019-03-18 14:14:23,492 epoch 94 - iter 184/469 - loss 0.11937180\n",
      "2019-03-18 14:14:32,094 epoch 94 - iter 230/469 - loss 0.11731994\n",
      "2019-03-18 14:14:39,753 epoch 94 - iter 276/469 - loss 0.11794975\n",
      "2019-03-18 14:14:47,520 epoch 94 - iter 322/469 - loss 0.11293139\n",
      "2019-03-18 14:14:55,377 epoch 94 - iter 368/469 - loss 0.11417712\n",
      "2019-03-18 14:15:02,987 epoch 94 - iter 414/469 - loss 0.11518415\n",
      "2019-03-18 14:15:10,508 epoch 94 - iter 460/469 - loss 0.11758505\n",
      "2019-03-18 14:15:11,692 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 14:15:11,693 EPOCH 94 done: loss 0.1165 - lr 0.0008 - bad epochs 0\n",
      "2019-03-18 14:15:29,290 DEV  : loss 0.59471977 - f-score 0.9563 - acc 0.9163\n",
      "2019-03-18 14:15:45,690 TEST : loss 1.22139871 - f-score 0.9296 - acc 0.8686\n",
      "2019-03-18 14:15:45,691 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 14:15:45,899 epoch 95 - iter 0/469 - loss 0.07207972\n",
      "2019-03-18 14:15:53,677 epoch 95 - iter 46/469 - loss 0.12709423\n",
      "2019-03-18 14:16:01,586 epoch 95 - iter 92/469 - loss 0.11303662\n",
      "2019-03-18 14:16:09,674 epoch 95 - iter 138/469 - loss 0.11523666\n",
      "2019-03-18 14:16:17,708 epoch 95 - iter 184/469 - loss 0.10590766\n",
      "2019-03-18 14:16:25,097 epoch 95 - iter 230/469 - loss 0.11948005\n",
      "2019-03-18 14:16:32,753 epoch 95 - iter 276/469 - loss 0.12243289\n",
      "2019-03-18 14:16:40,420 epoch 95 - iter 322/469 - loss 0.12017782\n",
      "2019-03-18 14:16:47,826 epoch 95 - iter 368/469 - loss 0.11930129\n",
      "2019-03-18 14:16:55,370 epoch 95 - iter 414/469 - loss 0.11527501\n",
      "2019-03-18 14:17:02,910 epoch 95 - iter 460/469 - loss 0.11472674\n",
      "2019-03-18 14:17:04,097 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 14:17:04,098 EPOCH 95 done: loss 0.1138 - lr 0.0008 - bad epochs 1\n",
      "2019-03-18 14:17:21,084 DEV  : loss 0.59453017 - f-score 0.9562 - acc 0.9160\n",
      "2019-03-18 14:17:37,189 TEST : loss 1.22211945 - f-score 0.9295 - acc 0.8683\n",
      "2019-03-18 14:17:45,372 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 14:17:45,547 epoch 96 - iter 0/469 - loss 0.55873632\n",
      "2019-03-18 14:17:53,458 epoch 96 - iter 46/469 - loss 0.11402534\n",
      "2019-03-18 14:18:01,003 epoch 96 - iter 92/469 - loss 0.10265078\n",
      "2019-03-18 14:18:08,526 epoch 96 - iter 138/469 - loss 0.10663303\n",
      "2019-03-18 14:18:16,432 epoch 96 - iter 184/469 - loss 0.10711059\n",
      "2019-03-18 14:18:24,741 epoch 96 - iter 230/469 - loss 0.10483066\n",
      "2019-03-18 14:18:32,732 epoch 96 - iter 276/469 - loss 0.10963519\n",
      "2019-03-18 14:18:40,655 epoch 96 - iter 322/469 - loss 0.11079133\n",
      "2019-03-18 14:18:48,431 epoch 96 - iter 368/469 - loss 0.11595725\n",
      "2019-03-18 14:18:56,191 epoch 96 - iter 414/469 - loss 0.12101190\n",
      "2019-03-18 14:19:04,007 epoch 96 - iter 460/469 - loss 0.11867240\n",
      "2019-03-18 14:19:05,296 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 14:19:05,297 EPOCH 96 done: loss 0.1186 - lr 0.0008 - bad epochs 0\n",
      "2019-03-18 14:19:23,528 DEV  : loss 0.59407103 - f-score 0.9563 - acc 0.9163\n",
      "2019-03-18 14:19:40,572 TEST : loss 1.22194934 - f-score 0.9294 - acc 0.8681\n",
      "2019-03-18 14:19:40,573 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 14:19:40,777 epoch 97 - iter 0/469 - loss 0.18888602\n",
      "2019-03-18 14:19:48,479 epoch 97 - iter 46/469 - loss 0.12919924\n",
      "2019-03-18 14:19:56,477 epoch 97 - iter 92/469 - loss 0.12412812\n",
      "2019-03-18 14:20:04,198 epoch 97 - iter 138/469 - loss 0.15596655\n",
      "2019-03-18 14:20:11,967 epoch 97 - iter 184/469 - loss 0.15414689\n",
      "2019-03-18 14:20:19,830 epoch 97 - iter 230/469 - loss 0.14556166\n",
      "2019-03-18 14:20:27,641 epoch 97 - iter 276/469 - loss 0.14562966\n",
      "2019-03-18 14:20:35,526 epoch 97 - iter 322/469 - loss 0.14335348\n",
      "2019-03-18 14:20:43,513 epoch 97 - iter 368/469 - loss 0.14312128\n",
      "2019-03-18 14:20:51,441 epoch 97 - iter 414/469 - loss 0.14317418\n",
      "2019-03-18 14:20:59,263 epoch 97 - iter 460/469 - loss 0.14055685\n",
      "2019-03-18 14:21:00,583 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 14:21:00,584 EPOCH 97 done: loss 0.1408 - lr 0.0008 - bad epochs 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-18 14:21:19,095 DEV  : loss 0.59413189 - f-score 0.9562 - acc 0.9160\n",
      "2019-03-18 14:21:35,748 TEST : loss 1.22222173 - f-score 0.9295 - acc 0.8684\n",
      "2019-03-18 14:21:35,749 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 14:21:35,922 epoch 98 - iter 0/469 - loss 0.01013422\n",
      "2019-03-18 14:21:43,654 epoch 98 - iter 46/469 - loss 0.12420974\n",
      "2019-03-18 14:21:51,464 epoch 98 - iter 92/469 - loss 0.11000997\n",
      "2019-03-18 14:21:59,185 epoch 98 - iter 138/469 - loss 0.10542277\n",
      "2019-03-18 14:22:06,965 epoch 98 - iter 184/469 - loss 0.11283811\n",
      "2019-03-18 14:22:15,044 epoch 98 - iter 230/469 - loss 0.11447495\n",
      "2019-03-18 14:22:22,873 epoch 98 - iter 276/469 - loss 0.11744090\n",
      "2019-03-18 14:22:30,853 epoch 98 - iter 322/469 - loss 0.11644648\n",
      "2019-03-18 14:22:38,620 epoch 98 - iter 368/469 - loss 0.11574984\n",
      "2019-03-18 14:22:46,486 epoch 98 - iter 414/469 - loss 0.11830231\n",
      "2019-03-18 14:22:54,587 epoch 98 - iter 460/469 - loss 0.11995204\n",
      "2019-03-18 14:22:55,902 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 14:22:55,903 EPOCH 98 done: loss 0.1191 - lr 0.0008 - bad epochs 2\n",
      "2019-03-18 14:23:14,870 DEV  : loss 0.59678257 - f-score 0.9559 - acc 0.9156\n",
      "2019-03-18 14:23:32,254 TEST : loss 1.22305846 - f-score 0.9296 - acc 0.8684\n",
      "2019-03-18 14:23:32,256 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 14:23:32,435 epoch 99 - iter 0/469 - loss 0.01856244\n",
      "2019-03-18 14:23:40,318 epoch 99 - iter 46/469 - loss 0.15323519\n",
      "2019-03-18 14:23:48,178 epoch 99 - iter 92/469 - loss 0.12572676\n",
      "2019-03-18 14:23:55,895 epoch 99 - iter 138/469 - loss 0.12695170\n",
      "2019-03-18 14:24:03,527 epoch 99 - iter 184/469 - loss 0.11800232\n",
      "2019-03-18 14:24:11,507 epoch 99 - iter 230/469 - loss 0.11104860\n",
      "2019-03-18 14:24:19,281 epoch 99 - iter 276/469 - loss 0.11184122\n",
      "2019-03-18 14:24:27,148 epoch 99 - iter 322/469 - loss 0.11416963\n",
      "2019-03-18 14:24:35,028 epoch 99 - iter 368/469 - loss 0.11551074\n",
      "2019-03-18 14:24:42,995 epoch 99 - iter 414/469 - loss 0.11571336\n",
      "2019-03-18 14:24:50,882 epoch 99 - iter 460/469 - loss 0.11638018\n",
      "2019-03-18 14:24:52,155 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 14:24:52,155 EPOCH 99 done: loss 0.1167 - lr 0.0008 - bad epochs 3\n",
      "2019-03-18 14:25:09,373 DEV  : loss 0.59729022 - f-score 0.9562 - acc 0.9162\n",
      "2019-03-18 14:25:25,514 TEST : loss 1.22224414 - f-score 0.9298 - acc 0.8689\n",
      "Epoch    98: reducing learning rate of group 0 to 3.9063e-04.\n",
      "2019-03-18 14:25:25,515 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 14:25:25,652 epoch 100 - iter 0/469 - loss 0.18912610\n",
      "2019-03-18 14:25:33,263 epoch 100 - iter 46/469 - loss 0.10303929\n",
      "2019-03-18 14:25:41,227 epoch 100 - iter 92/469 - loss 0.14577440\n",
      "2019-03-18 14:25:49,405 epoch 100 - iter 138/469 - loss 0.13913523\n",
      "2019-03-18 14:25:57,415 epoch 100 - iter 184/469 - loss 0.13512549\n",
      "2019-03-18 14:26:05,390 epoch 100 - iter 230/469 - loss 0.13244948\n",
      "2019-03-18 14:26:13,466 epoch 100 - iter 276/469 - loss 0.13116624\n",
      "2019-03-18 14:26:21,332 epoch 100 - iter 322/469 - loss 0.12723966\n",
      "2019-03-18 14:26:29,360 epoch 100 - iter 368/469 - loss 0.12686325\n",
      "2019-03-18 14:26:37,331 epoch 100 - iter 414/469 - loss 0.12707675\n",
      "2019-03-18 14:26:45,176 epoch 100 - iter 460/469 - loss 0.12675883\n",
      "2019-03-18 14:26:46,385 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 14:26:46,386 EPOCH 100 done: loss 0.1271 - lr 0.0004 - bad epochs 0\n",
      "2019-03-18 14:27:04,707 DEV  : loss 0.59656870 - f-score 0.9562 - acc 0.9162\n",
      "2019-03-18 14:27:21,230 TEST : loss 1.22239184 - f-score 0.9295 - acc 0.8684\n",
      "2019-03-18 14:27:21,231 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 14:27:21,406 epoch 101 - iter 0/469 - loss 0.03913772\n",
      "2019-03-18 14:27:29,351 epoch 101 - iter 46/469 - loss 0.09908973\n",
      "2019-03-18 14:27:37,286 epoch 101 - iter 92/469 - loss 0.11388501\n",
      "2019-03-18 14:27:44,936 epoch 101 - iter 138/469 - loss 0.11316586\n",
      "2019-03-18 14:27:53,801 epoch 101 - iter 184/469 - loss 0.11704984\n",
      "2019-03-18 14:28:01,584 epoch 101 - iter 230/469 - loss 0.11607598\n",
      "2019-03-18 14:28:09,334 epoch 101 - iter 276/469 - loss 0.12440445\n",
      "2019-03-18 14:28:17,055 epoch 101 - iter 322/469 - loss 0.12821368\n",
      "2019-03-18 14:28:25,141 epoch 101 - iter 368/469 - loss 0.12818826\n",
      "2019-03-18 14:28:33,282 epoch 101 - iter 414/469 - loss 0.12824107\n",
      "2019-03-18 14:28:41,214 epoch 101 - iter 460/469 - loss 0.12792059\n",
      "2019-03-18 14:28:42,499 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 14:28:42,500 EPOCH 101 done: loss 0.1267 - lr 0.0004 - bad epochs 1\n",
      "2019-03-18 14:29:00,821 DEV  : loss 0.59714550 - f-score 0.9562 - acc 0.9162\n",
      "2019-03-18 14:29:17,939 TEST : loss 1.22272646 - f-score 0.9294 - acc 0.8681\n",
      "2019-03-18 14:29:17,940 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 14:29:18,097 epoch 102 - iter 0/469 - loss 0.00146580\n",
      "2019-03-18 14:29:25,774 epoch 102 - iter 46/469 - loss 0.14758089\n",
      "2019-03-18 14:29:33,828 epoch 102 - iter 92/469 - loss 0.14389868\n",
      "2019-03-18 14:29:41,606 epoch 102 - iter 138/469 - loss 0.13321803\n",
      "2019-03-18 14:29:49,323 epoch 102 - iter 184/469 - loss 0.12928266\n",
      "2019-03-18 14:29:57,371 epoch 102 - iter 230/469 - loss 0.12850832\n",
      "2019-03-18 14:30:05,506 epoch 102 - iter 276/469 - loss 0.12776395\n",
      "2019-03-18 14:30:13,403 epoch 102 - iter 322/469 - loss 0.13113389\n",
      "2019-03-18 14:30:21,323 epoch 102 - iter 368/469 - loss 0.13086477\n",
      "2019-03-18 14:30:29,402 epoch 102 - iter 414/469 - loss 0.12543865\n",
      "2019-03-18 14:30:37,320 epoch 102 - iter 460/469 - loss 0.12463740\n",
      "2019-03-18 14:30:38,644 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 14:30:38,645 EPOCH 102 done: loss 0.1250 - lr 0.0004 - bad epochs 2\n",
      "2019-03-18 14:30:56,205 DEV  : loss 0.59738088 - f-score 0.9562 - acc 0.9162\n",
      "2019-03-18 14:31:13,219 TEST : loss 1.22317719 - f-score 0.9296 - acc 0.8686\n",
      "2019-03-18 14:31:13,220 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 14:31:13,384 epoch 103 - iter 0/469 - loss 0.11374027\n",
      "2019-03-18 14:31:21,350 epoch 103 - iter 46/469 - loss 0.18042708\n",
      "2019-03-18 14:31:29,185 epoch 103 - iter 92/469 - loss 0.16085403\n",
      "2019-03-18 14:31:36,946 epoch 103 - iter 138/469 - loss 0.14195892\n",
      "2019-03-18 14:31:45,002 epoch 103 - iter 184/469 - loss 0.14370271\n",
      "2019-03-18 14:31:53,016 epoch 103 - iter 230/469 - loss 0.14783080\n",
      "2019-03-18 14:32:00,819 epoch 103 - iter 276/469 - loss 0.13863190\n",
      "2019-03-18 14:32:08,979 epoch 103 - iter 322/469 - loss 0.13292406\n",
      "2019-03-18 14:32:17,033 epoch 103 - iter 368/469 - loss 0.12642791\n",
      "2019-03-18 14:32:25,171 epoch 103 - iter 414/469 - loss 0.12588871\n",
      "2019-03-18 14:32:33,456 epoch 103 - iter 460/469 - loss 0.12363928\n",
      "2019-03-18 14:32:34,676 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 14:32:34,676 EPOCH 103 done: loss 0.1227 - lr 0.0004 - bad epochs 3\n",
      "2019-03-18 14:32:53,933 DEV  : loss 0.59706688 - f-score 0.9564 - acc 0.9165\n",
      "2019-03-18 14:33:11,336 TEST : loss 1.22304809 - f-score 0.9298 - acc 0.8689\n",
      "Epoch   102: reducing learning rate of group 0 to 1.9531e-04.\n",
      "2019-03-18 14:33:11,338 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 14:33:11,529 epoch 104 - iter 0/469 - loss 0.09111893\n",
      "2019-03-18 14:33:19,237 epoch 104 - iter 46/469 - loss 0.10316497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-18 14:33:27,321 epoch 104 - iter 92/469 - loss 0.12956791\n",
      "2019-03-18 14:33:34,975 epoch 104 - iter 138/469 - loss 0.13241807\n",
      "2019-03-18 14:33:42,970 epoch 104 - iter 184/469 - loss 0.13929903\n",
      "2019-03-18 14:33:50,666 epoch 104 - iter 230/469 - loss 0.13598956\n",
      "2019-03-18 14:33:58,837 epoch 104 - iter 276/469 - loss 0.13567103\n",
      "2019-03-18 14:34:06,708 epoch 104 - iter 322/469 - loss 0.13950378\n",
      "2019-03-18 14:34:14,813 epoch 104 - iter 368/469 - loss 0.13268518\n",
      "2019-03-18 14:34:22,733 epoch 104 - iter 414/469 - loss 0.13057789\n",
      "2019-03-18 14:34:30,713 epoch 104 - iter 460/469 - loss 0.13468739\n",
      "2019-03-18 14:34:32,014 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 14:34:32,014 EPOCH 104 done: loss 0.1343 - lr 0.0002 - bad epochs 0\n",
      "2019-03-18 14:34:50,356 DEV  : loss 0.59681934 - f-score 0.9564 - acc 0.9165\n",
      "2019-03-18 14:35:07,185 TEST : loss 1.22300828 - f-score 0.9298 - acc 0.8689\n",
      "2019-03-18 14:35:07,186 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 14:35:07,392 epoch 105 - iter 0/469 - loss 0.39961147\n",
      "2019-03-18 14:35:14,907 epoch 105 - iter 46/469 - loss 0.09946972\n",
      "2019-03-18 14:35:22,643 epoch 105 - iter 92/469 - loss 0.10874256\n",
      "2019-03-18 14:35:30,631 epoch 105 - iter 138/469 - loss 0.10352878\n",
      "2019-03-18 14:35:38,116 epoch 105 - iter 184/469 - loss 0.11904354\n",
      "2019-03-18 14:35:45,780 epoch 105 - iter 230/469 - loss 0.11865283\n",
      "2019-03-18 14:35:53,966 epoch 105 - iter 276/469 - loss 0.11486379\n",
      "2019-03-18 14:36:01,636 epoch 105 - iter 322/469 - loss 0.11501723\n",
      "2019-03-18 14:36:09,696 epoch 105 - iter 368/469 - loss 0.11031903\n",
      "2019-03-18 14:36:17,774 epoch 105 - iter 414/469 - loss 0.11379177\n",
      "2019-03-18 14:36:25,534 epoch 105 - iter 460/469 - loss 0.11229099\n",
      "2019-03-18 14:36:26,889 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 14:36:26,889 EPOCH 105 done: loss 0.1120 - lr 0.0002 - bad epochs 1\n",
      "2019-03-18 14:36:44,871 DEV  : loss 0.59711820 - f-score 0.9564 - acc 0.9165\n",
      "2019-03-18 14:37:01,446 TEST : loss 1.22269166 - f-score 0.9296 - acc 0.8686\n",
      "2019-03-18 14:37:08,897 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 14:37:09,131 epoch 106 - iter 0/469 - loss 0.16930646\n",
      "2019-03-18 14:37:17,004 epoch 106 - iter 46/469 - loss 0.13567018\n",
      "2019-03-18 14:37:24,915 epoch 106 - iter 92/469 - loss 0.12693706\n",
      "2019-03-18 14:37:32,640 epoch 106 - iter 138/469 - loss 0.11299431\n",
      "2019-03-18 14:37:40,190 epoch 106 - iter 184/469 - loss 0.11616047\n",
      "2019-03-18 14:37:48,249 epoch 106 - iter 230/469 - loss 0.12245587\n",
      "2019-03-18 14:37:56,447 epoch 106 - iter 276/469 - loss 0.11889255\n",
      "2019-03-18 14:38:04,259 epoch 106 - iter 322/469 - loss 0.11383796\n",
      "2019-03-18 14:38:11,979 epoch 106 - iter 368/469 - loss 0.11541726\n",
      "2019-03-18 14:38:19,776 epoch 106 - iter 414/469 - loss 0.11511822\n",
      "2019-03-18 14:38:27,938 epoch 106 - iter 460/469 - loss 0.11316363\n",
      "2019-03-18 14:38:29,252 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 14:38:29,252 EPOCH 106 done: loss 0.1130 - lr 0.0002 - bad epochs 0\n",
      "2019-03-18 14:38:47,144 DEV  : loss 0.59717095 - f-score 0.9564 - acc 0.9165\n",
      "2019-03-18 14:39:03,636 TEST : loss 1.22299361 - f-score 0.9296 - acc 0.8686\n",
      "2019-03-18 14:39:03,637 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 14:39:03,818 epoch 107 - iter 0/469 - loss 0.33681148\n",
      "2019-03-18 14:39:11,646 epoch 107 - iter 46/469 - loss 0.12974082\n",
      "2019-03-18 14:39:19,744 epoch 107 - iter 92/469 - loss 0.14217088\n",
      "2019-03-18 14:39:27,410 epoch 107 - iter 138/469 - loss 0.14707574\n",
      "2019-03-18 14:39:35,290 epoch 107 - iter 184/469 - loss 0.13925022\n",
      "2019-03-18 14:39:43,332 epoch 107 - iter 230/469 - loss 0.13479376\n",
      "2019-03-18 14:39:51,346 epoch 107 - iter 276/469 - loss 0.13248265\n",
      "2019-03-18 14:39:59,479 epoch 107 - iter 322/469 - loss 0.13604781\n",
      "2019-03-18 14:40:07,647 epoch 107 - iter 368/469 - loss 0.13087340\n",
      "2019-03-18 14:40:15,797 epoch 107 - iter 414/469 - loss 0.12863304\n",
      "2019-03-18 14:40:23,472 epoch 107 - iter 460/469 - loss 0.12936600\n",
      "2019-03-18 14:40:24,756 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 14:40:24,757 EPOCH 107 done: loss 0.1291 - lr 0.0002 - bad epochs 1\n",
      "2019-03-18 14:40:43,055 DEV  : loss 0.59729224 - f-score 0.9564 - acc 0.9165\n",
      "2019-03-18 14:41:00,910 TEST : loss 1.22305024 - f-score 0.9296 - acc 0.8686\n",
      "2019-03-18 14:41:00,911 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 14:41:01,081 epoch 108 - iter 0/469 - loss 0.15962124\n",
      "2019-03-18 14:41:08,624 epoch 108 - iter 46/469 - loss 0.09951003\n",
      "2019-03-18 14:41:16,225 epoch 108 - iter 92/469 - loss 0.09835047\n",
      "2019-03-18 14:41:24,404 epoch 108 - iter 138/469 - loss 0.10254420\n",
      "2019-03-18 14:41:32,494 epoch 108 - iter 184/469 - loss 0.11133798\n",
      "2019-03-18 14:41:40,109 epoch 108 - iter 230/469 - loss 0.11597535\n",
      "2019-03-18 14:41:47,814 epoch 108 - iter 276/469 - loss 0.11704378\n",
      "2019-03-18 14:41:56,256 epoch 108 - iter 322/469 - loss 0.11754461\n",
      "2019-03-18 14:42:04,329 epoch 108 - iter 368/469 - loss 0.12248598\n",
      "2019-03-18 14:42:11,996 epoch 108 - iter 414/469 - loss 0.11901146\n",
      "2019-03-18 14:42:19,954 epoch 108 - iter 460/469 - loss 0.11853022\n",
      "2019-03-18 14:42:21,202 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 14:42:21,203 EPOCH 108 done: loss 0.1191 - lr 0.0002 - bad epochs 2\n",
      "2019-03-18 14:42:39,085 DEV  : loss 0.59697914 - f-score 0.9564 - acc 0.9165\n",
      "2019-03-18 14:42:56,284 TEST : loss 1.22316337 - f-score 0.9296 - acc 0.8686\n",
      "2019-03-18 14:42:56,285 ----------------------------------------------------------------------------------------------------\n",
      "train mode resetting embeddings\n",
      "train mode resetting embeddings\n",
      "2019-03-18 14:42:56,468 epoch 109 - iter 0/469 - loss 0.09333545\n",
      "2019-03-18 14:43:04,333 epoch 109 - iter 46/469 - loss 0.14566276\n",
      "2019-03-18 14:43:12,526 epoch 109 - iter 92/469 - loss 0.13700816\n",
      "2019-03-18 14:43:20,354 epoch 109 - iter 138/469 - loss 0.13193646\n",
      "2019-03-18 14:43:28,592 epoch 109 - iter 184/469 - loss 0.12910757\n",
      "2019-03-18 14:43:36,564 epoch 109 - iter 230/469 - loss 0.12408262\n",
      "2019-03-18 14:43:44,251 epoch 109 - iter 276/469 - loss 0.12264963\n",
      "2019-03-18 14:43:52,209 epoch 109 - iter 322/469 - loss 0.11445679\n",
      "2019-03-18 14:44:00,159 epoch 109 - iter 368/469 - loss 0.11841167\n",
      "2019-03-18 14:44:08,292 epoch 109 - iter 414/469 - loss 0.12097082\n",
      "2019-03-18 14:44:16,477 epoch 109 - iter 460/469 - loss 0.12051334\n",
      "2019-03-18 14:44:17,803 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 14:44:17,804 EPOCH 109 done: loss 0.1207 - lr 0.0002 - bad epochs 3\n",
      "2019-03-18 14:44:35,713 DEV  : loss 0.59691143 - f-score 0.9564 - acc 0.9165\n",
      "2019-03-18 14:44:52,803 TEST : loss 1.22322524 - f-score 0.9296 - acc 0.8686\n",
      "Epoch   108: reducing learning rate of group 0 to 9.7656e-05.\n",
      "2019-03-18 14:44:52,805 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 14:44:52,805 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 14:44:52,806 learning rate too small - quitting training!\n",
      "2019-03-18 14:44:52,806 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 14:45:00,282 ----------------------------------------------------------------------------------------------------\n",
      "2019-03-18 14:45:00,284 Testing using best model ...\n",
      "2019-03-18 14:45:00,286 loading file models/flair/conll_03-ner/best-model.pt\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of backend CUDA but got backend CPU for argument #2 'other'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-eea47e8de6c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m trainer.train('models/flair/conll_03-ner',\n\u001b[0;32m----> 5\u001b[0;31m               max_epochs=150)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/glvis/lib/python3.6/site-packages/flair/trainers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, base_path, evaluation_metric, learning_rate, mini_batch_size, eval_mini_batch_size, max_epochs, anneal_factor, patience, anneal_against_train_loss, train_with_dev, monitor_train, embeddings_in_memory, checkpoint, save_final_model, anneal_with_restarts, test_mode, param_selection_mode, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;31m# test best model if test data is present\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mfinal_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings_in_memory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluation_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_mini_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0mfinal_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/glvis/lib/python3.6/site-packages/flair/trainers/trainer.py\u001b[0m in \u001b[0;36mfinal_test\u001b[0;34m(self, base_path, embeddings_in_memory, evaluation_metric, eval_mini_batch_size)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         test_metric, test_loss = self.evaluate(self.model, self.corpus.test, eval_mini_batch_size=eval_mini_batch_size,\n\u001b[0;32m--> 278\u001b[0;31m                                                embeddings_in_memory=embeddings_in_memory)\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'MICRO_AVG: acc {test_metric.micro_avg_accuracy()} - f1-score {test_metric.micro_avg_f_score()}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/glvis/lib/python3.6/site-packages/flair/trainers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, data_set, eval_mini_batch_size, embeddings_in_memory, out_path)\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequenceTagger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             return ModelTrainer._evaluate_sequence_tagger(model, data_set, eval_mini_batch_size, embeddings_in_memory,\n\u001b[0;32m--> 346\u001b[0;31m                                                           out_path)\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/glvis/lib/python3.6/site-packages/flair/trainers/trainer.py\u001b[0m in \u001b[0;36m_evaluate_sequence_tagger\u001b[0;34m(model, sentences, eval_mini_batch_size, embeddings_in_memory, out_path)\u001b[0m\n\u001b[1;32m    365\u001b[0m                 \u001b[0mbatch_no\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m                 \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_labels_and_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0meval_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/glvis/lib/python3.6/site-packages/flair/models/sequence_tagger_model.py\u001b[0m in \u001b[0;36mforward_labels_and_loss\u001b[0;34m(self, sentences, sort)\u001b[0m\n\u001b[1;32m    266\u001b[0m                                 sort=True) -> (List[List[Label]], torch.tensor):\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m             \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_obtain_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/glvis/lib/python3.6/site-packages/flair/models/sequence_tagger_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sentences, sort)\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;31m# if sorting is enabled, sort sentences by number of tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/glvis/lib/python3.6/site-packages/flair/embeddings.py\u001b[0m in \u001b[0;36membed\u001b[0;34m(self, sentences, static_embeddings)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0membedding\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/glvis/lib/python3.6/site-packages/flair/embeddings.py\u001b[0m in \u001b[0;36membed\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0meverything_embedded\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatic_embeddings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_embeddings_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/glvis/lib/python3.6/site-packages/flair/embeddings.py\u001b[0m in \u001b[0;36m_add_embeddings_internal\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m   1029\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_count\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1031\u001b[0;31m                         \u001b[0maggregated_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_embedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1032\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooling\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'fade'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m                             \u001b[0maggregated_embedding\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of backend CUDA but got backend CPU for argument #2 'other'"
     ]
    }
   ],
   "source": [
    "# initialize trainer\n",
    "trainer: ModelTrainer = ModelTrainer(tagger, corpus)\n",
    "\n",
    "trainer.train('models/flair/conll_03-ner',\n",
    "              max_epochs=150)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
